# `NEQ`: Identifying Adverbs with Strongest Negative Environment Associations


```python
from pathlib import Path

import pandas as pd
from pprint import pprint
# from source.utils import PKL_SUFF
from source.utils.associate import AM_DF_DIR, TOP_AM_DIR, adjust_assoc_columns
from source.utils.general import print_iter, snake_to_camel, timestamp_today, confirm_dir

SET_FLOOR = 5000
MIR_FLOOR = min(round(SET_FLOOR//10, -2), 1000)
K = 8

TAG='NEQ'
TOP_AM_TAG_DIR = TOP_AM_DIR / TAG
confirm_dir(TOP_AM_TAG_DIR)

data_top = f'{TAG}-Top{K}'
OUT_DIR = TOP_AM_TAG_DIR / data_top
confirm_dir(OUT_DIR)
```

Set columns and diplay settings


```python
FOCUS = ['f',
         'am_p1_given2', 'am_p1_given2_simple', 'conservative_log_ratio',
         'am_log_likelihood',
        #  'mutual_information', 
         'am_odds_ratio_disc', 't_score',
         'N', 'f1', 'f2', 'E11', 'unexpected_f', 
         'l1', 'l2']
pd.set_option('display.max_colwidth', 20)
pd.set_option('display.max_columns', 12)
pd.set_option('display.width', 90)
pd.set_option("display.precision", 2)
pd.set_option("styler.format.precision", 2)
pd.set_option("styler.format.thousands", ",")
pd.set_option("display.float_format", '{:,.2f}'.format)
```


```python
def force_ints(_df):
    count_cols = _df.filter(regex=r'total|^[fN]').columns
    _df[count_cols] = _df[count_cols].astype('int')
    # _df[count_cols] = _df[:, count_cols].astype('int64')
    # print(_df.dtypes.to_frame('dtypes'))
    return _df
```


```python
def nb_show_table(df, n_dec: int = 2,
                  adjust_columns: bool = True,
                   outpath:Path=None, 
                   return_df:bool=False) -> None: 
    _df = df.copy()
    try: 
        start_0 = _df.index.start == 0
    except AttributeError: 
        pass
    else:
        _df.index.name = 'rank'
        if start_0: 
            _df.index = _df.index + 1
    if adjust_columns: 
        _df = adjust_assoc_columns(_df)
    _df.columns = [f'`{c}`' for c in _df.columns]
    _df.index = [f'**{r}**' for r in _df.index ]
    table = _df.to_markdown(floatfmt=f',.{n_dec}f', intfmt=',')
    if outpath:
        outpath.write_text(table)

    print(f'\n{table}\n')
    return (_df if return_df else None)
```

## Set paths and load adverb association tables


```python
def update_index(df, pat_name:str = None):
    neg_env_name = df.filter(like='NEG', axis=0).l1.iloc[0]
    # > will be either `NEGATED` or `NEGMIR`
    #   both are shortened to just `NEG` for the keys in their separate dataframes
    # > replace to avoid ambiguity in `key` values when combined
    #! some filtering relies on 'NEG', so have to keep that prefix
    index_update = pat_name or ('NEGmir' if neg_env_name.endswith('MIR') else 'NEGany')
    df.index = df.index.str.replace('NEG', index_update)
    return df
```


```python
POLAR_DIR = AM_DF_DIR.joinpath('polar')

globs = {'RBdirect': f'*{TAG}*min{SET_FLOOR}x*parq',
        'mirror': f'*{TAG}*min{MIR_FLOOR}x*parq'}

adv_am_paths = {p.name: tuple(p.joinpath('adv/extra').glob(globs[p.name])) for p in POLAR_DIR.iterdir()}

bash_cmd = 'bash /share/compling/projects/sanpi/script/run_assoc.sh'
for key, paths_tuple in adv_am_paths.items():
    if not paths_tuple:
        err_message = (
            f'Provided SET_FLOOR value, {SET_FLOOR}, has no corresponding processing. Change the value or run:\n'
            + f'  $ {bash_cmd} -m {SET_FLOOR}'
            ) if key=='RBdirect' else (
                f'Provided MIR_FLOOR value, {MIR_FLOOR}, has no corresponding processing. Change the value or run:\n'
                + f'  $ {bash_cmd} -m {MIR_FLOOR} -P "mirror"')
        raise ValueError(err_message)

    adv_am_paths[key] = paths_tuple[0]

pprint(adv_am_paths)
```

    {'RBdirect': PosixPath('/share/compling/projects/sanpi/results/assoc_df/polar/RBdirect/adv/extra/polarized-adv_NEQ-direct_min5000x_extra.parq'),
     'mirror': PosixPath('/share/compling/projects/sanpi/results/assoc_df/polar/mirror/adv/extra/polarized-adv_NEQ-mirror_min500x_extra.parq')}



```python
setdiff_adv = update_index(pd.read_parquet(adv_am_paths['RBdirect'], columns=FOCUS))
mirror_adv = update_index(pd.read_parquet(adv_am_paths['mirror'], columns=FOCUS))
nb_show_table(setdiff_adv.sample(min(6,K)).sort_values('conservative_log_ratio', ascending=False))
```

    
    |                      |     `f` |   `dP1` |   `P1` |   `LRC` |       `G2` |   `odds_r_disc` |    `t` |       `N` |      `f1` |    `f2` |    `exp_f` |   `unexp_f` | `l1`       | `l2`      |
    |:---------------------|--------:|--------:|-------:|--------:|-----------:|----------------:|-------:|----------:|----------:|--------:|-----------:|------------:|:-----------|:----------|
    | **COM~now**          |  19,616 |    0.46 |   0.96 |    4.27 |  21,346.76 |            1.36 |  66.99 | 6,347,364 | 3,173,552 |  20,468 |  10,233.58 |    9,382.42 | COMPLEMENT | now       |
    | **COM~most**         | 325,174 |    0.47 |   0.94 |    4.03 | 344,851.77 |            1.27 | 268.29 | 6,347,364 | 3,173,552 | 344,378 | 172,181.95 |  152,992.05 | COMPLEMENT | most      |
    | **NEGany~remotely**  |   5,661 |    0.42 |   0.92 |    3.16 |   5,075.57 |            1.05 |  34.30 | 6,347,364 | 3,173,660 |   6,161 |   3,080.48 |    2,580.52 | NEGATED    | remotely  |
    | **COM~very**         | 412,871 |    0.20 |   0.69 |    1.10 |  93,225.19 |            0.37 | 173.58 | 6,347,364 | 3,173,552 | 602,694 | 301,334.66 |  111,536.34 | COMPLEMENT | very      |
    | **NEGany~currently** |   7,077 |    0.08 |   0.58 |    0.32 |     298.75 |            0.14 |  11.33 | 6,347,364 | 3,173,660 |  12,247 |   6,123.46 |      953.54 | NEGATED    | currently |
    | **NEGany~already**   |   5,637 |   -0.16 |   0.34 |   -0.81 |  -1,639.98 |           -0.28 | -34.22 | 6,347,364 | 3,173,660 |  16,412 |   8,205.94 |   -2,568.94 | NEGATED    | already   |
    



|                           |    `f` |   `dP1` |   `dP1_simple` |   `LRC` |       `G2` |   `odds_r_disc` |     `t` |       `N` |      `f1` |   `f2` |   `exp_f` |   `unexp_f` | `l1`       | `l2`           |
|:--------------------------|-------:|--------:|---------------:|--------:|-----------:|----------------:|--------:|----------:|----------:|-------:|----------:|------------:|:-----------|:---------------|
| **COM~certainly**         |  4,454 |    0.47 |           0.97 |    4.34 |   5,085.46 |            1.48 |   32.28 | 6,347,364 | 3,173,552 |  4,600 |  2,299.91 |    2,154.09 | COMPLEMENT | certainly      |
| **COM~partially**         |  1,027 |    0.41 |           0.91 |    2.59 |     876.99 |            1.00 |   14.42 | 6,347,364 | 3,173,552 |  1,130 |    564.98 |      462.02 | COMPLEMENT | partially      |
| **NEGany~overwhelmingly** |    905 |   -0.10 |           0.40 |   -0.24 |     -81.68 |           -0.17 |   -7.08 | 6,347,364 | 3,173,660 |  2,236 |  1,117.99 |     -212.99 | NEGATED    | overwhelmingly |
| **COM~financially**       |  2,090 |   -0.10 |           0.40 |   -0.39 |    -224.93 |           -0.18 |  -11.85 | 6,347,364 | 3,173,552 |  5,264 |  2,631.89 |     -541.89 | COMPLEMENT | financially    |
| **NEGany~ultimately**     |    509 |   -0.26 |           0.24 |   -1.32 |    -632.42 |           -0.51 |  -25.22 | 6,347,364 | 3,173,660 |  2,156 |  1,077.99 |     -568.99 | NEGATED    | ultimately     |
| **COM~particularly**      | 20,635 |   -0.23 |           0.27 |   -1.37 | -16,788.46 |           -0.43 | -121.44 | 6,347,364 | 3,173,552 | 76,162 | 38,079.44 |  -17,444.44 | COMPLEMENT | particularly   |




```python
nb_show_table(mirror_adv.sample(min(6,K)).sort_values('conservative_log_ratio', ascending=False))
```

    
    |                  |   `f` |   `dP1` |   `P1` |   `LRC` |     `G2` |   `odds_r_disc` |    `t` |     `N` |    `f1` |   `f2` |   `exp_f` |   `unexp_f` | `l1`   | `l2`     |
    |:-----------------|------:|--------:|-------:|--------:|---------:|----------------:|-------:|--------:|--------:|-------:|----------:|------------:|:-------|:---------|
    | **POS~somewhat** |   937 |    0.48 |   0.98 |    4.34 | 1,160.12 |            1.76 |  15.04 | 583,470 | 291,729 |    953 |    476.49 |      460.51 | POSMIR | somewhat |
    | **NEGmir~any**   | 1,066 |    0.47 |   0.97 |    4.00 | 1,252.02 |            1.56 |  15.88 | 583,470 | 291,732 |  1,095 |    547.49 |      518.51 | NEGMIR | any      |
    | **POS~almost**   | 1,065 |    0.46 |   0.96 |    3.67 | 1,184.44 |            1.41 |  15.69 | 583,470 | 291,729 |  1,106 |    552.99 |      512.01 | POSMIR | almost   |
    | **POS~equally**  | 1,538 |    0.46 |   0.95 |    3.60 | 1,642.68 |            1.32 |  18.68 | 583,470 | 291,729 |  1,611 |    805.48 |      732.52 | POSMIR | equally  |
    | **POS~slightly** | 1,513 |    0.44 |   0.93 |    3.16 | 1,465.03 |            1.15 |  18.09 | 583,470 | 291,729 |  1,619 |    809.48 |      703.52 | POSMIR | slightly |
    | **POS~terribly** |   637 |   -0.21 |   0.29 |   -0.97 |  -406.44 |           -0.39 | -18.42 | 583,470 | 291,729 |  2,204 |  1,101.98 |     -464.98 | POSMIR | terribly |
    



|                  |    `f` |   `dP1` |   `dP1_simple` |   `LRC` |      `G2` |   `odds_r_disc` |    `t` |     `N` |    `f1` |   `f2` |   `exp_f` |   `unexp_f` | `l1`   | `l2`     |
|:-----------------|-------:|--------:|---------------:|--------:|----------:|----------------:|-------:|--------:|--------:|-------:|----------:|------------:|:-------|:---------|
| **POS~slightly** |  1,513 |    0.44 |           0.93 |    3.16 |  1,465.03 |            1.15 |  18.09 | 583,470 | 291,729 |  1,619 |    809.48 |      703.52 | POSMIR | slightly |
| **POS~very**     | 36,427 |    0.33 |           0.80 |    1.95 | 19,317.81 |            0.66 |  72.08 | 583,470 | 291,729 | 45,341 | 22,670.03 |   13,756.97 | POSMIR | very     |
| **POS~utterly**  |    435 |    0.34 |           0.84 |    1.55 |    257.92 |            0.71 |   8.39 | 583,470 | 291,729 |    520 |    259.99 |      175.01 | POSMIR | utterly  |
| **POS~mentally** |    369 |    0.30 |           0.80 |    1.19 |    176.58 |            0.60 |   7.18 | 583,470 | 291,729 |    462 |    231.00 |      138.00 | POSMIR | mentally |
| **NEGmir~as**    | 31,169 |    0.18 |           0.66 |    0.89 |  5,411.20 |            0.31 |  43.02 | 583,470 | 291,732 | 47,150 | 23,574.76 |    7,594.24 | NEGMIR | as       |
| **POS~overly**   |    589 |   -0.20 |           0.30 |   -0.89 |   -336.13 |           -0.37 | -16.54 | 583,470 | 291,729 |  1,981 |    990.48 |     -401.48 | POSMIR | overly   |



## Calculate "Most Negative" Adverbs for each Polarity Approximation


```python
def get_top_vals(df: pd.DataFrame,
                 index_like: str = 'NEG',
                 metric_filter: str | list = ['am_p1_given2', 'conservative_log_ratio'],
                 k: int = 10,
                 val_col: str = None,
                 ignore_neg_adv: bool = True):
    env_df = df.copy().loc[df.conservative_log_ratio >=
                           1].filter(like=index_like, axis=0)
    if ignore_neg_adv:
        env_df = env_df.loc[~df.l2.isin(
            ("n't", 'not', 'barely', 'never', 'no', 'none')), :]
    if isinstance(metric_filter, str):
        metric_filter = [metric_filter]

    top = pd.concat([env_df.nlargest(k, m) for m in metric_filter]
                    ).drop_duplicates(keep='first')

    if val_col:
        top = top[[val_col] + metric_filter]

    return top.sort_values(metric_filter, ascending=False)


[setdiff_top15, mirror_top15] = [
    get_top_vals(adv_df, k=15)
    for adv_df in (setdiff_adv, mirror_adv)
]

```


```python
nb_show_table(setdiff_top15.reset_index().filter(regex=r'^[^l]'))
```

    
    |        | `key`              |     `f` |   `dP1` |   `P1` |   `LRC` |       `G2` |   `odds_r_disc` |    `t` |       `N` |      `f1` |    `f2` |    `exp_f` |   `unexp_f` |
    |:-------|:-------------------|--------:|--------:|-------:|--------:|-----------:|----------------:|-------:|----------:|----------:|--------:|-----------:|------------:|
    | **1**  | NEGany~that        | 164,768 |    0.50 |   0.99 |    6.26 | 214,504.57 |            1.96 | 200.61 | 6,347,364 | 3,173,660 | 166,676 |  83,337.42 |   81,430.58 |
    | **2**  | NEGany~necessarily |  42,595 |    0.50 |   0.99 |    6.77 |  56,251.14 |            2.17 | 102.49 | 6,347,364 | 3,173,660 |  42,886 |  21,442.85 |   21,152.15 |
    | **3**  | NEGany~exactly     |  43,813 |    0.49 |   0.98 |    5.71 |  54,870.72 |            1.81 | 103.01 | 6,347,364 | 3,173,660 |  44,503 |  22,251.35 |   21,561.65 |
    | **4**  | NEGany~immediately |  56,099 |    0.47 |   0.97 |    4.68 |  63,920.54 |            1.47 | 114.33 | 6,347,364 | 3,173,660 |  58,040 |  29,019.80 |   27,079.20 |
    | **5**  | NEGany~yet         |  51,867 |    0.47 |   0.96 |    4.52 |  57,900.12 |            1.42 | 109.45 | 6,347,364 | 3,173,660 |  53,881 |  26,940.31 |   24,926.69 |
    | **6**  | NEGany~any         |  15,384 |    0.45 |   0.95 |    3.91 |  15,851.55 |            1.26 |  58.57 | 6,347,364 | 3,173,660 |  16,238 |   8,118.94 |    7,265.06 |
    | **7**  | NEGany~remotely    |   5,661 |    0.42 |   0.92 |    3.16 |   5,075.57 |            1.05 |  34.30 | 6,347,364 | 3,173,660 |   6,161 |   3,080.48 |    2,580.52 |
    | **8**  | NEGany~terribly    |  17,949 |    0.41 |   0.91 |    3.10 |  15,186.21 |            0.99 |  60.07 | 6,347,364 | 3,173,660 |  19,802 |   9,900.93 |    8,048.07 |
    | **9**  | NEGany~only        | 113,502 |    0.39 |   0.89 |    2.89 |  88,060.81 |            0.90 | 146.68 | 6,347,364 | 3,173,660 | 128,174 |  64,086.56 |   49,415.44 |
    | **10** | NEGany~overly      |  24,613 |    0.38 |   0.87 |    2.67 |  17,861.62 |            0.85 |  67.23 | 6,347,364 | 3,173,660 |  28,132 |  14,065.90 |   10,547.10 |
    | **11** | NEGany~entirely    |  63,321 |    0.37 |   0.87 |    2.66 |  45,040.32 |            0.83 | 106.96 | 6,347,364 | 3,173,660 |  72,811 |  36,405.25 |   26,915.75 |
    | **12** | NEGany~as          | 531,731 |    0.35 |   0.81 |    2.07 | 301,508.90 |            0.69 | 279.31 | 6,347,364 | 3,173,660 | 656,123 | 328,059.23 |  203,671.77 |
    | **13** | NEGany~merely      |   5,918 |    0.34 |   0.84 |    2.19 |   3,642.62 |            0.73 |  31.33 | 6,347,364 | 3,173,660 |   7,016 |   3,507.98 |    2,410.02 |
    | **14** | NEGany~always      | 103,883 |    0.32 |   0.82 |    2.12 |  56,744.90 |            0.67 | 125.40 | 6,347,364 | 3,173,660 | 126,929 |  63,464.06 |   40,418.94 |
    | **15** | NEGany~directly    |   8,197 |    0.31 |   0.81 |    1.89 |   4,162.98 |            0.63 |  34.56 | 6,347,364 | 3,173,660 |  10,136 |   5,067.96 |    3,129.04 |
    


### `NEQ` 15 Most Negatively Associated Adverbs for superset data (
    
_Absent Negative_ approximation) as ranked by $\Delta P(1|2)$ (`dP1`) and $LRC$


|        | `key`              |     `f` |   `dP1` |   `P1` |   `LRC` |       `G2` |   `odds_r_disc` |    `t` |       `N` |      `f1` |    `f2` |    `exp_f` |   `unexp_f` |
|:-------|:-------------------|--------:|--------:|-------:|--------:|-----------:|----------------:|-------:|----------:|----------:|--------:|-----------:|------------:|
| **1**  | NEGany~that        | 164,768 |    0.50 |   0.99 |    6.26 | 214,504.57 |            1.96 | 200.61 | 6,347,364 | 3,173,660 | 166,676 |  83,337.42 |   81,430.58 |
| **2**  | NEGany~necessarily |  42,595 |    0.50 |   0.99 |    6.77 |  56,251.14 |            2.17 | 102.49 | 6,347,364 | 3,173,660 |  42,886 |  21,442.85 |   21,152.15 |
| **3**  | NEGany~exactly     |  43,813 |    0.49 |   0.98 |    5.71 |  54,870.72 |            1.81 | 103.01 | 6,347,364 | 3,173,660 |  44,503 |  22,251.35 |   21,561.65 |
| **4**  | NEGany~immediately |  56,099 |    0.47 |   0.97 |    4.68 |  63,920.54 |            1.47 | 114.33 | 6,347,364 | 3,173,660 |  58,040 |  29,019.80 |   27,079.20 |
| **5**  | NEGany~yet         |  51,867 |    0.47 |   0.96 |    4.52 |  57,900.12 |            1.42 | 109.45 | 6,347,364 | 3,173,660 |  53,881 |  26,940.31 |   24,926.69 |
| **6**  | NEGany~any         |  15,384 |    0.45 |   0.95 |    3.91 |  15,851.55 |            1.26 |  58.57 | 6,347,364 | 3,173,660 |  16,238 |   8,118.94 |    7,265.06 |
| **7**  | NEGany~remotely    |   5,661 |    0.42 |   0.92 |    3.16 |   5,075.57 |            1.05 |  34.30 | 6,347,364 | 3,173,660 |   6,161 |   3,080.48 |    2,580.52 |
| **8**  | NEGany~terribly    |  17,949 |    0.41 |   0.91 |    3.10 |  15,186.21 |            0.99 |  60.07 | 6,347,364 | 3,173,660 |  19,802 |   9,900.93 |    8,048.07 |
| **9**  | NEGany~only        | 113,502 |    0.39 |   0.89 |    2.89 |  88,060.81 |            0.90 | 146.68 | 6,347,364 | 3,173,660 | 128,174 |  64,086.56 |   49,415.44 |
| **10** | NEGany~overly      |  24,613 |    0.38 |   0.87 |    2.67 |  17,861.62 |            0.85 |  67.23 | 6,347,364 | 3,173,660 |  28,132 |  14,065.90 |   10,547.10 |
| **11** | NEGany~entirely    |  63,321 |    0.37 |   0.87 |    2.66 |  45,040.32 |            0.83 | 106.96 | 6,347,364 | 3,173,660 |  72,811 |  36,405.25 |   26,915.75 |
| **12** | NEGany~as          | 531,731 |    0.35 |   0.81 |    2.07 | 301,508.90 |            0.69 | 279.31 | 6,347,364 | 3,173,660 | 656,123 | 328,059.23 |  203,671.77 |
| **13** | NEGany~merely      |   5,918 |    0.34 |   0.84 |    2.19 |   3,642.62 |            0.73 |  31.33 | 6,347,364 | 3,173,660 |   7,016 |   3,507.98 |    2,410.02 |
| **14** | NEGany~always      | 103,883 |    0.32 |   0.82 |    2.12 |  56,744.90 |            0.67 | 125.40 | 6,347,364 | 3,173,660 | 126,929 |  63,464.06 |   40,418.94 |
| **15** | NEGany~directly    |   8,197 |    0.31 |   0.81 |    1.89 |   4,162.98 |            0.63 |  34.56 | 6,347,364 | 3,173,660 |  10,136 |   5,067.96 |    3,129.04 |





```python
nb_show_table(mirror_top15.reset_index().filter(regex=r'^[^l]'))
```

    
    |        | `key`               |   `f` |   `dP1` |   `P1` |   `LRC` |     `G2` |   `odds_r_disc` |   `t` |     `N` |    `f1` |   `f2` |   `exp_f` |   `unexp_f` |
    |:-------|:--------------------|------:|--------:|-------:|--------:|---------:|----------------:|------:|--------:|--------:|-------:|----------:|------------:|
    | **1**  | NEGmir~ever         | 4,709 |    0.49 |   0.98 |    5.17 | 5,883.26 |            1.79 | 33.75 | 583,470 | 291,732 |  4,786 |  2,392.98 |    2,316.02 |
    | **2**  | NEGmir~any          | 1,066 |    0.47 |   0.97 |    4.00 | 1,252.02 |            1.56 | 15.88 | 583,470 | 291,732 |  1,095 |    547.49 |      518.51 |
    | **3**  | NEGmir~necessarily  |   963 |    0.47 |   0.97 |    3.86 | 1,114.70 |            1.52 | 15.05 | 583,470 | 291,732 |    992 |    495.99 |      467.01 |
    | **4**  | NEGmir~that         | 4,308 |    0.45 |   0.94 |    3.66 | 4,405.21 |            1.24 | 30.91 | 583,470 | 291,732 |  4,559 |  2,279.48 |    2,028.52 |
    | **5**  | NEGmir~remotely     | 1,840 |    0.44 |   0.94 |    3.37 | 1,849.23 |            1.21 | 20.13 | 583,470 | 291,732 |  1,953 |    976.49 |      863.51 |
    | **6**  | NEGmir~exactly      |   813 |    0.44 |   0.94 |    2.95 |   790.27 |            1.16 | 13.27 | 583,470 | 291,732 |    869 |    434.50 |      378.50 |
    | **7**  | NEGmir~particularly | 9,243 |    0.43 |   0.92 |    3.30 | 8,516.58 |            1.08 | 43.98 | 583,470 | 291,732 | 10,029 |  5,014.45 |    4,228.55 |
    | **8**  | NEGmir~inherently   | 2,864 |    0.36 |   0.86 |    2.24 | 1,899.59 |            0.78 | 22.29 | 583,470 | 291,732 |  3,342 |  1,670.98 |    1,193.02 |
    | **9**  | NEGmir~especially   | 1,569 |    0.28 |   0.78 |    1.43 |   658.82 |            0.54 | 14.13 | 583,470 | 291,732 |  2,019 |  1,009.49 |      559.51 |
    | **10** | NEGmir~fully        | 1,664 |    0.23 |   0.73 |    1.08 |   492.40 |            0.43 | 12.75 | 583,470 | 291,732 |  2,288 |  1,143.99 |      520.01 |
    


### `NEQ` 15 Most Negatively Associated Adverbs for `mirror` subset 

(_Present Positive_ approximation) as ranked by $\Delta P(1|2)$ (`dP1`) and $LRC$

|        | `key`               |   `f` |   `dP1` |   `P1` |   `LRC` |     `G2` |   `odds_r_disc` |   `t` |     `N` |    `f1` |   `f2` |   `exp_f` |   `unexp_f` |
|:-------|:--------------------|------:|--------:|-------:|--------:|---------:|----------------:|------:|--------:|--------:|-------:|----------:|------------:|
| **1**  | NEGmir~ever         | 4,709 |    0.49 |   0.98 |    5.17 | 5,883.26 |            1.79 | 33.75 | 583,470 | 291,732 |  4,786 |  2,392.98 |    2,316.02 |
| **2**  | NEGmir~any          | 1,066 |    0.47 |   0.97 |    4.00 | 1,252.02 |            1.56 | 15.88 | 583,470 | 291,732 |  1,095 |    547.49 |      518.51 |
| **3**  | NEGmir~necessarily  |   963 |    0.47 |   0.97 |    3.86 | 1,114.70 |            1.52 | 15.05 | 583,470 | 291,732 |    992 |    495.99 |      467.01 |
| **4**  | NEGmir~that         | 4,308 |    0.45 |   0.94 |    3.66 | 4,405.21 |            1.24 | 30.91 | 583,470 | 291,732 |  4,559 |  2,279.48 |    2,028.52 |
| **5**  | NEGmir~remotely     | 1,840 |    0.44 |   0.94 |    3.37 | 1,849.23 |            1.21 | 20.13 | 583,470 | 291,732 |  1,953 |    976.49 |      863.51 |
| **6**  | NEGmir~exactly      |   813 |    0.44 |   0.94 |    2.95 |   790.27 |            1.16 | 13.27 | 583,470 | 291,732 |    869 |    434.50 |      378.50 |
| **7**  | NEGmir~particularly | 9,243 |    0.43 |   0.92 |    3.30 | 8,516.58 |            1.08 | 43.98 | 583,470 | 291,732 | 10,029 |  5,014.45 |    4,228.55 |
| **8**  | NEGmir~inherently   | 2,864 |    0.36 |   0.86 |    2.24 | 1,899.59 |            0.78 | 22.29 | 583,470 | 291,732 |  3,342 |  1,670.98 |    1,193.02 |
| **9**  | NEGmir~especially   | 1,569 |    0.28 |   0.78 |    1.43 |   658.82 |            0.54 | 14.13 | 583,470 | 291,732 |  2,019 |  1,009.49 |      559.51 |
| **10** | NEGmir~fully        | 1,664 |    0.23 |   0.73 |    1.08 |   492.40 |            0.43 | 12.75 | 583,470 | 291,732 |  2,288 |  1,143.99 |      520.01 |



### Or here, the least "negative"/most "non-negative"


```python
def show_top_positive(adv_df, 
                      k:int=15, 
                      filter_and_sort:list=['conservative_log_ratio', 
                                            'am_log_likelihood', 
                                            'am_p1_given2']):
    
    _l1 = adv_df.filter(like='O', axis=0).l1.iat[0].lower().strip()
    _N = int(adv_df.N.iat[0])
    ie = '(`set_diff`, $*\complement_{N^+}$)' if _l1.startswith("com") else '(`mirror`, $@P$)'
    print(f'#### Adverbs in top {k}',
          r'for $LRC$, $G^2$, and $\Delta P(\texttt{env}|\texttt{adv})$',
          f'measuring association with *{_l1.capitalize()}* Environments {ie}', 
          end='\n'*2)
    print(f'Total Tokens in dataset: $N = {_N:,}$')
    nb_show_table(
        get_top_vals(
            adv_df.filter(items=FOCUS), 
            k=k,
            metric_filter=filter_and_sort,
            index_like='O',  # should match "POS" & "COM", but neither "NEG*"
            ).round(2).sort_values(filter_and_sort, ascending=False).set_index('l2').drop(['N', 'l1'], axis=1)
    )
    
# All data
show_top_positive(setdiff_adv, k=15)
```

    #### Adverbs in top 15 for $LRC$, $G^2$, and $\Delta P(\texttt{env}|\texttt{adv})$ measuring association with *Complement* Environments (`set_diff`, $*\complement_{N^+}$)
    
    Total Tokens in dataset: $N = 6,347,364$
    
    |                  |        `f` |   `dP1` |   `P1` |   `LRC` |       `G2` |   `odds_r_disc` |    `t` |         `f1` |       `f2` |    `exp_f` |   `unexp_f` |
    |:-----------------|-----------:|--------:|-------:|--------:|-----------:|----------------:|-------:|-------------:|-----------:|-----------:|------------:|
    | **increasingly** |  17,147.00 |    0.50 |   1.00 |    7.07 |  22,976.10 |            2.37 |  65.20 | 3,173,552.00 |  17,220.00 |   8,609.65 |    8,537.35 |
    | **relatively**   |  26,303.00 |    0.49 |   0.99 |    5.97 |  33,565.49 |            1.92 |  80.11 | 3,173,552.00 |  26,621.00 |  13,309.95 |   12,993.05 |
    | **almost**       |  19,843.00 |    0.48 |   0.98 |    5.28 |  24,212.21 |            1.70 |  69.03 | 3,173,552.00 |  20,240.00 |  10,119.59 |    9,723.41 |
    | **mostly**       |   9,295.00 |    0.48 |   0.98 |    5.14 |  11,346.01 |            1.71 |  47.26 | 3,173,552.00 |   9,478.00 |   4,738.81 |    4,556.19 |
    | **seemingly**    |   7,411.00 |    0.48 |   0.98 |    5.07 |   9,037.07 |            1.70 |  42.19 | 3,173,552.00 |   7,558.00 |   3,778.85 |    3,632.15 |
    | **fairly**       |  17,040.00 |    0.48 |   0.98 |    5.00 |  20,307.10 |            1.61 |  63.67 | 3,173,552.00 |  17,457.00 |   8,728.14 |    8,311.86 |
    | **pretty**       |  68,498.00 |    0.48 |   0.97 |    4.96 |  80,502.90 |            1.55 | 127.13 | 3,173,552.00 |  70,454.00 |  35,225.56 |   33,272.44 |
    | **largely**      |   7,916.00 |    0.48 |   0.98 |    4.89 |   9,476.32 |            1.63 |  43.45 | 3,173,552.00 |   8,101.00 |   4,050.33 |    3,865.67 |
    | **rather**       |  16,570.00 |    0.47 |   0.97 |    4.75 |  19,253.20 |            1.53 |  62.47 | 3,173,552.00 |  17,059.00 |   8,529.15 |    8,040.85 |
    | **sometimes**    |   6,493.00 |    0.47 |   0.97 |    4.58 |   7,549.67 |            1.54 |  39.12 | 3,173,552.00 |   6,682.00 |   3,340.86 |    3,152.14 |
    | **also**         |  48,143.00 |    0.46 |   0.96 |    4.44 |  53,221.81 |            1.40 | 105.23 | 3,173,552.00 |  50,109.00 |  25,053.47 |   23,089.53 |
    | **now**          |  19,616.00 |    0.46 |   0.96 |    4.27 |  21,346.76 |            1.36 |  66.99 | 3,173,552.00 |  20,468.00 |  10,233.58 |    9,382.42 |
    | **probably**     |   5,724.00 |    0.46 |   0.96 |    4.14 |   6,291.06 |            1.39 |  36.28 | 3,173,552.00 |   5,958.00 |   2,978.88 |    2,745.12 |
    | **somewhat**     |  12,992.00 |    0.46 |   0.95 |    4.10 |  13,877.77 |            1.33 |  54.30 | 3,173,552.00 |  13,607.00 |   6,803.22 |    6,188.78 |
    | **potentially**  |   8,708.00 |    0.46 |   0.96 |    4.07 |   9,340.83 |            1.34 |  44.50 | 3,173,552.00 |   9,111.00 |   4,555.31 |    4,152.69 |
    | **most**         | 325,174.00 |    0.47 |   0.94 |    4.03 | 344,851.77 |            1.27 | 268.29 | 3,173,552.00 | 344,378.00 | 172,181.95 |  152,992.05 |
    | **still**        |  35,199.00 |    0.45 |   0.95 |    3.99 |  36,320.19 |            1.26 |  88.57 | 3,173,552.00 |  37,164.00 |  18,581.24 |   16,617.76 |
    | **highly**       |  33,581.00 |    0.44 |   0.93 |    3.65 |  32,384.35 |            1.15 |  85.07 | 3,173,552.00 |  35,986.00 |  17,992.26 |   15,588.74 |
    | **extremely**    |  41,289.00 |    0.41 |   0.91 |    3.24 |  35,860.38 |            1.02 |  91.69 | 3,173,552.00 |  45,317.00 |  22,657.57 |   18,631.43 |
    | **less**         |  52,587.00 |    0.30 |   0.80 |    1.90 |  25,036.58 |            0.60 |  85.34 | 3,173,552.00 |  66,037.00 |  33,017.15 |   19,569.85 |
    | **more**         | 392,003.00 |    0.23 |   0.71 |    1.25 | 107,688.86 |            0.42 | 183.76 | 3,173,552.00 | 553,922.00 | 276,949.66 |  115,053.34 |
    | **very**         | 412,871.00 |    0.20 |   0.69 |    1.10 |  93,225.19 |            0.37 | 173.58 | 3,173,552.00 | 602,694.00 | 301,334.66 |  111,536.34 |
    


#### Adverbs in top 15 for $LRC$, $G^2$, and $\Delta P(\texttt{env}|\texttt{adv})$ measuring association with *Complement* Environments (`set_diff`, $*\complement_{N^+}$)

Total Tokens in dataset: $N = 6,347,364$

|                  |        `f` |   `dP1` |   `P1` |   `LRC` |       `G2` |   `odds_r_disc` |    `t` |         `f1` |       `f2` |    `exp_f` |   `unexp_f` |
|:-----------------|-----------:|--------:|-------:|--------:|-----------:|----------------:|-------:|-------------:|-----------:|-----------:|------------:|
| **increasingly** |  17,147.00 |    0.50 |   1.00 |    7.07 |  22,976.10 |            2.37 |  65.20 | 3,173,552.00 |  17,220.00 |   8,609.65 |    8,537.35 |
| **relatively**   |  26,303.00 |    0.49 |   0.99 |    5.97 |  33,565.49 |            1.92 |  80.11 | 3,173,552.00 |  26,621.00 |  13,309.95 |   12,993.05 |
| **almost**       |  19,843.00 |    0.48 |   0.98 |    5.28 |  24,212.21 |            1.70 |  69.03 | 3,173,552.00 |  20,240.00 |  10,119.59 |    9,723.41 |
| **mostly**       |   9,295.00 |    0.48 |   0.98 |    5.14 |  11,346.01 |            1.71 |  47.26 | 3,173,552.00 |   9,478.00 |   4,738.81 |    4,556.19 |
| **seemingly**    |   7,411.00 |    0.48 |   0.98 |    5.07 |   9,037.07 |            1.70 |  42.19 | 3,173,552.00 |   7,558.00 |   3,778.85 |    3,632.15 |
| **fairly**       |  17,040.00 |    0.48 |   0.98 |    5.00 |  20,307.10 |            1.61 |  63.67 | 3,173,552.00 |  17,457.00 |   8,728.14 |    8,311.86 |
| **pretty**       |  68,498.00 |    0.48 |   0.97 |    4.96 |  80,502.90 |            1.55 | 127.13 | 3,173,552.00 |  70,454.00 |  35,225.56 |   33,272.44 |
| **largely**      |   7,916.00 |    0.48 |   0.98 |    4.89 |   9,476.32 |            1.63 |  43.45 | 3,173,552.00 |   8,101.00 |   4,050.33 |    3,865.67 |
| **rather**       |  16,570.00 |    0.47 |   0.97 |    4.75 |  19,253.20 |            1.53 |  62.47 | 3,173,552.00 |  17,059.00 |   8,529.15 |    8,040.85 |
| **sometimes**    |   6,493.00 |    0.47 |   0.97 |    4.58 |   7,549.67 |            1.54 |  39.12 | 3,173,552.00 |   6,682.00 |   3,340.86 |    3,152.14 |
| **also**         |  48,143.00 |    0.46 |   0.96 |    4.44 |  53,221.81 |            1.40 | 105.23 | 3,173,552.00 |  50,109.00 |  25,053.47 |   23,089.53 |
| **now**          |  19,616.00 |    0.46 |   0.96 |    4.27 |  21,346.76 |            1.36 |  66.99 | 3,173,552.00 |  20,468.00 |  10,233.58 |    9,382.42 |
| **probably**     |   5,724.00 |    0.46 |   0.96 |    4.14 |   6,291.06 |            1.39 |  36.28 | 3,173,552.00 |   5,958.00 |   2,978.88 |    2,745.12 |
| **somewhat**     |  12,992.00 |    0.46 |   0.95 |    4.10 |  13,877.77 |            1.33 |  54.30 | 3,173,552.00 |  13,607.00 |   6,803.22 |    6,188.78 |
| **potentially**  |   8,708.00 |    0.46 |   0.96 |    4.07 |   9,340.83 |            1.34 |  44.50 | 3,173,552.00 |   9,111.00 |   4,555.31 |    4,152.69 |
| **most**         | 325,174.00 |    0.47 |   0.94 |    4.03 | 344,851.77 |            1.27 | 268.29 | 3,173,552.00 | 344,378.00 | 172,181.95 |  152,992.05 |
| **still**        |  35,199.00 |    0.45 |   0.95 |    3.99 |  36,320.19 |            1.26 |  88.57 | 3,173,552.00 |  37,164.00 |  18,581.24 |   16,617.76 |
| **highly**       |  33,581.00 |    0.44 |   0.93 |    3.65 |  32,384.35 |            1.15 |  85.07 | 3,173,552.00 |  35,986.00 |  17,992.26 |   15,588.74 |
| **extremely**    |  41,289.00 |    0.41 |   0.91 |    3.24 |  35,860.38 |            1.02 |  91.69 | 3,173,552.00 |  45,317.00 |  22,657.57 |   18,631.43 |
| **less**         |  52,587.00 |    0.30 |   0.80 |    1.90 |  25,036.58 |            0.60 |  85.34 | 3,173,552.00 |  66,037.00 |  33,017.15 |   19,569.85 |
| **more**         | 392,003.00 |    0.23 |   0.71 |    1.25 | 107,688.86 |            0.42 | 183.76 | 3,173,552.00 | 553,922.00 | 276,949.66 |  115,053.34 |
| **very**         | 412,871.00 |    0.20 |   0.69 |    1.10 |  93,225.19 |            0.37 | 173.58 | 3,173,552.00 | 602,694.00 | 301,334.66 |  111,536.34 |




```python
# Mirror Data ~ explicitly positive ~ positive trigger present
show_top_positive(mirror_adv, k=15)
```

    #### Adverbs in top 15 for $LRC$, $G^2$, and $\Delta P(\texttt{env}|\texttt{adv})$ measuring association with *Posmir* Environments (`mirror`, $@P$)
    
    Total Tokens in dataset: $N = 583,470$
    
    |                |       `f` |   `dP1` |   `P1` |   `LRC` |      `G2` |   `odds_r_disc` |   `t` |       `f1` |      `f2` |   `exp_f` |   `unexp_f` |
    |:---------------|----------:|--------:|-------:|--------:|----------:|----------------:|------:|-----------:|----------:|----------:|------------:|
    | **pretty**     |  5,049.00 |    0.48 |   0.98 |    4.71 |  6,024.97 |            1.61 | 34.64 | 291,729.00 |  5,176.00 |  2,587.95 |    2,461.05 |
    | **rather**     |  1,753.00 |    0.48 |   0.98 |    4.64 |  2,158.90 |            1.73 | 20.55 | 291,729.00 |  1,785.00 |    892.48 |      860.52 |
    | **plain**      |  1,001.00 |    0.48 |   0.98 |    4.38 |  1,240.10 |            1.76 | 15.55 | 291,729.00 |  1,018.00 |    508.99 |      492.01 |
    | **somewhat**   |    937.00 |    0.48 |   0.98 |    4.34 |  1,160.12 |            1.76 | 15.04 | 291,729.00 |    953.00 |    476.49 |      460.51 |
    | **fairly**     |  1,163.00 |    0.48 |   0.98 |    4.31 |  1,413.04 |            1.68 | 16.70 | 291,729.00 |  1,187.00 |    593.49 |      569.51 |
    | **otherwise**  |  1,426.00 |    0.47 |   0.97 |    4.07 |  1,657.11 |            1.53 | 18.33 | 291,729.00 |  1,468.00 |    733.98 |      692.02 |
    | **maybe**      |    546.00 |    0.48 |   0.98 |    3.97 |    677.87 |            1.76 | 11.49 | 291,729.00 |    555.00 |    277.49 |      268.51 |
    | **downright**  |    985.00 |    0.47 |   0.97 |    3.89 |  1,144.00 |            1.53 | 15.23 | 291,729.00 |  1,014.00 |    506.99 |      478.01 |
    | **already**    |    860.00 |    0.47 |   0.97 |    3.76 |    989.13 |            1.50 | 14.20 | 291,729.00 |    887.00 |    443.49 |      416.51 |
    | **relatively** |  1,073.00 |    0.47 |   0.97 |    3.75 |  1,210.84 |            1.45 | 15.80 | 291,729.00 |  1,111.00 |    555.49 |      517.51 |
    | **almost**     |  1,065.00 |    0.46 |   0.96 |    3.67 |  1,184.44 |            1.41 | 15.69 | 291,729.00 |  1,106.00 |    552.99 |      512.01 |
    | **equally**    |  1,538.00 |    0.46 |   0.95 |    3.60 |  1,642.68 |            1.32 | 18.68 | 291,729.00 |  1,611.00 |    805.48 |      732.52 |
    | **perhaps**    |    732.00 |    0.47 |   0.96 |    3.52 |    819.90 |            1.43 | 13.03 | 291,729.00 |    759.00 |    379.49 |      352.51 |
    | **highly**     |  1,848.00 |    0.44 |   0.93 |    3.21 |  1,788.17 |            1.15 | 19.98 | 291,729.00 |  1,978.00 |    988.98 |      859.02 |
    | **slightly**   |  1,513.00 |    0.44 |   0.93 |    3.16 |  1,465.03 |            1.15 | 18.09 | 291,729.00 |  1,619.00 |    809.48 |      703.52 |
    | **extremely**  |  3,575.00 |    0.42 |   0.92 |    3.14 |  3,256.93 |            1.07 | 27.34 | 291,729.00 |  3,881.00 |  1,940.46 |    1,634.54 |
    | **also**       |  1,370.00 |    0.43 |   0.93 |    3.06 |  1,302.12 |            1.13 | 17.13 | 291,729.00 |  1,472.00 |    735.98 |      634.02 |
    | **simply**     |  1,663.00 |    0.43 |   0.93 |    3.04 |  1,549.42 |            1.10 | 18.77 | 291,729.00 |  1,795.00 |    897.48 |      765.52 |
    | **still**      |  2,706.00 |    0.41 |   0.91 |    2.93 |  2,356.33 |            1.02 | 23.50 | 291,729.00 |  2,967.00 |  1,483.47 |    1,222.53 |
    | **incredibly** |  1,826.00 |    0.42 |   0.92 |    2.89 |  1,616.39 |            1.04 | 19.40 | 291,729.00 |  1,994.00 |    996.98 |      829.02 |
    | **just**       |  5,883.00 |    0.39 |   0.89 |    2.70 |  4,553.79 |            0.90 | 33.45 | 291,729.00 |  6,635.00 |  3,317.43 |    2,565.57 |
    | **even**       | 12,382.00 |    0.32 |   0.81 |    1.98 |  6,616.74 |            0.65 | 42.89 | 291,729.00 | 15,220.00 |  7,609.84 |    4,772.16 |
    | **very**       | 36,427.00 |    0.33 |   0.80 |    1.95 | 19,317.81 |            0.66 | 72.08 | 291,729.00 | 45,341.00 | 22,670.03 |   13,756.97 |
    


#### Adverbs in top 15 for $LRC$, $G^2$, and $\Delta P(\texttt{env}|\texttt{adv})$ measuring association with *Posmir* Environments (`mirror`, $@P$)

Total Tokens in dataset: $N = 583,470$

|                |       `f` |   `dP1` |   `P1` |   `LRC` |      `G2` |   `odds_r_disc` |   `t` |       `f1` |      `f2` |   `exp_f` |   `unexp_f` |
|:---------------|----------:|--------:|-------:|--------:|----------:|----------------:|------:|-----------:|----------:|----------:|------------:|
| **pretty**     |  5,049.00 |    0.48 |   0.98 |    4.71 |  6,024.97 |            1.61 | 34.64 | 291,729.00 |  5,176.00 |  2,587.95 |    2,461.05 |
| **rather**     |  1,753.00 |    0.48 |   0.98 |    4.64 |  2,158.90 |            1.73 | 20.55 | 291,729.00 |  1,785.00 |    892.48 |      860.52 |
| **plain**      |  1,001.00 |    0.48 |   0.98 |    4.38 |  1,240.10 |            1.76 | 15.55 | 291,729.00 |  1,018.00 |    508.99 |      492.01 |
| **somewhat**   |    937.00 |    0.48 |   0.98 |    4.34 |  1,160.12 |            1.76 | 15.04 | 291,729.00 |    953.00 |    476.49 |      460.51 |
| **fairly**     |  1,163.00 |    0.48 |   0.98 |    4.31 |  1,413.04 |            1.68 | 16.70 | 291,729.00 |  1,187.00 |    593.49 |      569.51 |
| **otherwise**  |  1,426.00 |    0.47 |   0.97 |    4.07 |  1,657.11 |            1.53 | 18.33 | 291,729.00 |  1,468.00 |    733.98 |      692.02 |
| **maybe**      |    546.00 |    0.48 |   0.98 |    3.97 |    677.87 |            1.76 | 11.49 | 291,729.00 |    555.00 |    277.49 |      268.51 |
| **downright**  |    985.00 |    0.47 |   0.97 |    3.89 |  1,144.00 |            1.53 | 15.23 | 291,729.00 |  1,014.00 |    506.99 |      478.01 |
| **already**    |    860.00 |    0.47 |   0.97 |    3.76 |    989.13 |            1.50 | 14.20 | 291,729.00 |    887.00 |    443.49 |      416.51 |
| **relatively** |  1,073.00 |    0.47 |   0.97 |    3.75 |  1,210.84 |            1.45 | 15.80 | 291,729.00 |  1,111.00 |    555.49 |      517.51 |
| **almost**     |  1,065.00 |    0.46 |   0.96 |    3.67 |  1,184.44 |            1.41 | 15.69 | 291,729.00 |  1,106.00 |    552.99 |      512.01 |
| **equally**    |  1,538.00 |    0.46 |   0.95 |    3.60 |  1,642.68 |            1.32 | 18.68 | 291,729.00 |  1,611.00 |    805.48 |      732.52 |
| **perhaps**    |    732.00 |    0.47 |   0.96 |    3.52 |    819.90 |            1.43 | 13.03 | 291,729.00 |    759.00 |    379.49 |      352.51 |
| **highly**     |  1,848.00 |    0.44 |   0.93 |    3.21 |  1,788.17 |            1.15 | 19.98 | 291,729.00 |  1,978.00 |    988.98 |      859.02 |
| **slightly**   |  1,513.00 |    0.44 |   0.93 |    3.16 |  1,465.03 |            1.15 | 18.09 | 291,729.00 |  1,619.00 |    809.48 |      703.52 |
| **extremely**  |  3,575.00 |    0.42 |   0.92 |    3.14 |  3,256.93 |            1.07 | 27.34 | 291,729.00 |  3,881.00 |  1,940.46 |    1,634.54 |
| **also**       |  1,370.00 |    0.43 |   0.93 |    3.06 |  1,302.12 |            1.13 | 17.13 | 291,729.00 |  1,472.00 |    735.98 |      634.02 |
| **simply**     |  1,663.00 |    0.43 |   0.93 |    3.04 |  1,549.42 |            1.10 | 18.77 | 291,729.00 |  1,795.00 |    897.48 |      765.52 |
| **still**      |  2,706.00 |    0.41 |   0.91 |    2.93 |  2,356.33 |            1.02 | 23.50 | 291,729.00 |  2,967.00 |  1,483.47 |    1,222.53 |
| **incredibly** |  1,826.00 |    0.42 |   0.92 |    2.89 |  1,616.39 |            1.04 | 19.40 | 291,729.00 |  1,994.00 |    996.98 |      829.02 |
| **just**       |  5,883.00 |    0.39 |   0.89 |    2.70 |  4,553.79 |            0.90 | 33.45 | 291,729.00 |  6,635.00 |  3,317.43 |    2,565.57 |
| **even**       | 12,382.00 |    0.32 |   0.81 |    1.98 |  6,616.74 |            0.65 | 42.89 | 291,729.00 | 15,220.00 |  7,609.84 |    4,772.16 |
| **very**       | 36,427.00 |    0.33 |   0.80 |    1.95 | 19,317.81 |            0.66 | 72.08 | 291,729.00 | 45,341.00 | 22,670.03 |   13,756.97 |



## Compile top NEG~adverb associations across both approximation methods

### Define the functions


```python
def load_backup(
                adv_set:set,
    lower_floor: int = None,
                loaded_path: Path = adv_am_paths['RBdirect'], 
                ) -> pd.DataFrame:
    lower_floor = lower_floor or round(SET_FLOOR//3, (-2 if SET_FLOOR//3 > 100 else -1))
    located_paths = tuple(loaded_path.parent.glob(
        f'{TAG}*min{lower_floor}x*parq'))
    try:
        backup_path = located_paths[0] 
    except IndexError: 
        try:
            backup_path = tuple(loaded_path.parent.glob(f'*{TAG}*min5x*parq'))[0]
        except IndexError as e: 
            raise FileNotFoundError('Error. Backup data not found. [in fill_empties()]') from e
    
    backup_df = pd.read_parquet(backup_path, columns=FOCUS, filters=[('l2', 'in', adv_set)])

    backup_df = backup_df.filter(like='NEG', axis=0).reset_index().set_index('l2')
    backup_df.index.name = 'adv'
    
    return backup_df



def uncat(df):
    cats = df.select_dtypes('category').columns
    df[cats] = df[cats].astype('string')
    # print(df.dtypes)
    return df, cats


def fill_empties(name_1, name_2, both, loaded_paths, adv_set):
    for name in (name_1, name_2):
        name = name.strip('_')
        path = loaded_paths['RBdirect'] if name == 'SET' else loaded_paths['mirror']
        if any(both[f'f_{name}'].isna()):

            floor = 10
            neg_backup = load_backup(lower_floor=floor, loaded_path=path, adv_set=adv_set)

            neg_backup.columns = (pd.Series(adjust_assoc_columns(neg_backup.columns)
                                            ) + f'_{name}').to_list()
            both, cats = uncat(both)
            neg_backup, __ = uncat(neg_backup)

            undefined_adv = both.loc[
                both[f'f_{name}'].isna(), :].index.to_list()

            both.loc[undefined_adv,
                     neg_backup.columns] = neg_backup.filter(items=undefined_adv, axis=0)

            both[cats] = both[cats].astype('category')

    return both


def combine_top(df_1: pd.DataFrame,
                name_1: str,
                df_2: pd.DataFrame,
                name_2: str,
                env_filter: str = 'NEG',
                filter_items: list = FOCUS,
                k: int = 10) -> pd.DataFrame:
    print(f'### `{TAG}` Most Negative Adverb Selections')
    top_dfs = [
        (get_top_vals(adv_df,  k=k,
                      index_like=env_filter,
                      metric_filter=['am_p1_given2',
                                     'conservative_log_ratio'])
         .sort_values('conservative_log_ratio', ascending=False))
        for adv_df in [df_1, df_2]
    ]
    for i, name in enumerate([name_1, name_2]):

        print_iter(
            [f'_{w}_' for w in top_dfs[i].l2], bullet='1.',
            header=(f'`{name}`: union of top {k} adverbs ranked by '
                    r'$LRC$ & $\Delta P(\texttt{env}|\texttt{adv})$'))
    top_adv_lists = [dx.l2.to_list() for dx in top_dfs]
    top_adv = pd.Series(top_adv_lists[0] + top_adv_lists[1]).drop_duplicates()
    # top_adv = pd.concat((top_dfs[0].l2, top_dfs[1].l2)).drop_duplicates()

    print_iter(
        [f'_{w}_' for w in top_adv], bullet='1.',
        header=f'Union of top adverbs for `{name_1}` and `{name_2}`. (Novel `{name_2}` adverbs listed last)')
    print(f'\n### `{name_1}` Adverb Associations (in initially loaded table)\n')
    df_1 = narrow_selection(df_1, top_adv, env_filter, filter_items)
    print(f'\n### `{name_2}` Adverb Associations (in initially loaded table)\n')
    df_2 = narrow_selection(df_2, top_adv, env_filter, filter_items)

    name_1, name_2 = [f"_{n.strip('_')}" for n in [name_1, name_2]]
    both = df_1.join(df_2, how="outer", lsuffix=name_1, rsuffix=name_2)

    # ! Empty cells need to be filled _before_ calculating mean
    both = fill_empties(name_1, name_2, both, adv_am_paths, adv_set=set(top_adv))
    both = force_ints(both)
    both = add_means(both)
    both = add_f_ratio(both, name_2, name_1)
    return both.sort_values('mean_dP1', ascending=False)


def add_f_ratio(df, subset_name, superset_name):
    counts = df.filter(regex=r'^[Nf][12]?').columns.str.split(
        '_').str.get(0).drop_duplicates()
    for count in counts:
        ratio_col = f'ratio_{count}{subset_name}'
        df[ratio_col] = (df[f'{count}{subset_name}']
                         / df[f'{count}{superset_name}'])
        # print(df.filter(like=count))
    return df


def add_means(both):
    for metric in (both.select_dtypes(include='number').columns.to_series()
                   .str.replace(r'_(MIR|SET)$', '', regex=True).unique()):
        both[f'mean_{snake_to_camel(metric)}'] = both.filter(
            regex=f"^{metric}").agg('mean', axis='columns')
    return both


def narrow_selection(df: pd.DataFrame,
                     top_adv: list,
                     env_filter: str = 'NEG',
                     filter_items: list = FOCUS):
    df = adjust_assoc_columns(
        df.filter(items=filter_items)
        .filter(like=env_filter, axis=0)
        .reset_index().set_index('l2')
        .filter(top_adv, axis=0)).sort_values(['LRC', 'dP1'], ascending=False)
    df.index.name = 'adv'
    nb_show_table(df.drop(['N', 'key', 'l1'], axis=1).round(
        2).sort_values(['LRC', 'dP1', ], ascending=False))

    return df

```

### Run it 🏃‍♀️


```python
C = combine_top(df_1=setdiff_adv, name_1='SET',
                df_2=mirror_adv, name_2='MIR', k=K)
```

    ### `NEQ` Most Negative Adverb Selections
    
    `SET`: union of top 8 adverbs ranked by $LRC$ & $\Delta P(\texttt{env}|\texttt{adv})$
    1. _necessarily_
    1. _that_
    1. _exactly_
    1. _immediately_
    1. _yet_
    1. _any_
    1. _remotely_
    1. _terribly_
    
    `MIR`: union of top 8 adverbs ranked by $LRC$ & $\Delta P(\texttt{env}|\texttt{adv})$
    1. _ever_
    1. _any_
    1. _necessarily_
    1. _that_
    1. _remotely_
    1. _particularly_
    1. _exactly_
    1. _inherently_
    
    Union of top adverbs for `SET` and `MIR`. (Novel `MIR` adverbs listed last)
    1. _necessarily_
    1. _that_
    1. _exactly_
    1. _immediately_
    1. _yet_
    1. _any_
    1. _remotely_
    1. _terribly_
    1. _ever_
    1. _particularly_
    1. _inherently_
    
    ### `SET` Adverb Associations (in initially loaded table)
    
    
    |                  |        `f` |   `dP1` |   `P1` |   `LRC` |       `G2` |   `odds_r_disc` |    `t` |         `f1` |       `f2` |   `exp_f` |   `unexp_f` |
    |:-----------------|-----------:|--------:|-------:|--------:|-----------:|----------------:|-------:|-------------:|-----------:|----------:|------------:|
    | **necessarily**  |  42,595.00 |    0.50 |   0.99 |    6.77 |  56,251.14 |            2.17 | 102.49 | 3,173,660.00 |  42,886.00 | 21,442.85 |   21,152.15 |
    | **that**         | 164,768.00 |    0.50 |   0.99 |    6.26 | 214,504.57 |            1.96 | 200.61 | 3,173,660.00 | 166,676.00 | 83,337.42 |   81,430.58 |
    | **exactly**      |  43,813.00 |    0.49 |   0.98 |    5.71 |  54,870.72 |            1.81 | 103.01 | 3,173,660.00 |  44,503.00 | 22,251.35 |   21,561.65 |
    | **immediately**  |  56,099.00 |    0.47 |   0.97 |    4.68 |  63,920.54 |            1.47 | 114.33 | 3,173,660.00 |  58,040.00 | 29,019.80 |   27,079.20 |
    | **yet**          |  51,867.00 |    0.47 |   0.96 |    4.52 |  57,900.12 |            1.42 | 109.45 | 3,173,660.00 |  53,881.00 | 26,940.31 |   24,926.69 |
    | **any**          |  15,384.00 |    0.45 |   0.95 |    3.91 |  15,851.55 |            1.26 |  58.57 | 3,173,660.00 |  16,238.00 |  8,118.94 |    7,265.06 |
    | **remotely**     |   5,661.00 |    0.42 |   0.92 |    3.16 |   5,075.57 |            1.05 |  34.30 | 3,173,660.00 |   6,161.00 |  3,080.48 |    2,580.52 |
    | **terribly**     |  17,949.00 |    0.41 |   0.91 |    3.10 |  15,186.21 |            0.99 |  60.07 | 3,173,660.00 |  19,802.00 |  9,900.93 |    8,048.07 |
    | **inherently**   |   6,743.00 |    0.28 |   0.78 |    1.66 |   2,929.13 |            0.56 |  29.67 | 3,173,660.00 |   8,614.00 |  4,306.97 |    2,436.03 |
    | **particularly** |  55,527.00 |    0.23 |   0.73 |    1.37 |  16,791.84 |            0.43 |  74.04 | 3,173,660.00 |  76,162.00 | 38,080.74 |   17,446.26 |
    | **ever**         |   5,932.00 |    0.05 |   0.55 |    0.12 |      91.19 |            0.08 |   6.45 | 3,173,660.00 |  10,870.00 |  5,434.96 |      497.04 |
    
    
    ### `MIR` Adverb Associations (in initially loaded table)
    
    
    |                  |      `f` |   `dP1` |   `P1` |   `LRC` |     `G2` |   `odds_r_disc` |   `t` |       `f1` |      `f2` |   `exp_f` |   `unexp_f` |
    |:-----------------|---------:|--------:|-------:|--------:|---------:|----------------:|------:|-----------:|----------:|----------:|------------:|
    | **ever**         | 4,709.00 |    0.49 |   0.98 |    5.17 | 5,883.26 |            1.79 | 33.75 | 291,732.00 |  4,786.00 |  2,392.98 |    2,316.02 |
    | **any**          | 1,066.00 |    0.47 |   0.97 |    4.00 | 1,252.02 |            1.56 | 15.88 | 291,732.00 |  1,095.00 |    547.49 |      518.51 |
    | **necessarily**  |   963.00 |    0.47 |   0.97 |    3.86 | 1,114.70 |            1.52 | 15.05 | 291,732.00 |    992.00 |    495.99 |      467.01 |
    | **that**         | 4,308.00 |    0.45 |   0.94 |    3.66 | 4,405.21 |            1.24 | 30.91 | 291,732.00 |  4,559.00 |  2,279.48 |    2,028.52 |
    | **remotely**     | 1,840.00 |    0.44 |   0.94 |    3.37 | 1,849.23 |            1.21 | 20.13 | 291,732.00 |  1,953.00 |    976.49 |      863.51 |
    | **particularly** | 9,243.00 |    0.43 |   0.92 |    3.30 | 8,516.58 |            1.08 | 43.98 | 291,732.00 | 10,029.00 |  5,014.45 |    4,228.55 |
    | **exactly**      |   813.00 |    0.44 |   0.94 |    2.95 |   790.27 |            1.16 | 13.27 | 291,732.00 |    869.00 |    434.50 |      378.50 |
    | **inherently**   | 2,864.00 |    0.36 |   0.86 |    2.24 | 1,899.59 |            0.78 | 22.29 | 291,732.00 |  3,342.00 |  1,670.98 |    1,193.02 |
    | **terribly**     | 1,567.00 |    0.21 |   0.71 |    0.97 |   406.49 |            0.39 | 11.75 | 291,732.00 |  2,204.00 |  1,101.99 |      465.01 |
    


### `NEQ` Most Negative Adverb Selections

`SET`: union of top 8 adverbs ranked by $LRC$ & $\Delta P(\texttt{env}|\texttt{adv})$
1. _necessarily_
1. _that_
1. _exactly_
1. _immediately_
1. _yet_
1. _any_
1. _remotely_
1. _terribly_

`MIR`: union of top 8 adverbs ranked by $LRC$ & $\Delta P(\texttt{env}|\texttt{adv})$
1. _ever_
1. _any_
1. _necessarily_
1. _that_
1. _remotely_
1. _particularly_
1. _exactly_
1. _inherently_

Union of top adverbs for `SET` and `MIR`. (Novel `MIR` adverbs listed last)
1. _necessarily_
1. _that_
1. _exactly_
1. _immediately_
1. _yet_
1. _any_
1. _remotely_
1. _terribly_
1. _ever_
1. _particularly_
1. _inherently_

### `SET` Adverb Associations (in initially loaded table)


|                  |        `f` |   `dP1` |   `P1` |   `LRC` |       `G2` |   `odds_r_disc` |    `t` |         `f1` |       `f2` |   `exp_f` |   `unexp_f` |
|:-----------------|-----------:|--------:|-------:|--------:|-----------:|----------------:|-------:|-------------:|-----------:|----------:|------------:|
| **necessarily**  |  42,595.00 |    0.50 |   0.99 |    6.77 |  56,251.14 |            2.17 | 102.49 | 3,173,660.00 |  42,886.00 | 21,442.85 |   21,152.15 |
| **that**         | 164,768.00 |    0.50 |   0.99 |    6.26 | 214,504.57 |            1.96 | 200.61 | 3,173,660.00 | 166,676.00 | 83,337.42 |   81,430.58 |
| **exactly**      |  43,813.00 |    0.49 |   0.98 |    5.71 |  54,870.72 |            1.81 | 103.01 | 3,173,660.00 |  44,503.00 | 22,251.35 |   21,561.65 |
| **immediately**  |  56,099.00 |    0.47 |   0.97 |    4.68 |  63,920.54 |            1.47 | 114.33 | 3,173,660.00 |  58,040.00 | 29,019.80 |   27,079.20 |
| **yet**          |  51,867.00 |    0.47 |   0.96 |    4.52 |  57,900.12 |            1.42 | 109.45 | 3,173,660.00 |  53,881.00 | 26,940.31 |   24,926.69 |
| **any**          |  15,384.00 |    0.45 |   0.95 |    3.91 |  15,851.55 |            1.26 |  58.57 | 3,173,660.00 |  16,238.00 |  8,118.94 |    7,265.06 |
| **remotely**     |   5,661.00 |    0.42 |   0.92 |    3.16 |   5,075.57 |            1.05 |  34.30 | 3,173,660.00 |   6,161.00 |  3,080.48 |    2,580.52 |
| **terribly**     |  17,949.00 |    0.41 |   0.91 |    3.10 |  15,186.21 |            0.99 |  60.07 | 3,173,660.00 |  19,802.00 |  9,900.93 |    8,048.07 |
| **inherently**   |   6,743.00 |    0.28 |   0.78 |    1.66 |   2,929.13 |            0.56 |  29.67 | 3,173,660.00 |   8,614.00 |  4,306.97 |    2,436.03 |
| **particularly** |  55,527.00 |    0.23 |   0.73 |    1.37 |  16,791.84 |            0.43 |  74.04 | 3,173,660.00 |  76,162.00 | 38,080.74 |   17,446.26 |
| **ever**         |   5,932.00 |    0.05 |   0.55 |    0.12 |      91.19 |            0.08 |   6.45 | 3,173,660.00 |  10,870.00 |  5,434.96 |      497.04 |


### `MIR` Adverb Associations (in initially loaded table)


|                  |      `f` |   `dP1` |   `P1` |   `LRC` |     `G2` |   `odds_r_disc` |   `t` |       `f1` |      `f2` |   `exp_f` |   `unexp_f` |
|:-----------------|---------:|--------:|-------:|--------:|---------:|----------------:|------:|-----------:|----------:|----------:|------------:|
| **ever**         | 4,709.00 |    0.49 |   0.98 |    5.17 | 5,883.26 |            1.79 | 33.75 | 291,732.00 |  4,786.00 |  2,392.98 |    2,316.02 |
| **any**          | 1,066.00 |    0.47 |   0.97 |    4.00 | 1,252.02 |            1.56 | 15.88 | 291,732.00 |  1,095.00 |    547.49 |      518.51 |
| **necessarily**  |   963.00 |    0.47 |   0.97 |    3.86 | 1,114.70 |            1.52 | 15.05 | 291,732.00 |    992.00 |    495.99 |      467.01 |
| **that**         | 4,308.00 |    0.45 |   0.94 |    3.66 | 4,405.21 |            1.24 | 30.91 | 291,732.00 |  4,559.00 |  2,279.48 |    2,028.52 |
| **remotely**     | 1,840.00 |    0.44 |   0.94 |    3.37 | 1,849.23 |            1.21 | 20.13 | 291,732.00 |  1,953.00 |    976.49 |      863.51 |
| **particularly** | 9,243.00 |    0.43 |   0.92 |    3.30 | 8,516.58 |            1.08 | 43.98 | 291,732.00 | 10,029.00 |  5,014.45 |    4,228.55 |
| **exactly**      |   813.00 |    0.44 |   0.94 |    2.95 |   790.27 |            1.16 | 13.27 | 291,732.00 |    869.00 |    434.50 |      378.50 |
| **inherently**   | 2,864.00 |    0.36 |   0.86 |    2.24 | 1,899.59 |            0.78 | 22.29 | 291,732.00 |  3,342.00 |  1,670.98 |    1,193.02 |
| **terribly**     | 1,567.00 |    0.21 |   0.71 |    0.97 |   406.49 |            0.39 | 11.75 | 291,732.00 |  2,204.00 |  1,101.99 |      465.01 |




```python
nb_show_table(C.filter(regex=r'^ratio_f2?_')
              .assign(f_minus_f2=C.ratio_f_MIR - C.ratio_f2_MIR)
              .multiply(100).round(1)
              .sort_values(['f_minus_f2', 'ratio_f_MIR'], ascending=False),
              n_dec=1, adjust_columns=False)

```

    
    |                  |   `ratio_f_MIR` |   `ratio_f2_MIR` |   `f_minus_f2` |
    |:-----------------|----------------:|-----------------:|---------------:|
    | **ever**         |            79.4 |             44.0 |           35.4 |
    | **inherently**   |            42.5 |             38.8 |            3.7 |
    | **particularly** |            16.6 |             13.2 |            3.5 |
    | **remotely**     |            32.5 |             31.7 |            0.8 |
    | **any**          |             6.9 |              6.7 |            0.2 |
    | **that**         |             2.6 |              2.7 |           -0.1 |
    | **necessarily**  |             2.3 |              2.3 |           -0.1 |
    | **exactly**      |             1.9 |              2.0 |           -0.1 |
    | **yet**          |             0.6 |              0.8 |           -0.2 |
    | **immediately**  |             0.7 |              1.0 |           -0.3 |
    | **terribly**     |             8.7 |             11.1 |           -2.4 |
    



|                  |   `ratio_f_MIR` |   `ratio_f2_MIR` |   `f_minus_f2` |
|:-----------------|----------------:|-----------------:|---------------:|
| **ever**         |            79.4 |             44.0 |           35.4 |
| **inherently**   |            42.5 |             38.8 |            3.7 |
| **particularly** |            16.6 |             13.2 |            3.5 |
| **remotely**     |            32.5 |             31.7 |            0.8 |
| **any**          |             6.9 |              6.7 |            0.2 |
| **that**         |             2.6 |              2.7 |           -0.1 |
| **necessarily**  |             2.3 |              2.3 |           -0.1 |
| **exactly**      |             1.9 |              2.0 |           -0.1 |
| **yet**          |             0.6 |              0.8 |           -0.2 |
| **immediately**  |             0.7 |              1.0 |           -0.3 |
| **terribly**     |             8.7 |             11.1 |           -2.4 |




```python
nb_show_table(
    C
    # .assign(f_percent_MIR=C.ratio_f_MIR * 100)
    .filter(regex=r'^f_.*[MS]').sort_index(axis=1, ascending=False)
    .assign(
        f_diff=C.f_SET-C.f_MIR).sort_values('f_diff', ascending=False)
    .rename(columns={'f_SET':'total negations', 
                     'f_MIR':'mirror subset negations', 
                     'f_diff': 'negations not in mirror subset'}), n_dec=0)
```

    
    |                  |   `total negations` |   `mirror subset negations` |   `negations not in mirror subset` |
    |:-----------------|--------------------:|----------------------------:|-----------------------------------:|
    | **that**         |             164,768 |                       4,308 |                            160,460 |
    | **immediately**  |              56,099 |                         403 |                             55,696 |
    | **yet**          |              51,867 |                         320 |                             51,547 |
    | **particularly** |              55,527 |                       9,243 |                             46,284 |
    | **exactly**      |              43,813 |                         813 |                             43,000 |
    | **necessarily**  |              42,595 |                         963 |                             41,632 |
    | **terribly**     |              17,949 |                       1,567 |                             16,382 |
    | **any**          |              15,384 |                       1,066 |                             14,318 |
    | **inherently**   |               6,743 |                       2,864 |                              3,879 |
    | **remotely**     |               5,661 |                       1,840 |                              3,821 |
    | **ever**         |               5,932 |                       4,709 |                              1,223 |
    



|                  |   `total negations` |   `mirror subset negations` |   `negations not in mirror subset` |
|:-----------------|--------------------:|----------------------------:|-----------------------------------:|
| **that**         |             164,768 |                       4,308 |                            160,460 |
| **immediately**  |              56,099 |                         403 |                             55,696 |
| **yet**          |              51,867 |                         320 |                             51,547 |
| **particularly** |              55,527 |                       9,243 |                             46,284 |
| **exactly**      |              43,813 |                         813 |                             43,000 |
| **necessarily**  |              42,595 |                         963 |                             41,632 |
| **terribly**     |              17,949 |                       1,567 |                             16,382 |
| **any**          |              15,384 |                       1,066 |                             14,318 |
| **inherently**   |               6,743 |                       2,864 |                              3,879 |
| **remotely**     |               5,661 |                       1,840 |                              3,821 |
| **ever**         |               5,932 |                       4,709 |                              1,223 |





#### Marginal (_Adverb Total_) Frequency Comparison


|                  |   `total adverb tokens` |   `mirror subset adverb tokens` |   `adverb tokens not in mirror subset` |
|:-----------------|------------------------:|--------------------------------:|---------------------------------------:|
| **that**         |                 166,676 |                           4,559 |                                162,117 |
| **particularly** |                  76,162 |                          10,029 |                                 66,133 |
| **immediately**  |                  58,040 |                             564 |                                 57,476 |
| **yet**          |                  53,881 |                             419 |                                 53,462 |
| **exactly**      |                  44,503 |                             869 |                                 43,634 |
| **necessarily**  |                  42,886 |                             992 |                                 41,894 |
| **terribly**     |                  19,802 |                           2,204 |                                 17,598 |
| **any**          |                  16,238 |                           1,095 |                                 15,143 |
| **ever**         |                  10,870 |                           4,786 |                                  6,084 |
| **inherently**   |                   8,614 |                           3,342 |                                  5,272 |
| **remotely**     |                   6,161 |                           1,953 |                                  4,208 |






```python
nb_show_table(
    C
    # .assign(f2_percent_MIR=C.ratio_f2_MIR * 100)
    .filter(regex=r'^f2_.*[MS]').sort_index(axis=1, ascending=False)
    .assign(
        f2_diff=C.f2_SET-C.f2_MIR).sort_values('f2_diff', ascending=False)
    .rename(columns={'f2_SET':'total adverb tokens', 
                     'f2_MIR':'mirror subset adverb tokens', 
                     'f2_diff': 'adverb tokens not in mirror subset'}), n_dec=0)
```

    
    |                  |   `total adverb tokens` |   `mirror subset adverb tokens` |   `adverb tokens not in mirror subset` |
    |:-----------------|------------------------:|--------------------------------:|---------------------------------------:|
    | **that**         |                 166,676 |                           4,559 |                                162,117 |
    | **particularly** |                  76,162 |                          10,029 |                                 66,133 |
    | **immediately**  |                  58,040 |                             564 |                                 57,476 |
    | **yet**          |                  53,881 |                             419 |                                 53,462 |
    | **exactly**      |                  44,503 |                             869 |                                 43,634 |
    | **necessarily**  |                  42,886 |                             992 |                                 41,894 |
    | **terribly**     |                  19,802 |                           2,204 |                                 17,598 |
    | **any**          |                  16,238 |                           1,095 |                                 15,143 |
    | **ever**         |                  10,870 |                           4,786 |                                  6,084 |
    | **inherently**   |                   8,614 |                           3,342 |                                  5,272 |
    | **remotely**     |                   6,161 |                           1,953 |                                  4,208 |
    



```python
full_C = C.copy()
main_cols_ordered = pd.concat((*[C.filter(like=m).columns.to_series() for m in ('LRC', 'P1', 'G2')],
                               *[C.filter(regex=f'^{f}_').columns.to_series() for f in ['f', 'f1', 'f2'] ]) 
                              ).to_list()
# print_iter([f'`{c}`' for c in main_cols_ordered], bullet='1.', header='Main Columns')
main_C = C[[c for c in main_cols_ordered if c in C.columns]]
nb_show_table(main_C.sort_values('mean_dP1', ascending=False), return_df=True)
```

    
    |                  |   `LRC_SET` |   `LRC_MIR` |   `mean_LRC` |   `dP1_SET` |   `P1_SET` |   `dP1_MIR` |   `P1_MIR` |   `mean_dP1` |   `mean_P1` |   `G2_SET` |   `G2_MIR` |   `mean_G2` |    `f_SET` |   `f_MIR` |     `f1_SET` |   `f1_MIR` |   `f2_SET` |   `f2_MIR` |
    |:-----------------|------------:|------------:|-------------:|------------:|-----------:|------------:|-----------:|-------------:|------------:|-----------:|-----------:|------------:|-----------:|----------:|-------------:|-----------:|-----------:|-----------:|
    | **necessarily**  |        6.77 |        3.86 |         5.31 |        0.50 |       0.99 |        0.47 |       0.97 |         0.48 |        0.98 |  56,251.14 |   1,114.70 |   28,682.92 |  42,595.00 |    963.00 | 3,173,660.00 | 291,732.00 |  42,886.00 |     992.00 |
    | **that**         |        6.26 |        3.66 |         4.96 |        0.50 |       0.99 |        0.45 |       0.94 |         0.48 |        0.97 | 214,504.57 |   4,405.21 |  109,454.89 | 164,768.00 |  4,308.00 | 3,173,660.00 | 291,732.00 | 166,676.00 |   4,559.00 |
    | **exactly**      |        5.71 |        2.95 |         4.33 |        0.49 |       0.98 |        0.44 |       0.94 |         0.46 |        0.96 |  54,870.72 |     790.27 |   27,830.50 |  43,813.00 |    813.00 | 3,173,660.00 | 291,732.00 |  44,503.00 |     869.00 |
    | **any**          |        3.91 |        4.00 |         3.96 |        0.45 |       0.95 |        0.47 |       0.97 |         0.46 |        0.96 |  15,851.55 |   1,252.02 |    8,551.79 |  15,384.00 |  1,066.00 | 3,173,660.00 | 291,732.00 |  16,238.00 |   1,095.00 |
    | **remotely**     |        3.16 |        3.37 |         3.27 |        0.42 |       0.92 |        0.44 |       0.94 |         0.43 |        0.93 |   5,075.57 |   1,849.23 |    3,462.40 |   5,661.00 |  1,840.00 | 3,173,660.00 | 291,732.00 |   6,161.00 |   1,953.00 |
    | **yet**          |        4.52 |        0.90 |         2.71 |        0.47 |       0.96 |        0.26 |       0.76 |         0.37 |        0.86 |  57,900.12 |     122.77 |   29,011.45 |  51,867.00 |    320.00 | 3,173,660.00 | 291,732.00 |  53,881.00 |     419.00 |
    | **immediately**  |        4.68 |        0.67 |         2.68 |        0.47 |       0.97 |        0.21 |       0.71 |         0.34 |        0.84 |  63,920.54 |     107.39 |   32,013.96 |  56,099.00 |    403.00 | 3,173,660.00 | 291,732.00 |  58,040.00 |     564.00 |
    | **particularly** |        1.37 |        3.30 |         2.33 |        0.23 |       0.73 |        0.43 |       0.92 |         0.33 |        0.83 |  16,791.84 |   8,516.58 |   12,654.21 |  55,527.00 |  9,243.00 | 3,173,660.00 | 291,732.00 |  76,162.00 |  10,029.00 |
    | **inherently**   |        1.66 |        2.24 |         1.95 |        0.28 |       0.78 |        0.36 |       0.86 |         0.32 |        0.82 |   2,929.13 |   1,899.59 |    2,414.36 |   6,743.00 |  2,864.00 | 3,173,660.00 | 291,732.00 |   8,614.00 |   3,342.00 |
    | **terribly**     |        3.10 |        0.97 |         2.03 |        0.41 |       0.91 |        0.21 |       0.71 |         0.31 |        0.81 |  15,186.21 |     406.49 |    7,796.35 |  17,949.00 |  1,567.00 | 3,173,660.00 | 291,732.00 |  19,802.00 |   2,204.00 |
    | **ever**         |        0.12 |        5.17 |         2.65 |        0.05 |       0.55 |        0.49 |       0.98 |         0.27 |        0.76 |      91.19 |   5,883.26 |    2,987.23 |   5,932.00 |  4,709.00 | 3,173,660.00 | 291,732.00 |  10,870.00 |   4,786.00 |
    





<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>`LRC_SET`</th>
      <th>`LRC_MIR`</th>
      <th>`mean_LRC`</th>
      <th>`dP1_SET`</th>
      <th>`P1_SET`</th>
      <th>`dP1_MIR`</th>
      <th>...</th>
      <th>`f_SET`</th>
      <th>`f_MIR`</th>
      <th>`f1_SET`</th>
      <th>`f1_MIR`</th>
      <th>`f2_SET`</th>
      <th>`f2_MIR`</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>**necessarily**</th>
      <td>6.77</td>
      <td>3.86</td>
      <td>5.31</td>
      <td>0.50</td>
      <td>0.99</td>
      <td>0.47</td>
      <td>...</td>
      <td>42595</td>
      <td>963</td>
      <td>3173660</td>
      <td>291732</td>
      <td>42886</td>
      <td>992</td>
    </tr>
    <tr>
      <th>**that**</th>
      <td>6.26</td>
      <td>3.66</td>
      <td>4.96</td>
      <td>0.50</td>
      <td>0.99</td>
      <td>0.45</td>
      <td>...</td>
      <td>164768</td>
      <td>4308</td>
      <td>3173660</td>
      <td>291732</td>
      <td>166676</td>
      <td>4559</td>
    </tr>
    <tr>
      <th>**exactly**</th>
      <td>5.71</td>
      <td>2.95</td>
      <td>4.33</td>
      <td>0.49</td>
      <td>0.98</td>
      <td>0.44</td>
      <td>...</td>
      <td>43813</td>
      <td>813</td>
      <td>3173660</td>
      <td>291732</td>
      <td>44503</td>
      <td>869</td>
    </tr>
    <tr>
      <th>**any**</th>
      <td>3.91</td>
      <td>4.00</td>
      <td>3.96</td>
      <td>0.45</td>
      <td>0.95</td>
      <td>0.47</td>
      <td>...</td>
      <td>15384</td>
      <td>1066</td>
      <td>3173660</td>
      <td>291732</td>
      <td>16238</td>
      <td>1095</td>
    </tr>
    <tr>
      <th>**remotely**</th>
      <td>3.16</td>
      <td>3.37</td>
      <td>3.27</td>
      <td>0.42</td>
      <td>0.92</td>
      <td>0.44</td>
      <td>...</td>
      <td>5661</td>
      <td>1840</td>
      <td>3173660</td>
      <td>291732</td>
      <td>6161</td>
      <td>1953</td>
    </tr>
    <tr>
      <th>**yet**</th>
      <td>4.52</td>
      <td>0.90</td>
      <td>2.71</td>
      <td>0.47</td>
      <td>0.96</td>
      <td>0.26</td>
      <td>...</td>
      <td>51867</td>
      <td>320</td>
      <td>3173660</td>
      <td>291732</td>
      <td>53881</td>
      <td>419</td>
    </tr>
    <tr>
      <th>**immediately**</th>
      <td>4.68</td>
      <td>0.67</td>
      <td>2.68</td>
      <td>0.47</td>
      <td>0.97</td>
      <td>0.21</td>
      <td>...</td>
      <td>56099</td>
      <td>403</td>
      <td>3173660</td>
      <td>291732</td>
      <td>58040</td>
      <td>564</td>
    </tr>
    <tr>
      <th>**particularly**</th>
      <td>1.37</td>
      <td>3.30</td>
      <td>2.33</td>
      <td>0.23</td>
      <td>0.73</td>
      <td>0.43</td>
      <td>...</td>
      <td>55527</td>
      <td>9243</td>
      <td>3173660</td>
      <td>291732</td>
      <td>76162</td>
      <td>10029</td>
    </tr>
    <tr>
      <th>**inherently**</th>
      <td>1.66</td>
      <td>2.24</td>
      <td>1.95</td>
      <td>0.28</td>
      <td>0.78</td>
      <td>0.36</td>
      <td>...</td>
      <td>6743</td>
      <td>2864</td>
      <td>3173660</td>
      <td>291732</td>
      <td>8614</td>
      <td>3342</td>
    </tr>
    <tr>
      <th>**terribly**</th>
      <td>3.10</td>
      <td>0.97</td>
      <td>2.03</td>
      <td>0.41</td>
      <td>0.91</td>
      <td>0.21</td>
      <td>...</td>
      <td>17949</td>
      <td>1567</td>
      <td>3173660</td>
      <td>291732</td>
      <td>19802</td>
      <td>2204</td>
    </tr>
    <tr>
      <th>**ever**</th>
      <td>0.12</td>
      <td>5.17</td>
      <td>2.65</td>
      <td>0.05</td>
      <td>0.55</td>
      <td>0.49</td>
      <td>...</td>
      <td>5932</td>
      <td>4709</td>
      <td>3173660</td>
      <td>291732</td>
      <td>10870</td>
      <td>4786</td>
    </tr>
  </tbody>
</table>
<p>11 rows × 18 columns</p>
</div>




|                  |   `LRC_SET` |   `LRC_MIR` |   `mean_LRC` |   `dP1_SET` |   `P1_SET` |   `dP1_MIR` |   `P1_MIR` |   `mean_dP1` |   `mean_P1` |   `G2_SET` |   `G2_MIR` |   `mean_G2` |    `f_SET` |   `f_MIR` |     `f1_SET` |   `f1_MIR` |   `f2_SET` |   `f2_MIR` |
|:-----------------|------------:|------------:|-------------:|------------:|-----------:|------------:|-----------:|-------------:|------------:|-----------:|-----------:|------------:|-----------:|----------:|-------------:|-----------:|-----------:|-----------:|
| **necessarily**  |        6.77 |        3.86 |         5.31 |        0.50 |       0.99 |        0.47 |       0.97 |         0.48 |        0.98 |  56,251.14 |   1,114.70 |   28,682.92 |  42,595.00 |    963.00 | 3,173,660.00 | 291,732.00 |  42,886.00 |     992.00 |
| **that**         |        6.26 |        3.66 |         4.96 |        0.50 |       0.99 |        0.45 |       0.94 |         0.48 |        0.97 | 214,504.57 |   4,405.21 |  109,454.89 | 164,768.00 |  4,308.00 | 3,173,660.00 | 291,732.00 | 166,676.00 |   4,559.00 |
| **exactly**      |        5.71 |        2.95 |         4.33 |        0.49 |       0.98 |        0.44 |       0.94 |         0.46 |        0.96 |  54,870.72 |     790.27 |   27,830.50 |  43,813.00 |    813.00 | 3,173,660.00 | 291,732.00 |  44,503.00 |     869.00 |
| **any**          |        3.91 |        4.00 |         3.96 |        0.45 |       0.95 |        0.47 |       0.97 |         0.46 |        0.96 |  15,851.55 |   1,252.02 |    8,551.79 |  15,384.00 |  1,066.00 | 3,173,660.00 | 291,732.00 |  16,238.00 |   1,095.00 |
| **remotely**     |        3.16 |        3.37 |         3.27 |        0.42 |       0.92 |        0.44 |       0.94 |         0.43 |        0.93 |   5,075.57 |   1,849.23 |    3,462.40 |   5,661.00 |  1,840.00 | 3,173,660.00 | 291,732.00 |   6,161.00 |   1,953.00 |
| **yet**          |        4.52 |        0.90 |         2.71 |        0.47 |       0.96 |        0.26 |       0.76 |         0.37 |        0.86 |  57,900.12 |     122.77 |   29,011.45 |  51,867.00 |    320.00 | 3,173,660.00 | 291,732.00 |  53,881.00 |     419.00 |
| **immediately**  |        4.68 |        0.67 |         2.68 |        0.47 |       0.97 |        0.21 |       0.71 |         0.34 |        0.84 |  63,920.54 |     107.39 |   32,013.96 |  56,099.00 |    403.00 | 3,173,660.00 | 291,732.00 |  58,040.00 |     564.00 |
| **particularly** |        1.37 |        3.30 |         2.33 |        0.23 |       0.73 |        0.43 |       0.92 |         0.33 |        0.83 |  16,791.84 |   8,516.58 |   12,654.21 |  55,527.00 |  9,243.00 | 3,173,660.00 | 291,732.00 |  76,162.00 |  10,029.00 |
| **inherently**   |        1.66 |        2.24 |         1.95 |        0.28 |       0.78 |        0.36 |       0.86 |         0.32 |        0.82 |   2,929.13 |   1,899.59 |    2,414.36 |   6,743.00 |  2,864.00 | 3,173,660.00 | 291,732.00 |   8,614.00 |   3,342.00 |
| **terribly**     |        3.10 |        0.97 |         2.03 |        0.41 |       0.91 |        0.21 |       0.71 |         0.31 |        0.81 |  15,186.21 |     406.49 |    7,796.35 |  17,949.00 |  1,567.00 | 3,173,660.00 | 291,732.00 |  19,802.00 |   2,204.00 |
| **ever**         |        0.12 |        5.17 |         2.65 |        0.05 |       0.55 |        0.49 |       0.98 |         0.27 |        0.76 |      91.19 |   5,883.26 |    2,987.23 |   5,932.00 |  4,709.00 | 3,173,660.00 | 291,732.00 |  10,870.00 |   4,786.00 |



## Save full adverb selection as `.csv`


```python
save_prefix=f'{data_top}_NEG-ADV_combined-{SET_FLOOR}'
combined_top_csv_output = OUT_DIR / f'{save_prefix}.{timestamp_today()}.csv'
print('Saving Combined "Most Negative Adverbs" AM table as csv:  '
    f'\n> `{combined_top_csv_output}`')

C.to_csv(combined_top_csv_output, float_format='{:.4f}'.format)

C
```

    Saving Combined "Most Negative Adverbs" AM table as csv:  
    > `/share/compling/projects/sanpi/results/top_AM/NEQ/NEQ-Top8/NEQ-Top8_NEG-ADV_combined-5000.2024-07-28.csv`





<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>key_SET</th>
      <th>f_SET</th>
      <th>dP1_SET</th>
      <th>P1_SET</th>
      <th>LRC_SET</th>
      <th>G2_SET</th>
      <th>...</th>
      <th>mean_expF</th>
      <th>mean_unexpF</th>
      <th>ratio_f_MIR</th>
      <th>ratio_N_MIR</th>
      <th>ratio_f1_MIR</th>
      <th>ratio_f2_MIR</th>
    </tr>
    <tr>
      <th>adv</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>necessarily</th>
      <td>NEGany~necessarily</td>
      <td>42595</td>
      <td>0.50</td>
      <td>0.99</td>
      <td>6.77</td>
      <td>56,251.14</td>
      <td>...</td>
      <td>10,969.42</td>
      <td>10,809.58</td>
      <td>0.02</td>
      <td>0.09</td>
      <td>0.09</td>
      <td>0.02</td>
    </tr>
    <tr>
      <th>that</th>
      <td>NEGany~that</td>
      <td>164768</td>
      <td>0.50</td>
      <td>0.99</td>
      <td>6.26</td>
      <td>214,504.57</td>
      <td>...</td>
      <td>42,808.45</td>
      <td>41,729.55</td>
      <td>0.03</td>
      <td>0.09</td>
      <td>0.09</td>
      <td>0.03</td>
    </tr>
    <tr>
      <th>exactly</th>
      <td>NEGany~exactly</td>
      <td>43813</td>
      <td>0.49</td>
      <td>0.98</td>
      <td>5.71</td>
      <td>54,870.72</td>
      <td>...</td>
      <td>11,342.92</td>
      <td>10,970.08</td>
      <td>0.02</td>
      <td>0.09</td>
      <td>0.09</td>
      <td>0.02</td>
    </tr>
    <tr>
      <th>any</th>
      <td>NEGany~any</td>
      <td>15384</td>
      <td>0.45</td>
      <td>0.95</td>
      <td>3.91</td>
      <td>15,851.55</td>
      <td>...</td>
      <td>4,333.22</td>
      <td>3,891.78</td>
      <td>0.07</td>
      <td>0.09</td>
      <td>0.09</td>
      <td>0.07</td>
    </tr>
    <tr>
      <th>remotely</th>
      <td>NEGany~remotely</td>
      <td>5661</td>
      <td>0.42</td>
      <td>0.92</td>
      <td>3.16</td>
      <td>5,075.57</td>
      <td>...</td>
      <td>2,028.48</td>
      <td>1,722.02</td>
      <td>0.33</td>
      <td>0.09</td>
      <td>0.09</td>
      <td>0.32</td>
    </tr>
    <tr>
      <th>yet</th>
      <td>NEGany~yet</td>
      <td>51867</td>
      <td>0.47</td>
      <td>0.96</td>
      <td>4.52</td>
      <td>57,900.12</td>
      <td>...</td>
      <td>13,574.91</td>
      <td>12,518.59</td>
      <td>0.01</td>
      <td>0.09</td>
      <td>0.09</td>
      <td>0.01</td>
    </tr>
    <tr>
      <th>immediately</th>
      <td>NEGany~immediately</td>
      <td>56099</td>
      <td>0.47</td>
      <td>0.97</td>
      <td>4.68</td>
      <td>63,920.54</td>
      <td>...</td>
      <td>14,650.90</td>
      <td>13,600.10</td>
      <td>0.01</td>
      <td>0.09</td>
      <td>0.09</td>
      <td>0.01</td>
    </tr>
    <tr>
      <th>particularly</th>
      <td>NEGany~particularly</td>
      <td>55527</td>
      <td>0.23</td>
      <td>0.73</td>
      <td>1.37</td>
      <td>16,791.84</td>
      <td>...</td>
      <td>21,547.59</td>
      <td>10,837.41</td>
      <td>0.17</td>
      <td>0.09</td>
      <td>0.09</td>
      <td>0.13</td>
    </tr>
    <tr>
      <th>inherently</th>
      <td>NEGany~inherently</td>
      <td>6743</td>
      <td>0.28</td>
      <td>0.78</td>
      <td>1.66</td>
      <td>2,929.13</td>
      <td>...</td>
      <td>2,988.98</td>
      <td>1,814.52</td>
      <td>0.42</td>
      <td>0.09</td>
      <td>0.09</td>
      <td>0.39</td>
    </tr>
    <tr>
      <th>terribly</th>
      <td>NEGany~terribly</td>
      <td>17949</td>
      <td>0.41</td>
      <td>0.91</td>
      <td>3.10</td>
      <td>15,186.21</td>
      <td>...</td>
      <td>5,501.46</td>
      <td>4,256.54</td>
      <td>0.09</td>
      <td>0.09</td>
      <td>0.09</td>
      <td>0.11</td>
    </tr>
    <tr>
      <th>ever</th>
      <td>NEGany~ever</td>
      <td>5932</td>
      <td>0.05</td>
      <td>0.55</td>
      <td>0.12</td>
      <td>91.19</td>
      <td>...</td>
      <td>3,913.97</td>
      <td>1,406.53</td>
      <td>0.79</td>
      <td>0.09</td>
      <td>0.09</td>
      <td>0.44</td>
    </tr>
  </tbody>
</table>
<p>11 rows × 44 columns</p>
</div>



Save `all-columns`, `means`, and `MAIN` as markdown formatted tables


```python
C.to_markdown(
    floatfmt=',.2f', intfmt=',',
    buf=OUT_DIR.joinpath(
        f'{save_prefix}_all-columns_{timestamp_today()}.md')
)
C.filter(like='mean_').to_markdown(
    floatfmt=',.2f', intfmt=',',
    buf=OUT_DIR.joinpath(
        f'{save_prefix}_means_{timestamp_today()}.md')
)
C[main_cols_ordered].to_markdown(
    floatfmt=',.2f', intfmt=',',
    buf=OUT_DIR.joinpath(
        f'{save_prefix}_MAIN_{timestamp_today()}.md')
)
```


```python
nb_show_table(C[main_cols_ordered])
```

    
    |                  |   `LRC_SET` |   `LRC_MIR` |   `mean_LRC` |   `dP1_SET` |   `P1_SET` |   `dP1_MIR` |   `P1_MIR` |   `mean_dP1` |   `mean_P1` |   `G2_SET` |   `G2_MIR` |   `mean_G2` |    `f_SET` |   `f_MIR` |     `f1_SET` |   `f1_MIR` |   `f2_SET` |   `f2_MIR` |
    |:-----------------|------------:|------------:|-------------:|------------:|-----------:|------------:|-----------:|-------------:|------------:|-----------:|-----------:|------------:|-----------:|----------:|-------------:|-----------:|-----------:|-----------:|
    | **necessarily**  |        6.77 |        3.86 |         5.31 |        0.50 |       0.99 |        0.47 |       0.97 |         0.48 |        0.98 |  56,251.14 |   1,114.70 |   28,682.92 |  42,595.00 |    963.00 | 3,173,660.00 | 291,732.00 |  42,886.00 |     992.00 |
    | **that**         |        6.26 |        3.66 |         4.96 |        0.50 |       0.99 |        0.45 |       0.94 |         0.48 |        0.97 | 214,504.57 |   4,405.21 |  109,454.89 | 164,768.00 |  4,308.00 | 3,173,660.00 | 291,732.00 | 166,676.00 |   4,559.00 |
    | **exactly**      |        5.71 |        2.95 |         4.33 |        0.49 |       0.98 |        0.44 |       0.94 |         0.46 |        0.96 |  54,870.72 |     790.27 |   27,830.50 |  43,813.00 |    813.00 | 3,173,660.00 | 291,732.00 |  44,503.00 |     869.00 |
    | **any**          |        3.91 |        4.00 |         3.96 |        0.45 |       0.95 |        0.47 |       0.97 |         0.46 |        0.96 |  15,851.55 |   1,252.02 |    8,551.79 |  15,384.00 |  1,066.00 | 3,173,660.00 | 291,732.00 |  16,238.00 |   1,095.00 |
    | **remotely**     |        3.16 |        3.37 |         3.27 |        0.42 |       0.92 |        0.44 |       0.94 |         0.43 |        0.93 |   5,075.57 |   1,849.23 |    3,462.40 |   5,661.00 |  1,840.00 | 3,173,660.00 | 291,732.00 |   6,161.00 |   1,953.00 |
    | **yet**          |        4.52 |        0.90 |         2.71 |        0.47 |       0.96 |        0.26 |       0.76 |         0.37 |        0.86 |  57,900.12 |     122.77 |   29,011.45 |  51,867.00 |    320.00 | 3,173,660.00 | 291,732.00 |  53,881.00 |     419.00 |
    | **immediately**  |        4.68 |        0.67 |         2.68 |        0.47 |       0.97 |        0.21 |       0.71 |         0.34 |        0.84 |  63,920.54 |     107.39 |   32,013.96 |  56,099.00 |    403.00 | 3,173,660.00 | 291,732.00 |  58,040.00 |     564.00 |
    | **particularly** |        1.37 |        3.30 |         2.33 |        0.23 |       0.73 |        0.43 |       0.92 |         0.33 |        0.83 |  16,791.84 |   8,516.58 |   12,654.21 |  55,527.00 |  9,243.00 | 3,173,660.00 | 291,732.00 |  76,162.00 |  10,029.00 |
    | **inherently**   |        1.66 |        2.24 |         1.95 |        0.28 |       0.78 |        0.36 |       0.86 |         0.32 |        0.82 |   2,929.13 |   1,899.59 |    2,414.36 |   6,743.00 |  2,864.00 | 3,173,660.00 | 291,732.00 |   8,614.00 |   3,342.00 |
    | **terribly**     |        3.10 |        0.97 |         2.03 |        0.41 |       0.91 |        0.21 |       0.71 |         0.31 |        0.81 |  15,186.21 |     406.49 |    7,796.35 |  17,949.00 |  1,567.00 | 3,173,660.00 | 291,732.00 |  19,802.00 |   2,204.00 |
    | **ever**         |        0.12 |        5.17 |         2.65 |        0.05 |       0.55 |        0.49 |       0.98 |         0.27 |        0.76 |      91.19 |   5,883.26 |    2,987.23 |   5,932.00 |  4,709.00 | 3,173,660.00 | 291,732.00 |  10,870.00 |   4,786.00 |
    


|                  |   `LRC_SET` |   `LRC_MIR` |   `mean_LRC` |   `dP1_SET` |   `P1_SET` |   `dP1_MIR` |   `P1_MIR` |   `mean_dP1` |   `mean_P1` |   `G2_SET` |   `G2_MIR` |   `mean_G2` |    `f_SET` |   `f_MIR` |     `f1_SET` |   `f1_MIR` |   `f2_SET` |   `f2_MIR` |
|:-----------------|------------:|------------:|-------------:|------------:|-----------:|------------:|-----------:|-------------:|------------:|-----------:|-----------:|------------:|-----------:|----------:|-------------:|-----------:|-----------:|-----------:|
| **necessarily**  |        6.77 |        3.86 |         5.31 |        0.50 |       0.99 |        0.47 |       0.97 |         0.48 |        0.98 |  56,251.14 |   1,114.70 |   28,682.92 |  42,595.00 |    963.00 | 3,173,660.00 | 291,732.00 |  42,886.00 |     992.00 |
| **that**         |        6.26 |        3.66 |         4.96 |        0.50 |       0.99 |        0.45 |       0.94 |         0.48 |        0.97 | 214,504.57 |   4,405.21 |  109,454.89 | 164,768.00 |  4,308.00 | 3,173,660.00 | 291,732.00 | 166,676.00 |   4,559.00 |
| **exactly**      |        5.71 |        2.95 |         4.33 |        0.49 |       0.98 |        0.44 |       0.94 |         0.46 |        0.96 |  54,870.72 |     790.27 |   27,830.50 |  43,813.00 |    813.00 | 3,173,660.00 | 291,732.00 |  44,503.00 |     869.00 |
| **any**          |        3.91 |        4.00 |         3.96 |        0.45 |       0.95 |        0.47 |       0.97 |         0.46 |        0.96 |  15,851.55 |   1,252.02 |    8,551.79 |  15,384.00 |  1,066.00 | 3,173,660.00 | 291,732.00 |  16,238.00 |   1,095.00 |
| **remotely**     |        3.16 |        3.37 |         3.27 |        0.42 |       0.92 |        0.44 |       0.94 |         0.43 |        0.93 |   5,075.57 |   1,849.23 |    3,462.40 |   5,661.00 |  1,840.00 | 3,173,660.00 | 291,732.00 |   6,161.00 |   1,953.00 |
| **yet**          |        4.52 |        0.90 |         2.71 |        0.47 |       0.96 |        0.26 |       0.76 |         0.37 |        0.86 |  57,900.12 |     122.77 |   29,011.45 |  51,867.00 |    320.00 | 3,173,660.00 | 291,732.00 |  53,881.00 |     419.00 |
| **immediately**  |        4.68 |        0.67 |         2.68 |        0.47 |       0.97 |        0.21 |       0.71 |         0.34 |        0.84 |  63,920.54 |     107.39 |   32,013.96 |  56,099.00 |    403.00 | 3,173,660.00 | 291,732.00 |  58,040.00 |     564.00 |
| **particularly** |        1.37 |        3.30 |         2.33 |        0.23 |       0.73 |        0.43 |       0.92 |         0.33 |        0.83 |  16,791.84 |   8,516.58 |   12,654.21 |  55,527.00 |  9,243.00 | 3,173,660.00 | 291,732.00 |  76,162.00 |  10,029.00 |
| **inherently**   |        1.66 |        2.24 |         1.95 |        0.28 |       0.78 |        0.36 |       0.86 |         0.32 |        0.82 |   2,929.13 |   1,899.59 |    2,414.36 |   6,743.00 |  2,864.00 | 3,173,660.00 | 291,732.00 |   8,614.00 |   3,342.00 |
| **terribly**     |        3.10 |        0.97 |         2.03 |        0.41 |       0.91 |        0.21 |       0.71 |         0.31 |        0.81 |  15,186.21 |     406.49 |    7,796.35 |  17,949.00 |  1,567.00 | 3,173,660.00 | 291,732.00 |  19,802.00 |   2,204.00 |
| **ever**         |        0.12 |        5.17 |         2.65 |        0.05 |       0.55 |        0.49 |       0.98 |         0.27 |        0.76 |      91.19 |   5,883.26 |    2,987.23 |   5,932.00 |  4,709.00 | 3,173,660.00 | 291,732.00 |  10,870.00 |   4,786.00 |
