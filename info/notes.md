# Up next: 

- [ ] determine contexts to run and discuss in syntax chapter: include locality constraints
- [ ] convert contexts to grew-match pattern specifications
- [ ] patterns for NPIs in same contexts
- [x] create bash script to run all python code? e.g. grewSearchDir -> fillJson --> tabulate --> future comparison script? 
- [ ] run patterns
- [ ] write scipt to compare new simplified count csv's
- [ ] determine naming schema for contexts-- create all contexts/patterns before naming?


# start with:
- [ ] http://www.collocations.de/UCS/tron-one-minute-guide.html  try ucs tables
    - [x] get all pair-hits of ADV ADJ for pattern 
    - [x] pipe `ADV \t ADJ \n` output to `ucs-make-tables -v`
    - [ ] alternatively, make own joint and marginal freq (frequency signature) tables script?
- [x] look at corpus study stats paper file:///C:/Users/Andrea/Downloads/cantos-2018-lexical.pdf
- [x] fixing encoding error in tabulate for p1 outputs! (remember server tabulate.py has print() statement)