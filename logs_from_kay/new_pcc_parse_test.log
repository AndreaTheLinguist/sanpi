...[previous runs removed]...

[arh234@kay:~/snpa$ python3 script/parse_pile.py -f pile_data/train/00.jsonl; python3 script/parse_pile.py -f pile_data/train/01.json
Loading dependency parsing pipeline...
2022-01-17 23:58:52 INFO: Loading these models for language: en (English):
========================
| Processor | Package  |
------------------------
| tokenize  | combined |
| pos       | combined |
| lemma     | combined |
| depparse  | combined |
========================

2022-01-17 23:58:52 INFO: Use device: cpu
2022-01-17 23:58:52 INFO: Loading: tokenize
2022-01-17 23:58:52 INFO: Loading: pos
2022-01-17 23:58:53 INFO: Loading: lemma
2022-01-17 23:58:53 INFO: Loading: depparse
2022-01-17 23:58:53 INFO: Done loading processors!
started: Mon Jan 17 23:58:53 2022
+ raw files selected to process:
[PosixPath('/data/pile/train/00.jsonl')]

raw jsonlines files will be processed for the following subcorpora: 
['Pile-CC']


---

Preprocessing /data/pile/train/00.jsonl...
  creating `jsonlines` generator for corpus selection...
  ~ 0.0008  sec elapsed
  building dataframe from from `jsonlines` generator object...
  ~ 373.871  sec elapsed
  translating encoding...
  ~ 1557.85  sec elapsed
  adding subset codes & text IDs...
  ~ 2.287  sec elapsed

Cleaning text in dataframe...
  looking for wikitext/wikimedia formatting...
  extracting text from 37 known wikitext formatting...
  cleaning 420 possibly wikitext formatted texts...
  looking for any html...
/home/arh234/.local/lib/python3.8/site-packages/bs4/builder/_htmlparser.py:102: UserWarning: expected name token at '<![ CDATA [\n<h0 n=3>'
  warnings.warn(msg)
Traceback (most recent call last):
  File "script/parse_pile.py", line 719, in <module>
    main()
  File "script/parse_pile.py", line 112, in main
    process_raw_jsonlines(rfiles, corpus_selection)
  File "script/parse_pile.py", line 190, in process_raw_jsonlines
    df = preprocess_pile_texts(rawfile_path, corpus_selection)
  File "script/parse_pile.py", line 495, in preprocess_pile_texts
    df = cleanup_df(df, tmpdfpath)
  File "script/parse_pile.py", line 232, in cleanup_df
    is_html = df.text.apply(
  File "/home/arh234/.local/lib/python3.8/site-packages/pandas/core/series.py", line 4357, in apply
    return SeriesApply(self, func, convert_dtype, args, kwargs).apply()
  File "/home/arh234/.local/lib/python3.8/site-packages/pandas/core/apply.py", line 1043, in apply
    return self.apply_standard()
  File "/home/arh234/.local/lib/python3.8/site-packages/pandas/core/apply.py", line 1098, in apply_standard
    mapped = lib.map_infer(
  File "pandas/_libs/lib.pyx", line 2859, in pandas._libs.lib.map_infer
  File "script/parse_pile.py", line 233, in <lambda>
    lambda t: (bool(BeautifulSoup(t, "html.parser").find())))
  File "/home/arh234/.local/lib/python3.8/site-packages/bs4/__init__.py", line 362, in __init__
    self._feed()
  File "/home/arh234/.local/lib/python3.8/site-packages/bs4/__init__.py", line 448, in _feed
    self.builder.feed(self.markup)
  File "/home/arh234/.local/lib/python3.8/site-packages/bs4/builder/_htmlparser.py", line 392, in feed
    parser.feed(markup)
  File "/usr/lib/python3.8/html/parser.py", line 111, in feed
    self.goahead(0)
  File "/usr/lib/python3.8/html/parser.py", line 179, in goahead
    k = self.parse_html_declaration(i)
  File "/usr/lib/python3.8/html/parser.py", line 264, in parse_html_declaration
    return self.parse_marked_section(i)
  File "/usr/lib/python3.8/_markupbase.py", line 149, in parse_marked_section
    sectName, j = self._scan_name( i+3, i )
TypeError: cannot unpack non-iterable NoneType object

[=== starting file `train/01.jsonl` ===]

Loading dependency parsing pipeline...
2022-01-18 01:22:35 INFO: Loading these models for language: en (English):
========================
| Processor | Package  |
------------------------
| tokenize  | combined |
| pos       | combined |
| lemma     | combined |
| depparse  | combined |
========================

2022-01-18 01:22:35 INFO: Use device: cpu
2022-01-18 01:22:35 INFO: Loading: tokenize
2022-01-18 01:22:35 INFO: Loading: pos
2022-01-18 01:22:35 INFO: Loading: lemma
2022-01-18 01:22:35 INFO: Loading: depparse
2022-01-18 01:22:35 INFO: Done loading processors!
started: Tue Jan 18 01:22:35 2022
+ raw files selected to process:
[PosixPath('/data/pile/train/01.jsonl')]

raw jsonlines files will be processed for the following subcorpora: 
['Pile-CC']


---

Preprocessing /data/pile/train/01.jsonl...
  creating `jsonlines` generator for corpus selection...
  ~ 0.0005  sec elapsed
  building dataframe from from `jsonlines` generator object...
  ~ 378.228  sec elapsed
  translating encoding...
  ~ 1554.35  sec elapsed
  adding subset codes & text IDs...
  ~ 2.539  sec elapsed

Cleaning text in dataframe...
  looking for wikitext/wikimedia formatting...
  extracting text from 26 known wikitext formatting...
  cleaning 376 possibly wikitext formatted texts...
  looking for any html...
/home/arh234/.local/lib/python3.8/site-packages/bs4/builder/_htmlparser.py:102: UserWarning: expected name token at '<![\nCDATA\n[ ... ]]>\n'
  warnings.warn(msg)
Traceback (most recent call last):
  File "script/parse_pile.py", line 719, in <module>
    main()
  File "script/parse_pile.py", line 112, in main
    process_raw_jsonlines(rfiles, corpus_selection)
  File "script/parse_pile.py", line 190, in process_raw_jsonlines
    df = preprocess_pile_texts(rawfile_path, corpus_selection)
  File "script/parse_pile.py", line 495, in preprocess_pile_texts
    df = cleanup_df(df, tmpdfpath)
  File "script/parse_pile.py", line 232, in cleanup_df
    is_html = df.text.apply(
  File "/home/arh234/.local/lib/python3.8/site-packages/pandas/core/series.py", line 4357, in apply
    return SeriesApply(self, func, convert_dtype, args, kwargs).apply()
  File "/home/arh234/.local/lib/python3.8/site-packages/pandas/core/apply.py", line 1043, in apply
    return self.apply_standard()
  File "/home/arh234/.local/lib/python3.8/site-packages/pandas/core/apply.py", line 1098, in apply_standard
    mapped = lib.map_infer(
  File "pandas/_libs/lib.pyx", line 2859, in pandas._libs.lib.map_infer
  File "script/parse_pile.py", line 233, in <lambda>
    lambda t: (bool(BeautifulSoup(t, "html.parser").find())))
  File "/home/arh234/.local/lib/python3.8/site-packages/bs4/__init__.py", line 362, in __init__
    self._feed()
  File "/home/arh234/.local/lib/python3.8/site-packages/bs4/__init__.py", line 448, in _feed
    self.builder.feed(self.markup)
  File "/home/arh234/.local/lib/python3.8/site-packages/bs4/builder/_htmlparser.py", line 392, in feed
    parser.feed(markup)
  File "/usr/lib/python3.8/html/parser.py", line 111, in feed
    self.goahead(0)
  File "/usr/lib/python3.8/html/parser.py", line 179, in goahead
    k = self.parse_html_declaration(i)
  File "/usr/lib/python3.8/html/parser.py", line 264, in parse_html_declaration
    return self.parse_marked_section(i)
  File "/usr/lib/python3.8/_markupbase.py", line 149, in parse_marked_section
    sectName, j = self._scan_name( i+3, i )
TypeError: cannot unpack non-iterable NoneType object


arh234@kay:~/snpa$ 
[Karh234@kay:~/snpa$ exit
exit
