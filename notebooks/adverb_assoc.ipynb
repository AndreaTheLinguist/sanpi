{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Identifying Adverbs with Strongest Negative Environment Associations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 78,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "\n",
                "import pandas as pd\n",
                "\n",
                "from source.utils import PKL_SUFF\n",
                "from source.utils.associate import AM_DF_DIR, TOP_AM_DIR, adjust_assoc_columns\n",
                "from source.utils.general import print_iter, snake_to_camel, timestamp_today\n",
                "\n",
                "SET_FLOOR = 1000\n",
                "MIR_FLOOR = 200\n",
                "K = 5\n",
                "\n",
                "# for loading `polar/*/bigram/*` tables\n",
                "bigram_floor = 200\n",
                "mirror_floor = 50"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Set columns and diplay settings"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 79,
            "metadata": {},
            "outputs": [],
            "source": [
                "FOCUS = ['f',\n",
                "         'am_p1_given2', 'conservative_log_ratio',\n",
                "         'am_log_likelihood',\n",
                "        #  'mutual_information', 'am_odds_ratio_disc', 't_score',\n",
                "         'N', 'f1', 'f2', 'E11', 'unexpected_f', \n",
                "         'l1', 'l2']\n",
                "pd.set_option('display.max_colwidth', 20)\n",
                "pd.set_option('display.max_columns', 12)\n",
                "pd.set_option('display.width', 90)\n",
                "pd.set_option(\"display.precision\", 2)\n",
                "pd.set_option(\"styler.format.precision\", 2)\n",
                "pd.set_option(\"styler.format.thousands\", \",\")\n",
                "pd.set_option(\"display.float_format\", '{:,.2f}'.format)\n",
                "# pd.set_option(\"styler.render.repr\", \"html\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 80,
            "metadata": {},
            "outputs": [],
            "source": [
                "def force_ints(_df):\n",
                "    count_cols = _df.filter(regex=r'total|^[fN]').columns\n",
                "    _df[count_cols] = _df[count_cols].astype('int')\n",
                "    # _df[count_cols] = _df[:, count_cols].astype('int64')\n",
                "    # print(_df.dtypes.to_frame('dtypes'))\n",
                "    return _df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 81,
            "metadata": {},
            "outputs": [],
            "source": [
                "def nb_show_table(df, n_dec: int = 2,\n",
                "                  adjust_columns: bool = True,\n",
                "                   outpath:Path=None, \n",
                "                   return_df:bool=False) -> None: \n",
                "    _df = df.copy()\n",
                "    if adjust_columns: \n",
                "        _df = adjust_assoc_columns(_df)\n",
                "    _df.columns = [f'`{c}`' for c in _df.columns]\n",
                "    _df.index = [f'**{r}**' for r in _df.index ]\n",
                "    table = _df.to_markdown(floatfmt=f',.{n_dec}f', intfmt=',')\n",
                "    if outpath:\n",
                "        outpath.write_text(table)\n",
                "\n",
                "    print(f'\\n{table}\\n')\n",
                "    return (_df if return_df else None)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Set paths and load adverb association tables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 82,
            "metadata": {},
            "outputs": [],
            "source": [
                "def update_index(df, pat_name:str = None):\n",
                "    neg_env_name = df.filter(like='NEG', axis=0).l1[0]\n",
                "    # > will be either `NEGATED` or `NEGMIR`\n",
                "    #   both are shortened to just `NEG` for the keys in their separate dataframes\n",
                "    # > replace to avoid ambiguity in `key` values when combined\n",
                "    #! some filtering relies on 'NEG', so have to keep that prefix\n",
                "    index_update = pat_name or ('NEGmir' if neg_env_name.endswith('MIR') else 'NEGany')\n",
                "    df.index = df.index.str.replace('NEG', index_update)\n",
                "    return df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 83,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "|                   |    `f` |   `dP1` |   `LRC` |    `G2` |        `N` |       `f1` |   `f2` |   `exp_f` |   `unexp_f` | `l1`       | `l2`      |\n",
                        "|:------------------|-------:|--------:|--------:|--------:|-----------:|-----------:|-------:|----------:|------------:|:-----------|:----------|\n",
                        "| **COM~initially** | 23,770 |   -0.00 |    0.00 |   -2.21 | 86,330,752 | 83,102,035 | 24,740 | 23,814.74 |      -44.74 | COMPLEMENT | initially |\n",
                        "| **COM~publicly**  | 32,804 |   -0.01 |   -0.31 | -177.30 | 86,330,752 | 83,102,035 | 34,594 | 33,300.21 |     -496.21 | COMPLEMENT | publicly  |\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "POLAR_DIR = AM_DF_DIR.joinpath('polar')\n",
                "\n",
                "polar_adv_dirs = []\n",
                "# results/assoc_df/polar/RBdirect/adv/extra/polarized-adv_35f-7c_min5000x_extra.pkl.gz\n",
                "adv_am_paths = {\n",
                "    p.name: tuple(\n",
                "        p.joinpath('adv/extra').glob(\n",
                "            f'*35f-7c_min{SET_FLOOR if p.name == \"RBdirect\" else MIR_FLOOR}x*{PKL_SUFF}')\n",
                "    )[0]\n",
                "    for p in POLAR_DIR.iterdir()}\n",
                "\n",
                "setdiff_adv = update_index(pd.read_pickle(adv_am_paths['RBdirect']))\n",
                "mirror_adv = update_index(pd.read_pickle(adv_am_paths['NEGmirror']))\n",
                "nb_show_table(setdiff_adv.sample(K//2).sort_values('conservative_log_ratio', ascending=False)[FOCUS])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 84,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "|               |    `f` |   `dP1` |   `LRC` |     `G2` |       `N` |      `f1` |   `f2` |   `exp_f` |   `unexp_f` | `l1`   | `l2`   |\n",
                        "|:--------------|-------:|--------:|--------:|---------:|----------:|----------:|-------:|----------:|------------:|:-------|:-------|\n",
                        "| **POS~maybe** |  2,573 |    0.16 |    3.43 |   846.03 | 1,761,853 | 1,472,036 |  2,581 |  2,156.44 |      416.56 | POSMIR | maybe  |\n",
                        "| **POS~just**  | 27,625 |    0.14 |    2.60 | 5,785.97 | 1,761,853 | 1,472,036 | 28,371 | 23,704.10 |    3,920.90 | POSMIR | just   |\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "nb_show_table(mirror_adv.sample(K//2).sort_values('conservative_log_ratio', ascending=False)[FOCUS])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Calculate \"Most Negative\" Adverbs for each Polarity Approximation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 85,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "|        | `key`              |     `f` |   `dP1` |   `LRC` |       `G2` |        `N` |      `f1` |    `f2` |   `exp_f` |   `unexp_f` | `l1`    | `l2`        |\n",
                        "|:-------|:-------------------|--------:|--------:|--------:|-----------:|-----------:|----------:|--------:|----------:|------------:|:--------|:------------|\n",
                        "| **0**  | NEGany~necessarily |  42,708 |    0.72 |    6.23 | 219,003.46 | 86,330,752 | 3,226,213 |  56,694 |  2,118.68 |   40,589.32 | NEGATED | necessarily |\n",
                        "| **1**  | NEGany~exactly     |  43,635 |    0.67 |    5.90 | 214,404.20 | 86,330,752 | 3,226,213 |  61,599 |  2,301.98 |   41,333.02 | NEGATED | exactly     |\n",
                        "| **2**  | NEGany~that        | 165,411 |    0.63 |    5.62 | 781,016.11 | 86,330,752 | 3,226,213 | 250,392 |  9,357.24 |  156,053.76 | NEGATED | that        |\n",
                        "| **3**  | NEGany~immediately |  57,319 |    0.52 |    4.96 | 239,462.58 | 86,330,752 | 3,226,213 | 103,177 |  3,855.76 |   53,463.24 | NEGATED | immediately |\n",
                        "| **4**  | NEGany~yet         |  52,546 |    0.48 |    4.74 | 209,055.78 | 86,330,752 | 3,226,213 | 101,707 |  3,800.83 |   48,745.17 | NEGATED | yet         |\n",
                        "| **5**  | NEGany~terribly    |  18,054 |    0.22 |    3.09 |  42,704.93 | 86,330,752 | 3,226,213 |  70,174 |  2,622.43 |   15,431.57 | NEGATED | terribly    |\n",
                        "| **6**  | NEGany~remotely    |   5,679 |    0.22 |    3.03 |  13,354.33 | 86,330,752 | 3,226,213 |  22,194 |    829.40 |    4,849.60 | NEGATED | remotely    |\n",
                        "| **7**  | NEGany~only        | 114,070 |    0.21 |    3.04 | 261,936.36 | 86,330,752 | 3,226,213 | 464,168 | 17,346.13 |   96,723.87 | NEGATED | only        |\n",
                        "| **8**  | NEGany~altogether  |   4,575 |    0.18 |    2.75 |   9,468.00 | 86,330,752 | 3,226,213 |  20,636 |    771.18 |    3,803.82 | NEGATED | altogether  |\n",
                        "| **9**  | NEGany~entirely    |  63,708 |    0.17 |    2.74 | 125,925.14 | 86,330,752 | 3,226,213 | 303,833 | 11,354.35 |   52,353.65 | NEGATED | entirely    |\n",
                        "| **10** | NEGany~overly      |  24,707 |    0.17 |    2.66 |  46,993.58 | 86,330,752 | 3,226,213 | 122,058 |  4,561.35 |   20,145.65 | NEGATED | overly      |\n",
                        "| **11** | NEGany~merely      |   5,944 |    0.13 |    2.26 |   9,223.66 | 86,330,752 | 3,226,213 |  35,608 |  1,330.68 |    4,613.32 | NEGATED | merely      |\n",
                        "| **12** | NEGany~any         |  15,492 |    0.13 |    2.28 |  23,683.00 | 86,330,752 | 3,226,213 |  94,152 |  3,518.50 |   11,973.50 | NEGATED | any         |\n",
                        "| **13** | NEGany~always      | 104,605 |    0.12 |    2.28 | 157,437.56 | 86,330,752 | 3,226,213 | 651,053 | 24,330.10 |   80,274.90 | NEGATED | always      |\n",
                        "| **14** | NEGany~outright    |   1,259 |    0.12 |    2.04 |   1,830.81 | 86,330,752 | 3,226,213 |   7,980 |    298.22 |      960.78 | NEGATED | outright    |\n",
                        "| **15** | NEGany~directly    |   8,317 |    0.12 |    2.13 |  11,654.57 | 86,330,752 | 3,226,213 |  54,441 |  2,034.48 |    6,282.52 | NEGATED | directly    |\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "def get_top_vals(df: pd.DataFrame,\n",
                "                 index_like: str = 'NEG',\n",
                "                 metric_filter: str | list = ['am_p1_given2', 'conservative_log_ratio'],\n",
                "                 k: int = 10,\n",
                "                 val_col: str = None,\n",
                "                 ignore_neg_adv: bool = True):\n",
                "    env_df = df.copy().loc[df.conservative_log_ratio >=\n",
                "                           1].filter(like=index_like, axis=0)\n",
                "    if ignore_neg_adv:\n",
                "        env_df = env_df.loc[~df.l2.isin(\n",
                "            (\"n't\", 'not', 'barely', 'never', 'no', 'none')), :]\n",
                "    if isinstance(metric_filter, str):\n",
                "        metric_filter = [metric_filter]\n",
                "\n",
                "    top = pd.concat([env_df.nlargest(k, m) for m in metric_filter]\n",
                "                    ).drop_duplicates(keep='first')\n",
                "\n",
                "    if val_col:\n",
                "        top = top[[val_col] + metric_filter]\n",
                "\n",
                "    return top.sort_values(metric_filter, ascending=False)\n",
                "\n",
                "\n",
                "[setdiff_top15, mirror_top15] = [\n",
                "    get_top_vals(adv_df, k=15)\n",
                "    for adv_df in (setdiff_adv, mirror_adv)\n",
                "]\n",
                "nb_show_table(setdiff_top15.filter(items=FOCUS).reset_index())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "15 Most Negatively Associated Adverbs for full dataset (_Absent Negative_ approximation) as ranked by $\\Delta P(1|2)$ (`dP1`) and $LRC$\n",
                "\n",
                "|        | `key`              |     `f` |   `dP1` |   `LRC` |       `G2` |        `N` |      `f1` |    `f2` |   `exp_f` |   `unexp_f` | `l1`    | `l2`        |\n",
                "|:-------|:-------------------|--------:|--------:|--------:|-----------:|-----------:|----------:|--------:|----------:|------------:|:--------|:------------|\n",
                "| **0**  | NEGany~necessarily |  42,708 |    0.72 |    6.23 | 219,003.46 | 86,330,752 | 3,226,213 |  56,694 |  2,118.68 |   40,589.32 | NEGATED | necessarily |\n",
                "| **1**  | NEGany~exactly     |  43,635 |    0.67 |    5.90 | 214,404.20 | 86,330,752 | 3,226,213 |  61,599 |  2,301.98 |   41,333.02 | NEGATED | exactly     |\n",
                "| **2**  | NEGany~that        | 165,411 |    0.63 |    5.62 | 781,016.11 | 86,330,752 | 3,226,213 | 250,392 |  9,357.24 |  156,053.76 | NEGATED | that        |\n",
                "| **3**  | NEGany~immediately |  57,319 |    0.52 |    4.96 | 239,462.58 | 86,330,752 | 3,226,213 | 103,177 |  3,855.76 |   53,463.24 | NEGATED | immediately |\n",
                "| **4**  | NEGany~yet         |  52,546 |    0.48 |    4.74 | 209,055.78 | 86,330,752 | 3,226,213 | 101,707 |  3,800.83 |   48,745.17 | NEGATED | yet         |\n",
                "| **5**  | NEGany~terribly    |  18,054 |    0.22 |    3.09 |  42,704.93 | 86,330,752 | 3,226,213 |  70,174 |  2,622.43 |   15,431.57 | NEGATED | terribly    |\n",
                "| **6**  | NEGany~remotely    |   5,679 |    0.22 |    3.03 |  13,354.33 | 86,330,752 | 3,226,213 |  22,194 |    829.40 |    4,849.60 | NEGATED | remotely    |\n",
                "| **7**  | NEGany~only        | 114,070 |    0.21 |    3.04 | 261,936.36 | 86,330,752 | 3,226,213 | 464,168 | 17,346.13 |   96,723.87 | NEGATED | only        |\n",
                "| **8**  | NEGany~altogether  |   4,575 |    0.18 |    2.75 |   9,468.00 | 86,330,752 | 3,226,213 |  20,636 |    771.17 |    3,803.82 | NEGATED | altogether  |\n",
                "| **9**  | NEGany~entirely    |  63,708 |    0.17 |    2.74 | 125,925.14 | 86,330,752 | 3,226,213 | 303,833 | 11,354.35 |   52,353.65 | NEGATED | entirely    |\n",
                "| **10** | NEGany~overly      |  24,707 |    0.17 |    2.66 |  46,993.58 | 86,330,752 | 3,226,213 | 122,058 |  4,561.35 |   20,145.65 | NEGATED | overly      |\n",
                "| **11** | NEGany~merely      |   5,944 |    0.13 |    2.26 |   9,223.66 | 86,330,752 | 3,226,213 |  35,608 |  1,330.68 |    4,613.32 | NEGATED | merely      |\n",
                "| **12** | NEGany~any         |  15,492 |    0.13 |    2.28 |  23,683.00 | 86,330,752 | 3,226,213 |  94,152 |  3,518.50 |   11,973.50 | NEGATED | any         |\n",
                "| **13** | NEGany~always      | 104,605 |    0.12 |    2.28 | 157,437.56 | 86,330,752 | 3,226,213 | 651,053 | 24,330.10 |   80,274.90 | NEGATED | always      |\n",
                "| **14** | NEGany~directly    |   8,317 |    0.12 |    2.13 |  11,654.57 | 86,330,752 | 3,226,213 |  54,441 |  2,034.48 |    6,282.52 | NEGATED | directly    |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 86,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "|        | `key`                |   `f` |   `dP1` |   `LRC` |      `G2` |       `N` |    `f1` |   `f2` |   `exp_f` |   `unexp_f` | `l1`   | `l2`          |\n",
                        "|:-------|:---------------------|------:|--------:|--------:|----------:|----------:|--------:|-------:|----------:|------------:|:-------|:--------------|\n",
                        "| **0**  | NEGmir~before        |   288 |    0.84 |    1.31 |  1,039.94 | 1,761,853 | 289,770 |    288 |     47.37 |      240.63 | NEGMIR | before        |\n",
                        "| **1**  | NEGmir~ever          | 4,688 |    0.77 |    5.73 | 14,624.92 | 1,761,853 | 289,770 |  5,027 |    826.79 |    3,861.21 | NEGMIR | ever          |\n",
                        "| **2**  | NEGmir~any           | 1,066 |    0.74 |    4.88 |  3,151.64 | 1,761,853 | 289,770 |  1,178 |    193.74 |      872.26 | NEGMIR | any           |\n",
                        "| **3**  | NEGmir~longer        |   802 |    0.74 |    4.71 |  2,350.18 | 1,761,853 | 289,770 |    891 |    146.54 |      655.46 | NEGMIR | longer        |\n",
                        "| **4**  | NEGmir~necessarily   |   960 |    0.71 |    4.47 |  2,679.92 | 1,761,853 | 289,770 |  1,100 |    180.92 |      779.08 | NEGMIR | necessarily   |\n",
                        "| **5**  | NEGmir~remotely      | 1,841 |    0.62 |    3.87 |  4,419.89 | 1,761,853 | 289,770 |  2,336 |    384.20 |    1,456.80 | NEGMIR | remotely      |\n",
                        "| **6**  | NEGmir~exactly       |   811 |    0.62 |    3.66 |  1,931.41 | 1,761,853 | 289,770 |  1,034 |    170.06 |      640.94 | NEGMIR | exactly       |\n",
                        "| **7**  | NEGmir~that          | 4,293 |    0.62 |    3.95 | 10,223.36 | 1,761,853 | 289,770 |  5,488 |    902.61 |    3,390.39 | NEGMIR | that          |\n",
                        "| **8**  | NEGmir~particularly  | 9,234 |    0.55 |    3.49 | 19,163.98 | 1,761,853 | 289,770 | 13,041 |  2,144.84 |    7,089.16 | NEGMIR | particularly  |\n",
                        "| **9**  | NEGmir~inherently    | 2,829 |    0.39 |    2.47 |  4,068.22 | 1,761,853 | 289,770 |  5,075 |    834.68 |    1,994.32 | NEGMIR | inherently    |\n",
                        "| **10** | NEGmir~overtly       |   390 |    0.36 |    1.98 |    512.59 | 1,761,853 | 289,770 |    738 |    121.38 |      268.62 | NEGMIR | overtly       |\n",
                        "| **11** | NEGmir~intrinsically |   430 |    0.32 |    1.75 |    479.46 | 1,761,853 | 289,770 |    896 |    147.36 |      282.64 | NEGMIR | intrinsically |\n",
                        "| **12** | NEGmir~especially    | 1,567 |    0.23 |    1.51 |  1,217.33 | 1,761,853 | 289,770 |  3,940 |    648.01 |      918.99 | NEGMIR | especially    |\n",
                        "| **13** | NEGmir~yet           |   319 |    0.23 |    1.20 |    242.11 | 1,761,853 | 289,770 |    810 |    133.22 |      185.78 | NEGMIR | yet           |\n",
                        "| **14** | NEGmir~fully         | 1,650 |    0.20 |    1.30 |  1,032.66 | 1,761,853 | 289,770 |  4,568 |    751.29 |      898.71 | NEGMIR | fully         |\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "nb_show_table(mirror_top15.filter(items=FOCUS).reset_index())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### _Previous_ Before Additional Filtering\n",
                "\n",
                "15 Most Negatively Associated Adverbs for `mirror` subset (_Present Positive_ approximation) as ranked by $\\Delta P(1|2)$ (`dP1`) and $LRC$\n",
                "\n",
                "|        | `key`                |   `f` |   `dP1` |   `LRC` |      `G2` |       `N` |    `f1` |   `f2` |   `exp_f` |   `unexp_f` | `l1`   | `l2`          |\n",
                "|:-------|:---------------------|------:|--------:|--------:|----------:|----------:|--------:|-------:|----------:|------------:|:-------|:--------------|\n",
                "| **0**  | NEGmir~before        |   290 |    0.84 |    5.11 |  1,080.52 | 2,032,082 | 293,963 |    294 |     42.53 |      247.47 | NEGMIR | before        |\n",
                "| **1**  | NEGmir~ever          | 4,718 |    0.77 |    5.57 | 15,340.34 | 2,032,082 | 293,963 |  5,179 |    749.20 |    3,968.80 | NEGMIR | ever          |\n",
                "| **2**  | NEGmir~exactly       |   813 |    0.59 |    3.51 |  1,939.47 | 2,032,082 | 293,963 |  1,114 |    161.15 |      651.85 | NEGMIR | exactly       |\n",
                "| **3**  | NEGmir~any           | 1,082 |    0.57 |    3.48 |  2,511.26 | 2,032,082 | 293,963 |  1,514 |    219.02 |      862.98 | NEGMIR | any           |\n",
                "| **4**  | NEGmir~remotely      | 1,846 |    0.54 |    3.35 |  4,009.84 | 2,032,082 | 293,963 |  2,717 |    393.04 |    1,452.96 | NEGMIR | remotely      |\n",
                "| **5**  | NEGmir~particularly  | 9,278 |    0.48 |    3.15 | 17,999.07 | 2,032,082 | 293,963 | 14,954 |  2,163.26 |    7,114.74 | NEGMIR | particularly  |\n",
                "| **6**  | NEGmir~that          | 4,338 |    0.44 |    2.86 |  7,632.21 | 2,032,082 | 293,963 |  7,472 |  1,080.91 |    3,257.09 | NEGMIR | that          |\n",
                "| **7**  | NEGmir~necessarily   |   971 |    0.43 |    2.66 |  1,688.91 | 2,032,082 | 293,963 |  1,681 |    243.18 |      727.82 | NEGMIR | necessarily   |\n",
                "| **8**  | NEGmir~inherently    | 2,872 |    0.36 |    2.42 |  4,160.38 | 2,032,082 | 293,963 |  5,649 |    817.19 |    2,054.81 | NEGMIR | inherently    |\n",
                "| **9**  | NEGmir~overtly       |   392 |    0.29 |    1.71 |    443.78 | 2,032,082 | 293,963 |    898 |    129.91 |      262.09 | NEGMIR | overtly       |\n",
                "| **10** | NEGmir~intrinsically |   432 |    0.29 |    1.73 |    487.95 | 2,032,082 | 293,963 |    991 |    143.36 |      288.64 | NEGMIR | intrinsically |\n",
                "| **11** | NEGmir~especially    | 1,573 |    0.21 |    1.49 |  1,232.03 | 2,032,082 | 293,963 |  4,400 |    636.51 |      936.49 | NEGMIR | especially    |\n",
                "| **12** | NEGmir~yet           |   320 |    0.21 |    1.18 |    242.23 | 2,032,082 | 293,963 |    909 |    131.50 |      188.50 | NEGMIR | yet           |\n",
                "| **13** | NEGmir~fully         | 1,668 |    0.18 |    1.31 |  1,086.24 | 2,032,082 | 293,963 |  5,084 |    735.46 |      932.54 | NEGMIR | fully         |\n",
                "| **14** | NEGmir~terribly      | 1,579 |    0.16 |    1.14 |    847.65 | 2,032,082 | 293,963 |  5,218 |    754.84 |      824.16 | NEGMIR | terribly      |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Or here, the least \"negative\"/most \"non-negative\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 87,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "#### Adverbs in top 15 for $LRC$, $G^2$, and $\\Delta P(\\texttt{env}|\\texttt{adv})$ measuring association with *Complement* Environments (`set_diff`, $*\\complement_{N^+}$)\n",
                        "\n",
                        "Total Tokens in dataset: $N = 86,330,752$\n",
                        "\n",
                        "|                    |          `f` |   `dP1` |   `LRC` |       `G2` |          `f1` |         `f2` |      `exp_f` |   `unexp_f` |   `dP2` |   `dP1_simple` |\n",
                        "|:-------------------|-------------:|--------:|--------:|-----------:|--------------:|-------------:|-------------:|------------:|--------:|---------------:|\n",
                        "| **increasingly**   |   404,356.00 |    0.04 |    6.00 |  29,076.69 | 83,102,035.00 |   404,521.00 |   389,392.16 |   14,963.84 |    0.00 |           1.00 |\n",
                        "| **relatively**     |   626,369.00 |    0.04 |    5.24 |  42,957.87 | 83,102,035.00 |   626,884.00 |   603,438.92 |   22,930.08 |    0.01 |           1.00 |\n",
                        "| **almost**         |   466,468.00 |    0.04 |    4.85 |  31,107.72 | 83,102,035.00 |   466,967.00 |   449,502.72 |   16,965.28 |    0.01 |           1.00 |\n",
                        "| **seemingly**      |   176,135.00 |    0.04 |    4.77 |  11,864.41 | 83,102,035.00 |   176,304.00 |   169,710.34 |    6,424.66 |    0.00 |           1.00 |\n",
                        "| **mostly**         |   212,255.00 |    0.04 |    4.71 |  14,160.67 | 83,102,035.00 |   212,478.00 |   204,531.45 |    7,723.55 |    0.00 |           1.00 |\n",
                        "| **pretty**         | 1,650,041.00 |    0.04 |    4.64 | 107,081.72 | 83,102,035.00 | 1,652,360.00 | 1,590,562.75 |   59,478.25 |    0.02 |           1.00 |\n",
                        "| **fairly**         |   401,326.00 |    0.04 |    4.50 |  25,904.34 | 83,102,035.00 |   401,879.00 |   386,848.97 |   14,477.03 |    0.00 |           1.00 |\n",
                        "| **partly**         |    80,461.00 |    0.04 |    4.50 |   5,418.01 | 83,102,035.00 |    80,538.00 |    77,525.93 |    2,935.07 |    0.00 |           1.00 |\n",
                        "| **rather**         |   402,067.00 |    0.04 |    4.44 |  25,775.15 | 83,102,035.00 |   402,648.00 |   387,589.21 |   14,477.79 |    0.00 |           1.00 |\n",
                        "| **largely**        |   186,382.00 |    0.04 |    4.36 |  12,018.96 | 83,102,035.00 |   186,638.00 |   179,657.85 |    6,724.15 |    0.00 |           1.00 |\n",
                        "| **sometimes**      |   154,738.00 |    0.04 |    4.25 |   9,894.59 | 83,102,035.00 |   154,963.00 |   149,167.48 |    5,570.52 |    0.00 |           1.00 |\n",
                        "| **also**           | 1,135,038.00 |    0.04 |    4.13 |  69,302.53 | 83,102,035.00 | 1,137,293.00 | 1,094,758.94 |   40,279.06 |    0.01 |           1.00 |\n",
                        "| **supposedly**     |    30,854.00 |    0.04 |    4.13 |   2,118.60 | 83,102,035.00 |    30,878.00 |    29,723.18 |    1,130.82 |    0.00 |           1.00 |\n",
                        "| **once**           |   108,130.00 |    0.04 |    4.01 |   6,779.79 | 83,102,035.00 |   108,308.00 |   104,257.35 |    3,872.65 |    0.00 |           1.00 |\n",
                        "| **certainly**      |   107,358.00 |    0.04 |    3.98 |   6,710.96 | 83,102,035.00 |   107,538.00 |   103,516.14 |    3,841.85 |    0.00 |           1.00 |\n",
                        "| **now**            |   456,039.00 |    0.04 |    3.88 |  27,026.68 | 83,102,035.00 |   457,065.00 |   439,971.05 |   16,067.95 |    0.01 |           1.00 |\n",
                        "| **most**           | 7,713,908.00 |    0.04 |    3.84 | 465,492.10 | 83,102,035.00 | 7,734,027.00 | 7,444,779.15 |  269,128.85 |    0.09 |           1.00 |\n",
                        "| **slightly**       |   399,124.00 |    0.03 |    3.63 |  22,711.33 | 83,102,035.00 |   400,193.00 |   385,226.03 |   13,897.97 |    0.00 |           1.00 |\n",
                        "| **still**          |   854,311.00 |    0.03 |    3.55 |  47,347.08 | 83,102,035.00 |   856,873.00 |   824,826.48 |   29,484.52 |    0.01 |           1.00 |\n",
                        "| **albeit**         |    17,169.00 |    0.04 |    3.53 |   1,270.78 | 83,102,035.00 |    17,172.00 |    16,529.78 |      639.22 |    0.00 |           1.00 |\n",
                        "| **admittedly**     |    13,998.00 |    0.04 |    3.34 |     945.10 | 83,102,035.00 |    14,011.00 |    13,487.00 |      511.00 |    0.00 |           1.00 |\n",
                        "| **understandably** |    13,111.00 |    0.04 |    3.24 |     879.17 | 83,102,035.00 |    13,124.00 |    12,633.17 |      477.83 |    0.00 |           1.00 |\n",
                        "| **highly**         |   789,705.00 |    0.03 |    3.08 |  39,233.91 | 83,102,035.00 |   793,031.00 |   763,372.13 |   26,332.87 |    0.01 |           1.00 |\n",
                        "| **extremely**      |   986,551.00 |    0.03 |    2.69 |  43,399.83 | 83,102,035.00 |   992,094.00 |   954,990.29 |   31,560.71 |    0.01 |           0.99 |\n",
                        "| **hopefully**      |     7,834.00 |    0.04 |    2.65 |     530.95 | 83,102,035.00 |     7,841.00 |     7,547.75 |      286.25 |    0.00 |           1.00 |\n",
                        "| **presumably**     |     8,011.00 |    0.04 |    2.59 |     568.20 | 83,102,035.00 |     8,015.00 |     7,715.24 |      295.76 |    0.00 |           1.00 |\n",
                        "| **less**           | 1,286,169.00 |    0.03 |    1.71 |  34,129.70 | 83,102,035.00 | 1,300,817.00 | 1,252,167.24 |   34,001.76 |    0.01 |           0.99 |\n",
                        "| **alternately**    |     4,148.00 |    0.04 |    1.11 |     294.82 | 83,102,035.00 |     4,150.00 |     3,994.79 |      153.21 |    0.00 |           1.00 |\n",
                        "| **more**           | 9,438,165.00 |    0.02 |    1.10 | 141,966.92 | 83,102,035.00 | 9,607,426.00 | 9,248,114.18 |  190,050.82 |    0.06 |           0.98 |\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "def show_top_positive(adv_df, \n",
                "                      k:int=15, \n",
                "                      filter_and_sort:list=['conservative_log_ratio', \n",
                "                                            'am_log_likelihood', \n",
                "                                            'am_p1_given2']):\n",
                "    \n",
                "    _l1 = adv_df.filter(like='O', axis=0).l1.iat[0].lower().strip()\n",
                "    _N = int(adv_df.N.iat[0])\n",
                "    ie = '(`set_diff`, $*\\complement_{N^+}$)' if _l1.startswith(\"com\") else '(`mirror`, $@P$)'\n",
                "    print(f'#### Adverbs in top {k}',\n",
                "          r'for $LRC$, $G^2$, and $\\Delta P(\\texttt{env}|\\texttt{adv})$',\n",
                "          f'measuring association with *{_l1.capitalize()}* Environments {ie}', \n",
                "          end='\\n'*2)\n",
                "    print(f'Total Tokens in dataset: $N = {_N:,}$')\n",
                "    nb_show_table(\n",
                "        get_top_vals(\n",
                "            adv_df.filter(items=FOCUS+['am_p2_given1', 'am_p1_given2_simple']), \n",
                "            k=k,\n",
                "            metric_filter=filter_and_sort,\n",
                "            index_like='O',  # should match \"POS\" & \"COM\", but neither \"NEG*\"\n",
                "            ).round(2).sort_values(filter_and_sort, ascending=False).set_index('l2').drop(['N', 'l1'], axis=1)\n",
                "    )\n",
                "    \n",
                "# All data\n",
                "show_top_positive(setdiff_adv, k=15)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Adverbs in top 15 for $LRC$, $G^2$, and $\\Delta P(\\texttt{env}|\\texttt{adv})$ measuring association with *Complement* Environments (`set_diff`, $*\\complement_{N^+}$)\n",
                "\n",
                "Total Tokens in dataset: $N = 86,330,752$\n",
                "\n",
                "|                    |          `f` |   `dP1` |   `LRC` |       `G2` |          `f1` |         `f2` |      `exp_f` |   `unexp_f` |   `dP2` |   `dP1_simple` |\n",
                "|:-------------------|-------------:|--------:|--------:|-----------:|--------------:|-------------:|-------------:|------------:|--------:|---------------:|\n",
                "| **increasingly**   |   404,356.00 |    0.04 |    6.00 |  29,076.69 | 83,102,035.00 |   404,521.00 |   389,392.16 |   14,963.84 |    0.00 |           1.00 |\n",
                "| **relatively**     |   626,369.00 |    0.04 |    5.24 |  42,957.87 | 83,102,035.00 |   626,884.00 |   603,438.92 |   22,930.08 |    0.01 |           1.00 |\n",
                "| **almost**         |   466,468.00 |    0.04 |    4.85 |  31,107.72 | 83,102,035.00 |   466,967.00 |   449,502.72 |   16,965.28 |    0.01 |           1.00 |\n",
                "| **seemingly**      |   176,135.00 |    0.04 |    4.77 |  11,864.41 | 83,102,035.00 |   176,304.00 |   169,710.34 |    6,424.66 |    0.00 |           1.00 |\n",
                "| **mostly**         |   212,255.00 |    0.04 |    4.71 |  14,160.67 | 83,102,035.00 |   212,478.00 |   204,531.45 |    7,723.55 |    0.00 |           1.00 |\n",
                "| **pretty**         | 1,650,041.00 |    0.04 |    4.64 | 107,081.72 | 83,102,035.00 | 1,652,360.00 | 1,590,562.75 |   59,478.25 |    0.02 |           1.00 |\n",
                "| **fairly**         |   401,326.00 |    0.04 |    4.50 |  25,904.34 | 83,102,035.00 |   401,879.00 |   386,848.97 |   14,477.03 |    0.00 |           1.00 |\n",
                "| **partly**         |    80,461.00 |    0.04 |    4.50 |   5,418.01 | 83,102,035.00 |    80,538.00 |    77,525.93 |    2,935.07 |    0.00 |           1.00 |\n",
                "| **rather**         |   402,067.00 |    0.04 |    4.44 |  25,775.15 | 83,102,035.00 |   402,648.00 |   387,589.21 |   14,477.79 |    0.00 |           1.00 |\n",
                "| **largely**        |   186,382.00 |    0.04 |    4.36 |  12,018.96 | 83,102,035.00 |   186,638.00 |   179,657.85 |    6,724.15 |    0.00 |           1.00 |\n",
                "| **sometimes**      |   154,738.00 |    0.04 |    4.25 |   9,894.59 | 83,102,035.00 |   154,963.00 |   149,167.48 |    5,570.52 |    0.00 |           1.00 |\n",
                "| **also**           | 1,135,038.00 |    0.04 |    4.13 |  69,302.53 | 83,102,035.00 | 1,137,293.00 | 1,094,758.94 |   40,279.06 |    0.01 |           1.00 |\n",
                "| **supposedly**     |    30,854.00 |    0.04 |    4.13 |   2,118.60 | 83,102,035.00 |    30,878.00 |    29,723.18 |    1,130.82 |    0.00 |           1.00 |\n",
                "| **once**           |   108,130.00 |    0.04 |    4.01 |   6,779.79 | 83,102,035.00 |   108,308.00 |   104,257.35 |    3,872.65 |    0.00 |           1.00 |\n",
                "| **certainly**      |   107,358.00 |    0.04 |    3.98 |   6,710.96 | 83,102,035.00 |   107,538.00 |   103,516.14 |    3,841.85 |    0.00 |           1.00 |\n",
                "| **now**            |   456,039.00 |    0.04 |    3.88 |  27,026.68 | 83,102,035.00 |   457,065.00 |   439,971.05 |   16,067.95 |    0.01 |           1.00 |\n",
                "| **most**           | 7,713,908.00 |    0.04 |    3.84 | 465,492.10 | 83,102,035.00 | 7,734,027.00 | 7,444,779.15 |  269,128.85 |    0.09 |           1.00 |\n",
                "| **slightly**       |   399,124.00 |    0.03 |    3.63 |  22,711.33 | 83,102,035.00 |   400,193.00 |   385,226.03 |   13,897.97 |    0.00 |           1.00 |\n",
                "| **still**          |   854,311.00 |    0.03 |    3.55 |  47,347.08 | 83,102,035.00 |   856,873.00 |   824,826.48 |   29,484.52 |    0.01 |           1.00 |\n",
                "| **albeit**         |    17,169.00 |    0.04 |    3.53 |   1,270.78 | 83,102,035.00 |    17,172.00 |    16,529.78 |      639.22 |    0.00 |           1.00 |\n",
                "| **admittedly**     |    13,998.00 |    0.04 |    3.34 |     945.10 | 83,102,035.00 |    14,011.00 |    13,487.00 |      511.00 |    0.00 |           1.00 |\n",
                "| **understandably** |    13,111.00 |    0.04 |    3.24 |     879.17 | 83,102,035.00 |    13,124.00 |    12,633.17 |      477.83 |    0.00 |           1.00 |\n",
                "| **highly**         |   789,705.00 |    0.03 |    3.08 |  39,233.91 | 83,102,035.00 |   793,031.00 |   763,372.13 |   26,332.87 |    0.01 |           1.00 |\n",
                "| **extremely**      |   986,551.00 |    0.03 |    2.69 |  43,399.83 | 83,102,035.00 |   992,094.00 |   954,990.29 |   31,560.71 |    0.01 |           0.99 |\n",
                "| **hopefully**      |     7,834.00 |    0.04 |    2.65 |     530.95 | 83,102,035.00 |     7,841.00 |     7,547.75 |      286.25 |    0.00 |           1.00 |\n",
                "| **presumably**     |     8,011.00 |    0.04 |    2.59 |     568.20 | 83,102,035.00 |     8,015.00 |     7,715.24 |      295.76 |    0.00 |           1.00 |\n",
                "| **less**           | 1,286,169.00 |    0.03 |    1.71 |  34,129.70 | 83,102,035.00 | 1,300,817.00 | 1,252,167.24 |   34,001.76 |    0.01 |           0.99 |\n",
                "| **alternately**    |     4,148.00 |    0.04 |    1.11 |     294.82 | 83,102,035.00 |     4,150.00 |     3,994.79 |      153.21 |    0.00 |           1.00 |\n",
                "| **more**           | 9,438,165.00 |    0.02 |    1.10 | 141,966.92 | 83,102,035.00 | 9,607,426.00 | 9,248,114.18 |  190,050.82 |    0.06 |           0.98 |\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 88,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "#### Adverbs in top 15 for $LRC$, $G^2$, and $\\Delta P(\\texttt{env}|\\texttt{adv})$ measuring association with *Posmir* Environments (`mirror`, $@P$)\n",
                        "\n",
                        "Total Tokens in dataset: $N = 1,761,853$\n",
                        "\n",
                        "|                  |        `f` |   `dP1` |   `LRC` |      `G2` |         `f1` |       `f2` |    `exp_f` |   `unexp_f` |   `dP2` |   `dP1_simple` |\n",
                        "|:-----------------|-----------:|--------:|--------:|----------:|-------------:|-----------:|-----------:|------------:|--------:|---------------:|\n",
                        "| **pretty**       |  24,599.00 |    0.16 |    4.59 |  7,751.98 | 1,472,036.00 |  24,729.00 |  20,661.19 |    3,937.81 |    0.02 |           0.99 |\n",
                        "| **rather**       |   8,259.00 |    0.16 |    4.39 |  2,671.93 | 1,472,036.00 |   8,291.00 |   6,927.17 |    1,331.83 |    0.01 |           1.00 |\n",
                        "| **plain**        |   5,053.00 |    0.16 |    4.15 |  1,660.56 | 1,472,036.00 |   5,069.00 |   4,235.17 |      817.83 |    0.00 |           1.00 |\n",
                        "| **fairly**       |   5,678.00 |    0.16 |    4.07 |  1,820.50 | 1,472,036.00 |   5,702.00 |   4,764.05 |      913.95 |    0.00 |           1.00 |\n",
                        "| **somewhat**     |   4,441.00 |    0.16 |    3.93 |  1,436.47 | 1,472,036.00 |   4,458.00 |   3,724.68 |      716.32 |    0.00 |           1.00 |\n",
                        "| **otherwise**    |   6,562.00 |    0.16 |    3.85 |  2,012.72 | 1,472,036.00 |   6,603.00 |   5,516.84 |    1,045.16 |    0.00 |           0.99 |\n",
                        "| **downright**    |   4,730.00 |    0.16 |    3.64 |  1,446.97 | 1,472,036.00 |   4,760.00 |   3,977.00 |      753.00 |    0.00 |           0.99 |\n",
                        "| **relatively**   |   5,328.00 |    0.16 |    3.61 |  1,603.27 | 1,472,036.00 |   5,366.00 |   4,483.32 |      844.68 |    0.00 |           0.99 |\n",
                        "| **already**      |   4,277.00 |    0.16 |    3.54 |  1,302.51 | 1,472,036.00 |   4,305.00 |   3,596.85 |      680.15 |    0.00 |           0.99 |\n",
                        "| **almost**       |   5,286.00 |    0.16 |    3.47 |  1,551.93 | 1,472,036.00 |   5,330.00 |   4,453.24 |      832.76 |    0.00 |           0.99 |\n",
                        "| **maybe**        |   2,573.00 |    0.16 |    3.43 |    846.03 | 1,472,036.00 |   2,581.00 |   2,156.44 |      416.56 |    0.00 |           1.00 |\n",
                        "| **equally**      |   7,235.00 |    0.15 |    3.36 |  2,018.36 | 1,472,036.00 |   7,314.00 |   6,110.88 |    1,124.12 |    0.00 |           0.99 |\n",
                        "| **perhaps**      |   3,353.00 |    0.16 |    3.22 |    989.23 | 1,472,036.00 |   3,380.00 |   2,824.00 |      528.99 |    0.00 |           0.99 |\n",
                        "| **highly**       |   9,133.00 |    0.15 |    3.18 |  2,407.55 | 1,472,036.00 |   9,260.00 |   7,736.77 |    1,396.23 |    0.01 |           0.99 |\n",
                        "| **slightly**     |   7,524.00 |    0.15 |    3.09 |  1,970.46 | 1,472,036.00 |   7,631.00 |   6,375.73 |    1,148.27 |    0.00 |           0.99 |\n",
                        "| **extremely**    |  17,254.00 |    0.15 |    3.06 |  4,253.50 | 1,472,036.00 |  17,559.00 |  14,670.62 |    2,583.38 |    0.01 |           0.98 |\n",
                        "| **also**         |   6,904.00 |    0.15 |    3.02 |  1,789.00 | 1,472,036.00 |   7,006.00 |   5,853.54 |    1,050.46 |    0.00 |           0.99 |\n",
                        "| **simply**       |   7,695.00 |    0.15 |    2.90 |  1,912.92 | 1,472,036.00 |   7,826.00 |   6,538.66 |    1,156.34 |    0.00 |           0.98 |\n",
                        "| **still**        |  13,239.00 |    0.15 |    2.85 |  3,122.90 | 1,472,036.00 |  13,504.00 |  11,282.65 |    1,956.35 |    0.01 |           0.98 |\n",
                        "| **incredibly**   |   8,847.00 |    0.15 |    2.81 |  2,118.18 | 1,472,036.00 |   9,016.00 |   7,532.91 |    1,314.09 |    0.01 |           0.98 |\n",
                        "| **just**         |  27,625.00 |    0.14 |    2.60 |  5,785.97 | 1,472,036.00 |  28,371.00 |  23,704.10 |    3,920.90 |    0.02 |           0.97 |\n",
                        "| **surprisingly** |   1,439.00 |    0.16 |    2.50 |    427.85 | 1,472,036.00 |   1,450.00 |   1,211.48 |      227.52 |    0.00 |           0.99 |\n",
                        "| **sometimes**    |   1,302.00 |    0.16 |    2.36 |    380.76 | 1,472,036.00 |   1,313.00 |   1,097.02 |      204.98 |    0.00 |           0.99 |\n",
                        "| **even**         |  58,121.00 |    0.12 |    1.89 |  8,471.57 | 1,472,036.00 |  60,933.00 |  50,909.79 |    7,211.21 |    0.03 |           0.95 |\n",
                        "| **very**         | 175,104.00 |    0.13 |    1.88 | 25,839.60 | 1,472,036.00 | 184,008.00 | 153,739.50 |   21,364.50 |    0.09 |           0.95 |\n",
                        "| **strangely**    |     696.00 |    0.16 |    1.56 |    202.78 | 1,472,036.00 |     702.00 |     586.52 |      109.48 |    0.00 |           0.99 |\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Mirror Data ~ explicitly positive ~ positive trigger present\n",
                "show_top_positive(mirror_adv, k=15)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Adverbs in top 15 for $LRC$, $G^2$, and $\\Delta P(\\texttt{env}|\\texttt{adv})$ measuring association with *Posmir* Environments (`mirror`, $@P$)\n",
                "\n",
                "Total Tokens in dataset: $N = 1,761,853$\n",
                "\n",
                "|                  |        `f` |   `dP1` |   `LRC` |      `G2` |         `f1` |       `f2` |    `exp_f` |   `unexp_f` |   `dP2` |   `dP1_simple` |\n",
                "|:-----------------|-----------:|--------:|--------:|----------:|-------------:|-----------:|-----------:|------------:|--------:|---------------:|\n",
                "| **pretty**       |  24,599.00 |    0.16 |    4.59 |  7,751.98 | 1,472,036.00 |  24,729.00 |  20,661.19 |    3,937.81 |    0.02 |           0.99 |\n",
                "| **rather**       |   8,259.00 |    0.16 |    4.39 |  2,671.93 | 1,472,036.00 |   8,291.00 |   6,927.17 |    1,331.83 |    0.01 |           1.00 |\n",
                "| **plain**        |   5,053.00 |    0.16 |    4.15 |  1,660.56 | 1,472,036.00 |   5,069.00 |   4,235.17 |      817.83 |    0.00 |           1.00 |\n",
                "| **fairly**       |   5,678.00 |    0.16 |    4.07 |  1,820.50 | 1,472,036.00 |   5,702.00 |   4,764.05 |      913.95 |    0.00 |           1.00 |\n",
                "| **somewhat**     |   4,441.00 |    0.16 |    3.93 |  1,436.47 | 1,472,036.00 |   4,458.00 |   3,724.68 |      716.32 |    0.00 |           1.00 |\n",
                "| **otherwise**    |   6,562.00 |    0.16 |    3.85 |  2,012.72 | 1,472,036.00 |   6,603.00 |   5,516.84 |    1,045.16 |    0.00 |           0.99 |\n",
                "| **downright**    |   4,730.00 |    0.16 |    3.64 |  1,446.97 | 1,472,036.00 |   4,760.00 |   3,977.00 |      753.00 |    0.00 |           0.99 |\n",
                "| **relatively**   |   5,328.00 |    0.16 |    3.61 |  1,603.27 | 1,472,036.00 |   5,366.00 |   4,483.32 |      844.68 |    0.00 |           0.99 |\n",
                "| **already**      |   4,277.00 |    0.16 |    3.54 |  1,302.51 | 1,472,036.00 |   4,305.00 |   3,596.85 |      680.15 |    0.00 |           0.99 |\n",
                "| **almost**       |   5,286.00 |    0.16 |    3.47 |  1,551.93 | 1,472,036.00 |   5,330.00 |   4,453.24 |      832.76 |    0.00 |           0.99 |\n",
                "| **maybe**        |   2,573.00 |    0.16 |    3.43 |    846.03 | 1,472,036.00 |   2,581.00 |   2,156.44 |      416.56 |    0.00 |           1.00 |\n",
                "| **equally**      |   7,235.00 |    0.15 |    3.36 |  2,018.36 | 1,472,036.00 |   7,314.00 |   6,110.88 |    1,124.12 |    0.00 |           0.99 |\n",
                "| **perhaps**      |   3,353.00 |    0.16 |    3.22 |    989.23 | 1,472,036.00 |   3,380.00 |   2,824.00 |      528.99 |    0.00 |           0.99 |\n",
                "| **highly**       |   9,133.00 |    0.15 |    3.18 |  2,407.55 | 1,472,036.00 |   9,260.00 |   7,736.77 |    1,396.23 |    0.01 |           0.99 |\n",
                "| **slightly**     |   7,524.00 |    0.15 |    3.09 |  1,970.46 | 1,472,036.00 |   7,631.00 |   6,375.73 |    1,148.27 |    0.00 |           0.99 |\n",
                "| **extremely**    |  17,254.00 |    0.15 |    3.06 |  4,253.50 | 1,472,036.00 |  17,559.00 |  14,670.62 |    2,583.38 |    0.01 |           0.98 |\n",
                "| **also**         |   6,904.00 |    0.15 |    3.02 |  1,789.00 | 1,472,036.00 |   7,006.00 |   5,853.54 |    1,050.46 |    0.00 |           0.99 |\n",
                "| **simply**       |   7,695.00 |    0.15 |    2.90 |  1,912.92 | 1,472,036.00 |   7,826.00 |   6,538.66 |    1,156.34 |    0.00 |           0.98 |\n",
                "| **still**        |  13,239.00 |    0.15 |    2.85 |  3,122.90 | 1,472,036.00 |  13,504.00 |  11,282.65 |    1,956.35 |    0.01 |           0.98 |\n",
                "| **incredibly**   |   8,847.00 |    0.15 |    2.81 |  2,118.18 | 1,472,036.00 |   9,016.00 |   7,532.91 |    1,314.09 |    0.01 |           0.98 |\n",
                "| **just**         |  27,625.00 |    0.14 |    2.60 |  5,785.97 | 1,472,036.00 |  28,371.00 |  23,704.10 |    3,920.90 |    0.02 |           0.97 |\n",
                "| **surprisingly** |   1,439.00 |    0.16 |    2.50 |    427.85 | 1,472,036.00 |   1,450.00 |   1,211.48 |      227.52 |    0.00 |           0.99 |\n",
                "| **sometimes**    |   1,302.00 |    0.16 |    2.36 |    380.76 | 1,472,036.00 |   1,313.00 |   1,097.02 |      204.98 |    0.00 |           0.99 |\n",
                "| **even**         |  58,121.00 |    0.12 |    1.89 |  8,471.57 | 1,472,036.00 |  60,933.00 |  50,909.79 |    7,211.21 |    0.03 |           0.95 |\n",
                "| **very**         | 175,104.00 |    0.13 |    1.88 | 25,839.60 | 1,472,036.00 | 184,008.00 | 153,739.50 |   21,364.50 |    0.09 |           0.95 |\n",
                "| **strangely**    |     696.00 |    0.16 |    1.56 |    202.78 | 1,472,036.00 |     702.00 |     586.52 |      109.48 |    0.00 |           0.99 |\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n",
                "##### _Previously_ \n",
                "\n",
                "`mirror` subset (_Present Positive_ approximation) \n",
                "\n",
                "|                    |    `f` | `dP1` | `LRC` |     `G2` |       `N` |      `f1` |   `f2` |   `exp_f` | `unexp_f` | `l1`   | `l2`       |\n",
                "|:-------------------|-------:|------:|------:|---------:|----------:|----------:|-------:|----------:|----------:|:-------|:-----------|\n",
                "| **POS~pretty**     | 26,788 |  0.14 |  4.48 | 7,278.87 | 2,032,082 | 1,738,105 | 26,919 | 23,024.69 |  3,763.31 | POSMIR | pretty     |\n",
                "| **POS~rather**     |  9,290 |  0.14 |  4.34 | 2,607.01 | 2,032,082 | 1,738,105 |  9,322 |  7,973.41 |  1,316.59 | POSMIR | rather     |\n",
                "| **POS~plain**      |  6,049 |  0.14 |  4.19 | 1,733.36 | 2,032,082 | 1,738,105 |  6,065 |  5,187.59 |    861.41 | POSMIR | plain      |\n",
                "| **POS~otherwise**  |  9,368 |  0.14 |  4.12 | 2,558.73 | 2,032,082 | 1,738,105 |  9,410 |  8,048.68 |  1,319.32 | POSMIR | otherwise  |\n",
                "| **POS~fairly**     |  6,184 |  0.14 |  3.97 | 1,713.96 | 2,032,082 | 1,738,105 |  6,208 |  5,309.90 |    874.10 | POSMIR | fairly     |\n",
                "| **POS~somewhat**   |  4,961 |  0.14 |  3.87 | 1,391.12 | 2,032,082 | 1,738,105 |  4,978 |  4,257.84 |    703.16 | POSMIR | somewhat   |\n",
                "| **POS~downright**  |  5,502 |  0.14 |  3.63 | 1,465.04 | 2,032,082 | 1,738,105 |  5,532 |  4,731.70 |    770.30 | POSMIR | downright  |\n",
                "| **POS~already**    |  5,035 |  0.14 |  3.56 | 1,336.93 | 2,032,082 | 1,738,105 |  5,063 |  4,330.55 |    704.45 | POSMIR | already    |\n",
                "| **POS~relatively** |  5,774 |  0.14 |  3.51 | 1,496.02 | 2,032,082 | 1,738,105 |  5,812 |  4,971.19 |    802.81 | POSMIR | relatively |\n",
                "| **POS~maybe**      |  2,998 |  0.14 |  3.43 |   857.78 | 2,032,082 | 1,738,105 |  3,006 |  2,571.13 |    426.87 | POSMIR | maybe      |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Compile top NEG~adverb associations across both approximation methods"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 89,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_backup(lower_floor: int = 100,\n",
                "                loaded_path: Path = adv_am_paths['RBdirect']) -> pd.DataFrame:\n",
                "    located_paths = tuple(loaded_path.parent.glob(\n",
                "        f'*35f-7c_min{lower_floor}x*{PKL_SUFF}'))\n",
                "    if any(located_paths):\n",
                "        backup_df = pd.read_pickle(located_paths[0])\n",
                "\n",
                "        backup_df = backup_df.filter(like='NEG', axis=0).filter(\n",
                "            items=FOCUS).reset_index().set_index('l2')\n",
                "        backup_df.index.name = 'adv'\n",
                "        return backup_df\n",
                "    else:\n",
                "        return []\n",
                "\n",
                "\n",
                "def uncat(df):\n",
                "    cats = df.select_dtypes('category').columns\n",
                "    df[cats] = df[cats].astype('string')\n",
                "    # print(df.dtypes)\n",
                "    return df, cats\n",
                "\n",
                "\n",
                "def fill_empties(name_1, name_2, both, loaded_paths):\n",
                "    for name in (name_1, name_2):\n",
                "        name = name.strip('_')\n",
                "        path = loaded_paths['RBdirect'] if name == 'SET' else loaded_paths['NEGmirror']\n",
                "        if any(both[f'f_{name}'].isna()):\n",
                "\n",
                "            floor = 100\n",
                "            neg_backup = load_backup(floor, loaded_path=path)\n",
                "            if not any(neg_backup):\n",
                "                print('Error. Backup data not found. [in fill_empties()]')\n",
                "\n",
                "            neg_backup.columns = (pd.Series(adjust_assoc_columns(neg_backup.columns)\n",
                "                                            ) + f'_{name}').to_list()\n",
                "            both, cats = uncat(both)\n",
                "            neg_backup, __ = uncat(neg_backup)\n",
                "\n",
                "            undefined_adv = both.loc[\n",
                "                both[f'f_{name}'].isna(), :].index.to_list()\n",
                "\n",
                "            both.loc[undefined_adv,\n",
                "                     neg_backup.columns] = neg_backup.filter(items=undefined_adv, axis=0)\n",
                "\n",
                "            both[cats] = both[cats].astype('category')\n",
                "\n",
                "    return both\n",
                "\n",
                "\n",
                "def combine_top(df_1: pd.DataFrame,\n",
                "                name_1: str,\n",
                "                df_2: pd.DataFrame,\n",
                "                name_2: str,\n",
                "                env_filter: str = 'NEG',\n",
                "                filter_items: list = FOCUS,\n",
                "                k: int = 10) -> pd.DataFrame:\n",
                "    print('### Adverb Selections')\n",
                "    top_dfs = [\n",
                "        (get_top_vals(adv_df,  k=k,\n",
                "                      index_like=env_filter,\n",
                "                      metric_filter=['am_p1_given2',\n",
                "                                     'conservative_log_ratio'])\n",
                "         .sort_values('conservative_log_ratio', ascending=False))\n",
                "        for adv_df in [df_1, df_2]\n",
                "    ]\n",
                "    for i, name in enumerate([name_1, name_2]):\n",
                "\n",
                "        print_iter(\n",
                "            [f'_{w}_' for w in top_dfs[i].l2], bullet='1.',\n",
                "            header=(f'`{name}`: union of top {k} adverbs ranked by '\n",
                "                    r'$LRC$ & $\\Delta P(\\texttt{env}|\\texttt{adv})$'))\n",
                "    top_adv_lists = [dx.l2.to_list() for dx in top_dfs]\n",
                "    top_adv = pd.Series(top_adv_lists[0] + top_adv_lists[1]).drop_duplicates()\n",
                "    # top_adv = pd.concat((top_dfs[0].l2, top_dfs[1].l2)).drop_duplicates()\n",
                "\n",
                "    print_iter(\n",
                "        [f'_{w}_' for w in top_adv], bullet='1.',\n",
                "        header=f'Union of top adverbs for `{name_1}` and `{name_2}`. (Novel `{name_2}` adverbs listed last)')\n",
                "    print(f'\\n### `{name_1}` Adverb Associations (in initially loaded table)\\n')\n",
                "    df_1 = narrow_selection(df_1, top_adv, env_filter, filter_items)\n",
                "    print(f'\\n### `{name_2}` Adverb Associations (in initially loaded table)\\n')\n",
                "    df_2 = narrow_selection(df_2, top_adv, env_filter, filter_items)\n",
                "\n",
                "    name_1, name_2 = [f\"_{n.strip('_')}\" for n in [name_1, name_2]]\n",
                "    both = df_1.join(df_2, how=\"outer\", lsuffix=name_1, rsuffix=name_2)\n",
                "\n",
                "    # ! Empty cells need to be filled _before_ calculating mean\n",
                "    both = fill_empties(name_1, name_2, both, adv_am_paths)\n",
                "    both = force_ints(both)\n",
                "    both = add_means(both)\n",
                "    both = add_f_ratio(both, name_2, name_1)\n",
                "    return both.sort_values('mean_dP1', ascending=False)\n",
                "\n",
                "\n",
                "def add_f_ratio(df, subset_name, superset_name):\n",
                "    counts = df.filter(regex=r'^[Nf][12]?').columns.str.split(\n",
                "        '_').str.get(0).drop_duplicates()\n",
                "    for count in counts:\n",
                "        ratio_col = f'ratio_{count}{subset_name}'\n",
                "        df[ratio_col] = (df[f'{count}{subset_name}']\n",
                "                         / df[f'{count}{superset_name}'])\n",
                "        # print(df.filter(like=count))\n",
                "    return df\n",
                "\n",
                "def add_means(both):\n",
                "    for metric in (both.select_dtypes(include='number').columns.to_series()\n",
                "                   .str.replace(r'_(MIR|SET)$', '', regex=True).unique()):\n",
                "        both[f'mean_{snake_to_camel(metric)}'] = both.filter(\n",
                "            regex=f\"^{metric}\").agg('mean', axis='columns')\n",
                "    return both\n",
                "\n",
                "\n",
                "def narrow_selection(df: pd.DataFrame,\n",
                "                     top_adv: list,\n",
                "                     env_filter: str = 'NEG',\n",
                "                     filter_items: list = FOCUS):\n",
                "    df = adjust_assoc_columns(\n",
                "        df.filter(items=filter_items)\n",
                "        .filter(like=env_filter, axis=0)\n",
                "        .reset_index().set_index('l2')\n",
                "        .filter(top_adv, axis=0)).sort_values(['LRC', 'dP1'], ascending=False)\n",
                "    df.index.name = 'adv'\n",
                "    nb_show_table(df.drop(['N', 'key', 'l1'], axis=1).round(2).sort_values(['LRC','dP1', ], ascending=False))\n",
                "\n",
                "    return df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 90,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "### Adverb Selections\n",
                        "\n",
                        "`SET`: union of top 5 adverbs ranked by $LRC$ & $\\Delta P(\\texttt{env}|\\texttt{adv})$\n",
                        "1. _necessarily_\n",
                        "1. _exactly_\n",
                        "1. _that_\n",
                        "1. _immediately_\n",
                        "1. _yet_\n",
                        "\n",
                        "`MIR`: union of top 5 adverbs ranked by $LRC$ & $\\Delta P(\\texttt{env}|\\texttt{adv})$\n",
                        "1. _ever_\n",
                        "1. _any_\n",
                        "1. _longer_\n",
                        "1. _necessarily_\n",
                        "1. _that_\n",
                        "1. _before_\n",
                        "\n",
                        "Union of top adverbs for `SET` and `MIR`. (Novel `MIR` adverbs listed last)\n",
                        "1. _necessarily_\n",
                        "1. _exactly_\n",
                        "1. _that_\n",
                        "1. _immediately_\n",
                        "1. _yet_\n",
                        "1. _ever_\n",
                        "1. _any_\n",
                        "1. _longer_\n",
                        "1. _before_\n",
                        "\n",
                        "### `SET` Adverb Associations (in initially loaded table)\n",
                        "\n",
                        "\n",
                        "|                 |        `f` |   `dP1` |   `LRC` |       `G2` |         `f1` |       `f2` |   `exp_f` |   `unexp_f` |\n",
                        "|:----------------|-----------:|--------:|--------:|-----------:|-------------:|-----------:|----------:|------------:|\n",
                        "| **necessarily** |  42,708.00 |    0.72 |    6.23 | 219,003.46 | 3,226,213.00 |  56,694.00 |  2,118.68 |   40,589.32 |\n",
                        "| **exactly**     |  43,635.00 |    0.67 |    5.90 | 214,404.20 | 3,226,213.00 |  61,599.00 |  2,301.98 |   41,333.02 |\n",
                        "| **that**        | 165,411.00 |    0.63 |    5.62 | 781,016.11 | 3,226,213.00 | 250,392.00 |  9,357.24 |  156,053.76 |\n",
                        "| **immediately** |  57,319.00 |    0.52 |    4.96 | 239,462.58 | 3,226,213.00 | 103,177.00 |  3,855.76 |   53,463.24 |\n",
                        "| **yet**         |  52,546.00 |    0.48 |    4.74 | 209,055.78 | 3,226,213.00 | 101,707.00 |  3,800.83 |   48,745.17 |\n",
                        "| **any**         |  15,492.00 |    0.13 |    2.28 |  23,683.00 | 3,226,213.00 |  94,152.00 |  3,518.50 |   11,973.50 |\n",
                        "| **ever**        |   5,967.00 |    0.01 |    0.28 |     353.58 | 3,226,213.00 | 124,592.00 |  4,656.05 |    1,310.95 |\n",
                        "| **longer**      |   1,448.00 |   -0.03 |   -1.87 |  -4,977.41 | 3,226,213.00 | 157,984.00 |  5,903.92 |   -4,455.92 |\n",
                        "\n",
                        "\n",
                        "### `MIR` Adverb Associations (in initially loaded table)\n",
                        "\n",
                        "\n",
                        "|                 |      `f` |   `dP1` |   `LRC` |      `G2` |       `f1` |     `f2` |   `exp_f` |   `unexp_f` |\n",
                        "|:----------------|---------:|--------:|--------:|----------:|-----------:|---------:|----------:|------------:|\n",
                        "| **ever**        | 4,688.00 |    0.77 |    5.73 | 14,624.92 | 289,770.00 | 5,027.00 |    826.79 |    3,861.21 |\n",
                        "| **any**         | 1,066.00 |    0.74 |    4.88 |  3,151.64 | 289,770.00 | 1,178.00 |    193.74 |      872.26 |\n",
                        "| **longer**      |   802.00 |    0.74 |    4.71 |  2,350.18 | 289,770.00 |   891.00 |    146.54 |      655.46 |\n",
                        "| **necessarily** |   960.00 |    0.71 |    4.47 |  2,679.92 | 289,770.00 | 1,100.00 |    180.92 |      779.08 |\n",
                        "| **that**        | 4,293.00 |    0.62 |    3.95 | 10,223.36 | 289,770.00 | 5,488.00 |    902.61 |    3,390.39 |\n",
                        "| **exactly**     |   811.00 |    0.62 |    3.66 |  1,931.41 | 289,770.00 | 1,034.00 |    170.06 |      640.94 |\n",
                        "| **before**      |   288.00 |    0.84 |    1.31 |  1,039.94 | 289,770.00 |   288.00 |     47.37 |      240.63 |\n",
                        "| **yet**         |   319.00 |    0.23 |    1.20 |    242.11 | 289,770.00 |   810.00 |    133.22 |      185.78 |\n",
                        "| **immediately** |   403.00 |    0.17 |    0.93 |    212.93 | 289,770.00 | 1,193.00 |    196.21 |      206.79 |\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "C = combine_top(setdiff_adv, 'SET',\n",
                "                mirror_adv, 'MIR', k=K)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Adverb Selections\n",
                "\n",
                "`SET`: union of top 6 adverbs ranked by $LRC$ & $\\Delta P(\\texttt{env}|\\texttt{adv})$\n",
                "1. _necessarily_\n",
                "1. _exactly_\n",
                "1. _that_\n",
                "1. _immediately_\n",
                "1. _yet_\n",
                "1. _terribly_\n",
                "\n",
                "`MIR`: union of top 6 adverbs ranked by $LRC$ & $\\Delta P(\\texttt{env}|\\texttt{adv})$\n",
                "1. _ever_\n",
                "1. _any_\n",
                "1. _longer_\n",
                "1. _necessarily_\n",
                "1. _that_\n",
                "1. _remotely_\n",
                "1. _before_\n",
                "\n",
                "Union of top adverbs for `SET` and `MIR`. (Novel `MIR` adverbs listed last)\n",
                "1. _necessarily_\n",
                "1. _exactly_\n",
                "1. _that_\n",
                "1. _immediately_\n",
                "1. _yet_\n",
                "1. _terribly_\n",
                "1. _ever_\n",
                "1. _any_\n",
                "1. _longer_\n",
                "1. _remotely_\n",
                "1. _before_\n",
                "\n",
                "### `SET` Adverb Associations (in initially loaded table)\n",
                "\n",
                "\n",
                "|                 |        `f` |   `dP1` |   `LRC` |       `G2` |         `f1` |       `f2` |   `exp_f` |   `unexp_f` |\n",
                "|:----------------|-----------:|--------:|--------:|-----------:|-------------:|-----------:|----------:|------------:|\n",
                "| **necessarily** |  42,708.00 |    0.72 |    6.23 | 219,003.46 | 3,226,213.00 |  56,694.00 |  2,118.68 |   40,589.32 |\n",
                "| **exactly**     |  43,635.00 |    0.67 |    5.90 | 214,404.20 | 3,226,213.00 |  61,599.00 |  2,301.98 |   41,333.02 |\n",
                "| **that**        | 165,411.00 |    0.63 |    5.62 | 781,016.11 | 3,226,213.00 | 250,392.00 |  9,357.24 |  156,053.76 |\n",
                "| **immediately** |  57,319.00 |    0.52 |    4.96 | 239,462.58 | 3,226,213.00 | 103,177.00 |  3,855.76 |   53,463.24 |\n",
                "| **yet**         |  52,546.00 |    0.48 |    4.74 | 209,055.78 | 3,226,213.00 | 101,707.00 |  3,800.83 |   48,745.17 |\n",
                "| **terribly**    |  18,054.00 |    0.22 |    3.09 |  42,704.93 | 3,226,213.00 |  70,174.00 |  2,622.43 |   15,431.57 |\n",
                "| **remotely**    |   5,679.00 |    0.22 |    3.03 |  13,354.33 | 3,226,213.00 |  22,194.00 |    829.40 |    4,849.60 |\n",
                "| **any**         |  15,492.00 |    0.13 |    2.28 |  23,683.00 | 3,226,213.00 |  94,152.00 |  3,518.50 |   11,973.50 |\n",
                "| **ever**        |   5,967.00 |    0.01 |    0.28 |     353.58 | 3,226,213.00 | 124,592.00 |  4,656.05 |    1,310.95 |\n",
                "| **longer**      |   1,448.00 |   -0.03 |   -1.87 |  -4,977.41 | 3,226,213.00 | 157,984.00 |  5,903.92 |   -4,455.92 |\n",
                "\n",
                "\n",
                "### `MIR` Adverb Associations (in initially loaded table)\n",
                "\n",
                "\n",
                "|                 |      `f` |   `dP1` |   `LRC` |      `G2` |       `f1` |     `f2` |   `exp_f` |   `unexp_f` |\n",
                "|:----------------|---------:|--------:|--------:|----------:|-----------:|---------:|----------:|------------:|\n",
                "| **ever**        | 4,688.00 |    0.77 |    5.73 | 14,624.92 | 289,770.00 | 5,027.00 |    826.79 |    3,861.21 |\n",
                "| **any**         | 1,066.00 |    0.74 |    4.88 |  3,151.64 | 289,770.00 | 1,178.00 |    193.74 |      872.26 |\n",
                "| **longer**      |   802.00 |    0.74 |    4.71 |  2,350.18 | 289,770.00 |   891.00 |    146.54 |      655.46 |\n",
                "| **necessarily** |   960.00 |    0.71 |    4.47 |  2,679.92 | 289,770.00 | 1,100.00 |    180.92 |      779.08 |\n",
                "| **that**        | 4,293.00 |    0.62 |    3.95 | 10,223.36 | 289,770.00 | 5,488.00 |    902.61 |    3,390.39 |\n",
                "| **remotely**    | 1,841.00 |    0.62 |    3.87 |  4,419.89 | 289,770.00 | 2,336.00 |    384.20 |    1,456.80 |\n",
                "| **exactly**     |   811.00 |    0.62 |    3.66 |  1,931.41 | 289,770.00 | 1,034.00 |    170.06 |      640.94 |\n",
                "| **before**      |   288.00 |    0.84 |    1.31 |  1,039.94 | 289,770.00 |   288.00 |     47.37 |      240.63 |\n",
                "| **yet**         |   319.00 |    0.23 |    1.20 |    242.11 | 289,770.00 |   810.00 |    133.22 |      185.78 |\n",
                "| **terribly**    | 1,571.00 |    0.18 |    1.18 |    857.86 | 289,770.00 | 4,596.00 |    755.90 |      815.10 |\n",
                "| **immediately** |   403.00 |    0.17 |    0.93 |    212.93 | 289,770.00 | 1,193.00 |    196.21 |      206.79 |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "---\n",
                "\n",
                "### $\\textbf{\\textit{Previous}}$ `MIR` Adverb Associations (in initially loaded table)\n",
                "\n",
                "`MIR`: union of top 5 adverbs ranked by $LRC$ & $\\Delta P(\\texttt{env}|\\texttt{adv})$\n",
                "\n",
                "1. _ever_\n",
                "1. _before_\n",
                "1. _exactly_\n",
                "1. _any_\n",
                "1. _remotely_\n",
                "\n",
                "|                 | `key`              |   `f` |   `dP1` |   `LRC` |      `G2` |       `N` |    `f1` |   `f2` |   `exp_f` |   `unexp_f` | `l1`   |\n",
                "|:----------------|:-------------------|------:|--------:|--------:|----------:|----------:|--------:|-------:|----------:|------------:|:-------|\n",
                "| **before**      | NEGmir~before      |   290 |    0.84 |    5.11 |  1,080.52 | 2,032,082 | 293,963 |    294 |     42.53 |      247.47 | NEGMIR |\n",
                "| **ever**        | NEGmir~ever        | 4,718 |    0.77 |    5.57 | 15,340.34 | 2,032,082 | 293,963 |  5,179 |    749.20 |    3,968.80 | NEGMIR |\n",
                "| **exactly**     | NEGmir~exactly     |   813 |    0.59 |    3.51 |  1,939.47 | 2,032,082 | 293,963 |  1,114 |    161.15 |      651.85 | NEGMIR |\n",
                "| **any**         | NEGmir~any         | 1,082 |    0.57 |    3.48 |  2,511.26 | 2,032,082 | 293,963 |  1,514 |    219.02 |      862.98 | NEGMIR |\n",
                "| **remotely**    | NEGmir~remotely    | 1,846 |    0.54 |    3.35 |  4,009.84 | 2,032,082 | 293,963 |  2,717 |    393.04 |    1,452.96 | NEGMIR |\n",
                "| **that**        | NEGmir~that        | 4,338 |    0.44 |    2.86 |  7,632.21 | 2,032,082 | 293,963 |  7,472 |  1,080.91 |    3,257.09 | NEGMIR |\n",
                "| **necessarily** | NEGmir~necessarily |   971 |    0.43 |    2.66 |  1,688.91 | 2,032,082 | 293,963 |  1,681 |    243.18 |      727.82 | NEGMIR |\n",
                "| **yet**         | NEGmir~yet         |   320 |    0.21 |    1.18 |    242.23 | 2,032,082 | 293,963 |    909 |    131.50 |      188.50 | NEGMIR |\n",
                "| **immediately** | NEGmir~immediately |   407 |    0.14 |    0.79 |    181.20 | 2,032,082 | 293,963 |  1,442 |    208.60 |      198.40 | NEGMIR |\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Frequency Comparisons between Polarity Approximations: All Data vs. Mirror Subset\n",
                "The following values indicate the percentage of the negated frequency (`f`) and the marginal frequency (`f2`) accounted for by the `mirror` subset for each adverb. \n",
                "That is, `ratio_f_MIR` indicates the percentage of negated tokens with the specific triggers covered by `NEGmirror`, \n",
                "and `ratio_f2_MIR` the percentage of all adverb tokens which were captured by _either_ mirror pattern, `POSmirror` or `NEGmirror`. \n",
                "The third column then indicates the discrepancy between these percentages: \n",
                "For example, \n",
                "\n",
                "- [ ]  **finish this discussion!**\n",
                "\n",
                "Note that _before_ and _ever_ have a much higher proportions of their negated tokens representated in the mirror subset. \n",
                "However, the discrepancy indicated by the `difference` column, which illuminates the "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Percentage Comparision\n",
                "\n",
                "|                   |  joint % MIR |  adverb % MIR | % MIR $\\Delta$ |\n",
                "|:------------------|-------------:|--------------:|---------------:|\n",
                "| **ever**          |         79.1 |           4.2 |           74.9 |\n",
                "| **before**        |         93.2 |          39.3 |           53.9 |\n",
                "| **inherently**    |         41.9 |          10.3 |           31.7 |\n",
                "| **intrinsically** |         40.3 |           9.9 |           30.4 |\n",
                "| **remotely**      |         32.5 |          12.2 |           20.3 |\n",
                "| **particularly**  |         16.6 |           2.6 |           14.0 |\n",
                "| **overtly**       |         18.1 |           5.9 |           12.2 |\n",
                "| **any**           |          7.0 |           1.6 |            5.4 |\n",
                "| **terribly**      |          8.7 |           7.4 |            1.3 |\n",
                "| **exactly**       |          1.9 |           1.8 |            0.1 |\n",
                "| **entirely**      |          3.8 |           3.9 |           -0.1 |\n",
                "| **yet**           |          0.6 |           0.9 |           -0.3 |\n",
                "| **that**          |          2.6 |           3.0 |           -0.4 |\n",
                "| **necessarily**   |          2.3 |           3.0 |           -0.7 |\n",
                "| **immediately**   |          0.7 |           1.4 |           -0.7 |\n",
                "| **only**          |          0.2 |           1.1 |           -1.0 |\n",
                "| **altogether**    |          2.4 |           8.8 |           -6.3 |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 91,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "|                 |   `ratio_f_MIR` |   `ratio_f2_MIR` |   `f_minus_f2` |\n",
                        "|:----------------|----------------:|-----------------:|---------------:|\n",
                        "| **ever**        |            78.6 |              4.0 |           74.5 |\n",
                        "| **longer**      |            55.4 |              0.6 |           54.8 |\n",
                        "| **before**      |            92.6 |             38.5 |           54.1 |\n",
                        "| **any**         |             6.9 |              1.3 |            5.6 |\n",
                        "| **that**        |             2.6 |              2.2 |            0.4 |\n",
                        "| **necessarily** |             2.2 |              1.9 |            0.3 |\n",
                        "| **exactly**     |             1.9 |              1.7 |            0.2 |\n",
                        "| **yet**         |             0.6 |              0.8 |           -0.2 |\n",
                        "| **immediately** |             0.7 |              1.2 |           -0.5 |\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "nb_show_table(C.filter(regex=r'^ratio_f2?_')\n",
                "              .assign(f_minus_f2=C.ratio_f_MIR - C.ratio_f2_MIR)\n",
                "              .multiply(100).round(1)\n",
                "              .sort_values(['f_minus_f2', 'ratio_f_MIR'], ascending=False),\n",
                "              n_dec=1, adjust_columns=False)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Joint (_Negated_) Frequency Comparison\n",
                "\n",
                "|                   |   `total negations` |   `mirror subset negations` |   `negations not in mirror subset` |\n",
                "|:------------------|--------------------:|----------------------------:|-----------------------------------:|\n",
                "| **that**          |             165,411 |                       4,338 |                            161,073 |\n",
                "| **only**          |             114,070 |                         173 |                            113,897 |\n",
                "| **entirely**      |              63,708 |                       2,429 |                             61,279 |\n",
                "| **immediately**   |              57,319 |                         407 |                             56,912 |\n",
                "| **yet**           |              52,546 |                         320 |                             52,226 |\n",
                "| **particularly**  |              55,799 |                       9,278 |                             46,521 |\n",
                "| **exactly**       |              43,635 |                         813 |                             42,822 |\n",
                "| **necessarily**   |              42,708 |                         971 |                             41,737 |\n",
                "| **terribly**      |              18,054 |                       1,579 |                             16,475 |\n",
                "| **any**           |              15,492 |                       1,082 |                             14,410 |\n",
                "| **altogether**    |               4,575 |                         112 |                              4,463 |\n",
                "| **inherently**    |               6,847 |                       2,872 |                              3,975 |\n",
                "| **remotely**      |               5,679 |                       1,846 |                              3,833 |\n",
                "| **overtly**       |               2,169 |                         392 |                              1,777 |\n",
                "| **ever**          |               5,967 |                       4,718 |                              1,249 |\n",
                "| **intrinsically** |               1,071 |                         432 |                                639 |\n",
                "| **before**        |                 311 |                         290 |                                 21 |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 92,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "|                 |   `total negations` |   `mirror subset negations` |   `negations not in mirror subset` |\n",
                        "|:----------------|--------------------:|----------------------------:|-----------------------------------:|\n",
                        "| **that**        |             165,411 |                       4,293 |                            161,118 |\n",
                        "| **immediately** |              57,319 |                         403 |                             56,916 |\n",
                        "| **yet**         |              52,546 |                         319 |                             52,227 |\n",
                        "| **exactly**     |              43,635 |                         811 |                             42,824 |\n",
                        "| **necessarily** |              42,708 |                         960 |                             41,748 |\n",
                        "| **any**         |              15,492 |                       1,066 |                             14,426 |\n",
                        "| **ever**        |               5,967 |                       4,688 |                              1,279 |\n",
                        "| **longer**      |               1,448 |                         802 |                                646 |\n",
                        "| **before**      |                 311 |                         288 |                                 23 |\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "nb_show_table(\n",
                "    C\n",
                "    # .assign(f_percent_MIR=C.ratio_f_MIR * 100)\n",
                "    .filter(regex=r'^f_.*[MS]').sort_index(axis=1, ascending=False)\n",
                "    .assign(\n",
                "        f_diff=C.f_SET-C.f_MIR).sort_values('f_diff', ascending=False)\n",
                "    .rename(columns={'f_SET':'total negations', \n",
                "                     'f_MIR':'mirror subset negations', \n",
                "                     'f_diff': 'negations not in mirror subset'}), n_dec=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Marginal (_Adverb Total_) Frequency Comparison\n",
                "\n",
                "|                   |   `total adverb tokens` |   `mirror subset adverb tokens` |   `adverb tokens not in mirror subset` |\n",
                "|:------------------|------------------------:|--------------------------------:|---------------------------------------:|\n",
                "| **particularly**  |                 575,960 |                          14,954 |                                561,006 |\n",
                "| **only**          |                 464,168 |                           5,169 |                                458,999 |\n",
                "| **entirely**      |                 303,833 |                          11,803 |                                292,030 |\n",
                "| **that**          |                 250,392 |                           7,472 |                                242,920 |\n",
                "| **ever**          |                 124,592 |                           5,179 |                                119,413 |\n",
                "| **immediately**   |                 103,177 |                           1,442 |                                101,735 |\n",
                "| **yet**           |                 101,707 |                             909 |                                100,798 |\n",
                "| **any**           |                  94,152 |                           1,514 |                                 92,638 |\n",
                "| **terribly**      |                  70,174 |                           5,218 |                                 64,956 |\n",
                "| **exactly**       |                  61,599 |                           1,114 |                                 60,485 |\n",
                "| **necessarily**   |                  56,694 |                           1,681 |                                 55,013 |\n",
                "| **inherently**    |                  55,088 |                           5,649 |                                 49,439 |\n",
                "| **remotely**      |                  22,194 |                           2,717 |                                 19,477 |\n",
                "| **altogether**    |                  20,636 |                           1,808 |                                 18,828 |\n",
                "| **overtly**       |                  15,219 |                             898 |                                 14,321 |\n",
                "| **intrinsically** |                  10,001 |                             991 |                                  9,010 |\n",
                "| **before**        |                     748 |                             294 |                                    454 |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 93,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "|                 |   `total adverb tokens` |   `mirror subset adverb tokens` |   `adverb tokens not in mirror subset` |\n",
                        "|:----------------|------------------------:|--------------------------------:|---------------------------------------:|\n",
                        "| **that**        |                 250,392 |                           5,488 |                                244,904 |\n",
                        "| **longer**      |                 157,984 |                             891 |                                157,093 |\n",
                        "| **ever**        |                 124,592 |                           5,027 |                                119,565 |\n",
                        "| **immediately** |                 103,177 |                           1,193 |                                101,984 |\n",
                        "| **yet**         |                 101,707 |                             810 |                                100,897 |\n",
                        "| **any**         |                  94,152 |                           1,178 |                                 92,974 |\n",
                        "| **exactly**     |                  61,599 |                           1,034 |                                 60,565 |\n",
                        "| **necessarily** |                  56,694 |                           1,100 |                                 55,594 |\n",
                        "| **before**      |                     748 |                             288 |                                    460 |\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "nb_show_table(\n",
                "    C\n",
                "    # .assign(f2_percent_MIR=C.ratio_f2_MIR * 100)\n",
                "    .filter(regex=r'^f2_.*[MS]').sort_index(axis=1, ascending=False)\n",
                "    .assign(\n",
                "        f2_diff=C.f2_SET-C.f2_MIR).sort_values('f2_diff', ascending=False)\n",
                "    .rename(columns={'f2_SET':'total adverb tokens', \n",
                "                     'f2_MIR':'mirror subset adverb tokens', \n",
                "                     'f2_diff': 'adverb tokens not in mirror subset'}), n_dec=0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 94,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "|                 |   `LRC_SET` |   `LRC_MIR` |   `mean_LRC` |   `dP1_SET` |   `dP1_MIR` |   `mean_dP1` |   `G2_SET` |   `G2_MIR` |   `mean_G2` |    `f_SET` |   `f_MIR` |     `f1_SET` |   `f1_MIR` |   `f2_SET` |   `f2_MIR` |\n",
                        "|:----------------|------------:|------------:|-------------:|------------:|------------:|-------------:|-----------:|-----------:|------------:|-----------:|----------:|-------------:|-----------:|-----------:|-----------:|\n",
                        "| **necessarily** |        6.23 |        4.47 |         5.35 |        0.72 |        0.71 |         0.71 | 219,003.46 |   2,679.92 |  110,841.69 |  42,708.00 |    960.00 | 3,226,213.00 | 289,770.00 |  56,694.00 |   1,100.00 |\n",
                        "| **exactly**     |        5.90 |        3.66 |         4.78 |        0.67 |        0.62 |         0.65 | 214,404.20 |   1,931.41 |  108,167.81 |  43,635.00 |    811.00 | 3,226,213.00 | 289,770.00 |  61,599.00 |   1,034.00 |\n",
                        "| **that**        |        5.62 |        3.95 |         4.79 |        0.63 |        0.62 |         0.62 | 781,016.11 |  10,223.36 |  395,619.73 | 165,411.00 |  4,293.00 | 3,226,213.00 | 289,770.00 | 250,392.00 |   5,488.00 |\n",
                        "| **before**      |        3.65 |        1.31 |         2.48 |        0.38 |        0.84 |         0.61 |   1,062.13 |   1,039.94 |    1,051.03 |     311.00 |    288.00 | 3,226,213.00 | 289,770.00 |     748.00 |     288.00 |\n",
                        "| **any**         |        2.28 |        4.88 |         3.58 |        0.13 |        0.74 |         0.43 |  23,683.00 |   3,151.64 |   13,417.32 |  15,492.00 |  1,066.00 | 3,226,213.00 | 289,770.00 |  94,152.00 |   1,178.00 |\n",
                        "| **ever**        |        0.28 |        5.73 |         3.00 |        0.01 |        0.77 |         0.39 |     353.58 |  14,624.92 |    7,489.25 |   5,967.00 |  4,688.00 | 3,226,213.00 | 289,770.00 | 124,592.00 |   5,027.00 |\n",
                        "| **yet**         |        4.74 |        1.20 |         2.97 |        0.48 |        0.23 |         0.35 | 209,055.78 |     242.11 |  104,648.95 |  52,546.00 |    319.00 | 3,226,213.00 | 289,770.00 | 101,707.00 |     810.00 |\n",
                        "| **longer**      |       -1.87 |        4.71 |         1.42 |       -0.03 |        0.74 |         0.35 |  -4,977.41 |   2,350.18 |   -1,313.62 |   1,448.00 |    802.00 | 3,226,213.00 | 289,770.00 | 157,984.00 |     891.00 |\n",
                        "| **immediately** |        4.96 |        0.93 |         2.95 |        0.52 |        0.17 |         0.35 | 239,462.58 |     212.93 |  119,837.75 |  57,319.00 |    403.00 | 3,226,213.00 | 289,770.00 | 103,177.00 |   1,193.00 |\n",
                        "\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>`LRC_SET`</th>\n",
                            "      <th>`LRC_MIR`</th>\n",
                            "      <th>`mean_LRC`</th>\n",
                            "      <th>`dP1_SET`</th>\n",
                            "      <th>`dP1_MIR`</th>\n",
                            "      <th>`mean_dP1`</th>\n",
                            "      <th>...</th>\n",
                            "      <th>`f_SET`</th>\n",
                            "      <th>`f_MIR`</th>\n",
                            "      <th>`f1_SET`</th>\n",
                            "      <th>`f1_MIR`</th>\n",
                            "      <th>`f2_SET`</th>\n",
                            "      <th>`f2_MIR`</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>**necessarily**</th>\n",
                            "      <td>6.23</td>\n",
                            "      <td>4.47</td>\n",
                            "      <td>5.35</td>\n",
                            "      <td>0.72</td>\n",
                            "      <td>0.71</td>\n",
                            "      <td>0.71</td>\n",
                            "      <td>...</td>\n",
                            "      <td>42708</td>\n",
                            "      <td>960</td>\n",
                            "      <td>3226213</td>\n",
                            "      <td>289770</td>\n",
                            "      <td>56694</td>\n",
                            "      <td>1100</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>**exactly**</th>\n",
                            "      <td>5.90</td>\n",
                            "      <td>3.66</td>\n",
                            "      <td>4.78</td>\n",
                            "      <td>0.67</td>\n",
                            "      <td>0.62</td>\n",
                            "      <td>0.65</td>\n",
                            "      <td>...</td>\n",
                            "      <td>43635</td>\n",
                            "      <td>811</td>\n",
                            "      <td>3226213</td>\n",
                            "      <td>289770</td>\n",
                            "      <td>61599</td>\n",
                            "      <td>1034</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>**that**</th>\n",
                            "      <td>5.62</td>\n",
                            "      <td>3.95</td>\n",
                            "      <td>4.79</td>\n",
                            "      <td>0.63</td>\n",
                            "      <td>0.62</td>\n",
                            "      <td>0.62</td>\n",
                            "      <td>...</td>\n",
                            "      <td>165411</td>\n",
                            "      <td>4293</td>\n",
                            "      <td>3226213</td>\n",
                            "      <td>289770</td>\n",
                            "      <td>250392</td>\n",
                            "      <td>5488</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>**before**</th>\n",
                            "      <td>3.65</td>\n",
                            "      <td>1.31</td>\n",
                            "      <td>2.48</td>\n",
                            "      <td>0.38</td>\n",
                            "      <td>0.84</td>\n",
                            "      <td>0.61</td>\n",
                            "      <td>...</td>\n",
                            "      <td>311</td>\n",
                            "      <td>288</td>\n",
                            "      <td>3226213</td>\n",
                            "      <td>289770</td>\n",
                            "      <td>748</td>\n",
                            "      <td>288</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>**any**</th>\n",
                            "      <td>2.28</td>\n",
                            "      <td>4.88</td>\n",
                            "      <td>3.58</td>\n",
                            "      <td>0.13</td>\n",
                            "      <td>0.74</td>\n",
                            "      <td>0.43</td>\n",
                            "      <td>...</td>\n",
                            "      <td>15492</td>\n",
                            "      <td>1066</td>\n",
                            "      <td>3226213</td>\n",
                            "      <td>289770</td>\n",
                            "      <td>94152</td>\n",
                            "      <td>1178</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>**ever**</th>\n",
                            "      <td>0.28</td>\n",
                            "      <td>5.73</td>\n",
                            "      <td>3.00</td>\n",
                            "      <td>0.01</td>\n",
                            "      <td>0.77</td>\n",
                            "      <td>0.39</td>\n",
                            "      <td>...</td>\n",
                            "      <td>5967</td>\n",
                            "      <td>4688</td>\n",
                            "      <td>3226213</td>\n",
                            "      <td>289770</td>\n",
                            "      <td>124592</td>\n",
                            "      <td>5027</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>**yet**</th>\n",
                            "      <td>4.74</td>\n",
                            "      <td>1.20</td>\n",
                            "      <td>2.97</td>\n",
                            "      <td>0.48</td>\n",
                            "      <td>0.23</td>\n",
                            "      <td>0.35</td>\n",
                            "      <td>...</td>\n",
                            "      <td>52546</td>\n",
                            "      <td>319</td>\n",
                            "      <td>3226213</td>\n",
                            "      <td>289770</td>\n",
                            "      <td>101707</td>\n",
                            "      <td>810</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>**longer**</th>\n",
                            "      <td>-1.87</td>\n",
                            "      <td>4.71</td>\n",
                            "      <td>1.42</td>\n",
                            "      <td>-0.03</td>\n",
                            "      <td>0.74</td>\n",
                            "      <td>0.35</td>\n",
                            "      <td>...</td>\n",
                            "      <td>1448</td>\n",
                            "      <td>802</td>\n",
                            "      <td>3226213</td>\n",
                            "      <td>289770</td>\n",
                            "      <td>157984</td>\n",
                            "      <td>891</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>**immediately**</th>\n",
                            "      <td>4.96</td>\n",
                            "      <td>0.93</td>\n",
                            "      <td>2.95</td>\n",
                            "      <td>0.52</td>\n",
                            "      <td>0.17</td>\n",
                            "      <td>0.35</td>\n",
                            "      <td>...</td>\n",
                            "      <td>57319</td>\n",
                            "      <td>403</td>\n",
                            "      <td>3226213</td>\n",
                            "      <td>289770</td>\n",
                            "      <td>103177</td>\n",
                            "      <td>1193</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>9 rows  15 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                 `LRC_SET`  `LRC_MIR`  `mean_LRC`  `dP1_SET`  `dP1_MIR`  `mean_dP1`  \\\n",
                            "**necessarily**       6.23       4.47        5.35       0.72       0.71        0.71   \n",
                            "**exactly**           5.90       3.66        4.78       0.67       0.62        0.65   \n",
                            "**that**              5.62       3.95        4.79       0.63       0.62        0.62   \n",
                            "**before**            3.65       1.31        2.48       0.38       0.84        0.61   \n",
                            "**any**               2.28       4.88        3.58       0.13       0.74        0.43   \n",
                            "**ever**              0.28       5.73        3.00       0.01       0.77        0.39   \n",
                            "**yet**               4.74       1.20        2.97       0.48       0.23        0.35   \n",
                            "**longer**           -1.87       4.71        1.42      -0.03       0.74        0.35   \n",
                            "**immediately**       4.96       0.93        2.95       0.52       0.17        0.35   \n",
                            "\n",
                            "                 ...  `f_SET`  `f_MIR`  `f1_SET`  `f1_MIR`  `f2_SET`  `f2_MIR`  \n",
                            "**necessarily**  ...    42708      960   3226213    289770     56694      1100  \n",
                            "**exactly**      ...    43635      811   3226213    289770     61599      1034  \n",
                            "**that**         ...   165411     4293   3226213    289770    250392      5488  \n",
                            "**before**       ...      311      288   3226213    289770       748       288  \n",
                            "**any**          ...    15492     1066   3226213    289770     94152      1178  \n",
                            "**ever**         ...     5967     4688   3226213    289770    124592      5027  \n",
                            "**yet**          ...    52546      319   3226213    289770    101707       810  \n",
                            "**longer**       ...     1448      802   3226213    289770    157984       891  \n",
                            "**immediately**  ...    57319      403   3226213    289770    103177      1193  \n",
                            "\n",
                            "[9 rows x 15 columns]"
                        ]
                    },
                    "execution_count": 94,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "full_C = C.copy()\n",
                "main_cols_ordered = pd.concat((*[C.filter(like=m).columns.to_series() for m in ('LRC', 'P1', 'G2')],\n",
                "                               *[C.filter(regex=f'^{f}_').columns.to_series() for f in ['f', 'f1', 'f2'] ]) \n",
                "                              ).to_list()\n",
                "# print_iter([f'`{c}`' for c in main_cols_ordered], bullet='1.', header='Main Columns')\n",
                "main_C = C[[c for c in main_cols_ordered if c in C.columns]]\n",
                "nb_show_table(main_C.sort_values('mean_dP1', ascending=False), return_df=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Combined Table of AM values for \"most negative\" adverbs, by descending `mean_dP1`\n",
                "\n",
                "|                 | `LRC_SET` | `LRC_MIR` | `mean_LRC` | `dP1_SET` | `dP1_MIR` | `mean_dP1` |   `G2_SET` |  `G2_MIR` |  `mean_G2` | `f_SET` | `f_MIR` |  `f1_SET` | `f1_MIR` | `f2_SET` | `f2_MIR` |\n",
                "|:----------------|----------:|----------:|-----------:|----------:|----------:|-----------:|-----------:|----------:|-----------:|--------:|--------:|----------:|---------:|---------:|---------:|\n",
                "| **exactly**     |      5.90 |      3.51 |       4.71 |      0.67 |      0.59 |       0.63 | 214,404.20 |  1,939.47 | 108,171.83 |  43,635 |     813 | 3,226,213 |  293,963 |   61,599 |    1,114 |\n",
                "| **before**      |      3.65 |      5.11 |       4.38 |      0.38 |      0.84 |       0.61 |   1,062.13 |  1,080.52 |   1,071.32 |     311 |     290 | 3,226,213 |  293,963 |      748 |      294 |\n",
                "| **necessarily** |      6.23 |      2.66 |       4.44 |      0.72 |      0.43 |       0.57 | 219,003.46 |  1,688.91 | 110,346.18 |  42,708 |     971 | 3,226,213 |  293,963 |   56,694 |    1,681 |\n",
                "| **that**        |      5.62 |      2.86 |       4.24 |      0.63 |      0.44 |       0.53 | 781,016.11 |  7,632.21 | 394,324.16 | 165,411 |   4,338 | 3,226,213 |  293,963 |  250,392 |    7,472 |\n",
                "| **ever**        |      0.28 |      5.57 |       2.92 |      0.01 |      0.77 |       0.39 |     353.58 | 15,340.34 |   7,846.96 |   5,967 |   4,718 | 3,226,213 |  293,963 |  124,592 |    5,179 |\n",
                "| **remotely**    |      3.03 |      3.35 |       3.19 |      0.22 |      0.54 |       0.38 |  13,354.33 |  4,009.84 |   8,682.08 |   5,679 |   1,846 | 3,226,213 |  293,963 |   22,194 |    2,717 |\n",
                "| **any**         |      2.28 |      3.48 |       2.88 |      0.13 |      0.57 |       0.35 |  23,683.00 |  2,511.26 |  13,097.13 |  15,492 |   1,082 | 3,226,213 |  293,963 |   94,152 |    1,514 |\n",
                "| **yet**         |      4.74 |      1.18 |       2.96 |      0.48 |      0.21 |       0.34 | 209,055.78 |    242.23 | 104,649.01 |  52,546 |     320 | 3,226,213 |  293,963 |  101,707 |      909 |\n",
                "| **immediately** |      4.96 |      0.79 |       2.88 |      0.52 |      0.14 |       0.33 | 239,462.58 |    181.20 | 119,821.89 |  57,319 |     407 | 3,226,213 |  293,963 |  103,177 |    1,442 |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Save full adverb selection as `.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 95,
            "metadata": {},
            "outputs": [],
            "source": [
                "C.to_csv(TOP_AM_DIR / f'Top{K}_NEG-ADV_combined.35f-7c_{timestamp_today()}.csv')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Save `all-columns`, `means`, and `MAIN` as markdown formatted tables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 96,
            "metadata": {},
            "outputs": [],
            "source": [
                "C.to_markdown(floatfmt=',.2f', intfmt=',', buf=TOP_AM_DIR / f'Top{K}_NEG-ADV_combined_all-columns.35f-7c_{timestamp_today()}.md')\n",
                "C.filter(like='mean_').to_markdown(floatfmt=',.2f', intfmt=',', buf=TOP_AM_DIR / f'Top{K}_NEG-ADV_combined_means.35f-7c_{timestamp_today()}.md')\n",
                "C[main_cols_ordered].to_markdown(floatfmt=',.2f', intfmt=',', buf=TOP_AM_DIR / f'Top{K}_NEG-ADV_combined_MAIN.35f-7c_{timestamp_today()}.md')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Collect bigrams corresponding to top adverbs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 97,
            "metadata": {},
            "outputs": [],
            "source": [
                "# results/assoc_df/polar/RBdirect/bigram/polarized-bigram_35f-7c_min1000x.pkl.gz\n",
                "\n",
                "bigram_dfs = {d.name:\n",
                "              update_index(pd.read_pickle(\n",
                "                  tuple(d.joinpath('bigram/extra')\n",
                "                        .glob(f'*35f-7c*min{mirror_floor if d.name == \"NEGmirror\" else bigram_floor}x*.pkl.gz')\n",
                "                        )[0]))\n",
                "              for d in POLAR_DIR.iterdir()}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 98,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "## Top 10 \"most negative\" bigrams corresponding to top 5 adverbs\n",
                        "\n",
                        "2024-05-23\n",
                        "\n",
                        "### 1. _necessarily_\n",
                        "\n",
                        "\n",
                        "#### Top 10 `RBdirect` \"necessarily_*\" bigrams (sorted by `dP1`; `LRC > 1`)\n",
                        "\n",
                        "\n",
                        "|                                       | `adj`          |   `adj_total` |   `LRC` |   `dP1` |      `G2` |   `f` |      `f1` |   `f2` |\n",
                        "|:--------------------------------------|:---------------|--------------:|--------:|--------:|----------:|------:|----------:|-------:|\n",
                        "| **NEGany~necessarily_sure**           | sure           |    844,981.00 |    5.91 |    0.95 |  1,436.68 |   222 | 3,226,213 |    224 |\n",
                        "| **NEGany~necessarily_surprising**     | surprising     |    150,067.00 |    7.22 |    0.93 |  2,150.86 |   343 | 3,226,213 |    355 |\n",
                        "| **NEGany~necessarily_indicative**     | indicative     |     12,760.00 |    8.37 |    0.93 |  8,811.69 | 1,406 | 3,226,213 |  1,456 |\n",
                        "| **NEGany~necessarily_representative** | representative |     25,187.00 |    7.31 |    0.91 |  3,044.27 |   496 | 3,226,213 |    524 |\n",
                        "| **NEGany~necessarily_available**      | available      |    866,272.00 |    6.36 |    0.89 |  1,280.24 |   213 | 3,226,213 |    230 |\n",
                        "| **NEGany~necessarily_easy**           | easy           |    771,307.00 |    7.26 |    0.88 |  5,448.34 |   914 | 3,226,213 |    996 |\n",
                        "| **NEGany~necessarily_true**           | true           |    348,994.00 |    6.89 |    0.82 | 18,199.76 | 3,238 | 3,226,213 |  3,786 |\n",
                        "| **NEGany~necessarily_illegal**        | illegal        |     44,028.00 |    6.48 |    0.87 |  1,659.90 |   280 | 3,226,213 |    307 |\n",
                        "| **NEGany~necessarily_related**        | related        |    137,661.00 |    6.74 |    0.84 |  4,271.76 |   742 | 3,226,213 |    842 |\n",
                        "| **NEGany~necessarily_interested**     | interested     |    364,497.00 |    6.77 |    0.87 |  2,500.26 |   422 | 3,226,213 |    463 |\n",
                        "\n",
                        "\n",
                        "#### Top 3 `NEGmirror` \"necessarily_*\" bigrams (sorted by `dP1`; `LRC > 1`)\n",
                        "\n",
                        "\n",
                        "|                              | `adj`   |   `adj_total` |   `LRC` |   `dP1` |   `G2` |   `f` |    `f1` |   `f2` |\n",
                        "|:-----------------------------|:--------|--------------:|--------:|--------:|-------:|------:|--------:|-------:|\n",
                        "| **NEGmir~necessarily_wrong** | wrong   |     20,866.00 |    4.27 |    0.81 | 708.98 |   209 | 289,770 |    214 |\n",
                        "| **NEGmir~necessarily_bad**   | bad     |     10,783.00 |    2.02 |    0.76 | 153.43 |    50 | 289,770 |     54 |\n",
                        "| **NEGmir~necessarily_true**  | true    |      7,402.00 |    2.18 |    0.75 | 159.07 |    53 | 289,770 |     58 |\n",
                        "\n",
                        "\n",
                        "### 2. _exactly_\n",
                        "\n",
                        "\n",
                        "#### Top 10 `RBdirect` \"exactly_*\" bigrams (sorted by `dP1`; `LRC > 1`)\n",
                        "\n",
                        "\n",
                        "|                               | `adj`      |   `adj_total` |   `LRC` |   `dP1` |      `G2` |   `f` |      `f1` |   `f2` |\n",
                        "|:------------------------------|:-----------|--------------:|--------:|--------:|----------:|------:|----------:|-------:|\n",
                        "| **NEGany~exactly_surprising** | surprising |    150,067.00 |    7.34 |    0.96 |  2,863.35 |   441 | 3,226,213 |    444 |\n",
                        "| **NEGany~exactly_cheap**      | cheap      |     83,765.00 |    8.28 |    0.95 |  4,443.27 |   693 | 3,226,213 |    704 |\n",
                        "| **NEGany~exactly_subtle**     | subtle     |     56,845.00 |    6.92 |    0.94 |  1,671.02 |   264 | 3,226,213 |    271 |\n",
                        "| **NEGany~exactly_fun**        | fun        |    224,457.00 |    6.67 |    0.94 |  1,423.92 |   225 | 3,226,213 |    231 |\n",
                        "| **NEGany~exactly_conducive**  | conducive  |     16,405.00 |    6.56 |    0.93 |  1,313.09 |   208 | 3,226,213 |    214 |\n",
                        "| **NEGany~exactly_sure**       | sure       |    844,981.00 |    8.63 |    0.92 | 54,750.58 | 8,860 | 3,226,213 |  9,301 |\n",
                        "| **NEGany~exactly_new**        | new        |    321,311.00 |    8.54 |    0.93 |  8,697.93 | 1,378 | 3,226,213 |  1,418 |\n",
                        "| **NEGany~exactly_easy**       | easy       |    771,307.00 |    8.37 |    0.93 |  6,747.64 | 1,069 | 3,226,213 |  1,100 |\n",
                        "| **NEGany~exactly_clear**      | clear      |    491,108.00 |    8.30 |    0.92 | 10,937.16 | 1,759 | 3,226,213 |  1,835 |\n",
                        "| **NEGany~exactly_happy**      | happy      |    528,511.00 |    7.16 |    0.90 |  2,694.69 |   441 | 3,226,213 |    468 |\n",
                        "\n",
                        "No bigrams found in loaded `NEGmirror` AM table.\n",
                        "\n",
                        "### 3. _that_\n",
                        "\n",
                        "\n",
                        "#### Top 10 `RBdirect` \"that_*\" bigrams (sorted by `dP1`; `LRC > 1`)\n",
                        "\n",
                        "\n",
                        "|                             | `adj`       |   `adj_total` |   `LRC` |   `dP1` |      `G2` |   `f` |      `f1` |   `f2` |\n",
                        "|:----------------------------|:------------|--------------:|--------:|--------:|----------:|------:|----------:|-------:|\n",
                        "| **NEGany~that_uncommon**    | uncommon    |     61,767.00 |    8.39 |    0.94 |  5,136.91 |   804 | 3,226,213 |    819 |\n",
                        "| **NEGany~that_fond**        | fond        |     39,809.00 |    7.27 |    0.94 |  2,127.94 |   334 | 3,226,213 |    341 |\n",
                        "| **NEGany~that_surprising**  | surprising  |    150,067.00 |    8.14 |    0.92 |  7,115.30 | 1,141 | 3,226,213 |  1,187 |\n",
                        "| **NEGany~that_common**      | common      |    556,435.00 |    8.12 |    0.92 |  7,564.08 | 1,216 | 3,226,213 |  1,268 |\n",
                        "| **NEGany~that_dissimilar**  | dissimilar  |      8,816.00 |    7.00 |    0.92 |  1,904.15 |   307 | 3,226,213 |    321 |\n",
                        "| **NEGany~that_hard**        | hard        |    430,990.00 |    7.96 |    0.88 | 59,642.82 | 9,966 | 3,226,213 | 10,818 |\n",
                        "| **NEGany~that_complicated** | complicated |    180,071.00 |    7.95 |    0.91 |  7,450.89 | 1,208 | 3,226,213 |  1,270 |\n",
                        "| **NEGany~that_impressed**   | impressed   |    113,281.00 |    7.57 |    0.91 |  4,207.58 |   684 | 3,226,213 |    721 |\n",
                        "| **NEGany~that_noticeable**  | noticeable  |     40,372.00 |    6.78 |    0.91 |  1,632.07 |   265 | 3,226,213 |    279 |\n",
                        "| **NEGany~that_exciting**    | exciting    |    236,396.00 |    7.48 |    0.90 |  4,892.83 |   805 | 3,226,213 |    859 |\n",
                        "\n",
                        "\n",
                        "#### Top 10 `NEGmirror` \"that_*\" bigrams (sorted by `dP1`; `LRC > 1`)\n",
                        "\n",
                        "\n",
                        "|                            | `adj`      |   `adj_total` |   `LRC` |   `dP1` |     `G2` |   `f` |    `f1` |   `f2` |\n",
                        "|:---------------------------|:-----------|--------------:|--------:|--------:|---------:|------:|--------:|-------:|\n",
                        "| **NEGmir~that_popular**    | popular    |      5,787.00 |    2.50 |    0.76 |   200.44 |    65 | 289,770 |     70 |\n",
                        "| **NEGmir~that_interested** | interested |      9,258.00 |    2.42 |    0.76 |   190.06 |    62 | 289,770 |     67 |\n",
                        "| **NEGmir~that_difficult**  | difficult  |     16,043.00 |    2.15 |    0.75 |   155.64 |    52 | 289,770 |     57 |\n",
                        "| **NEGmir~that_hard**       | hard       |      7,311.00 |    2.31 |    0.74 |   168.31 |    57 | 289,770 |     63 |\n",
                        "| **NEGmir~that_close**      | close      |     13,962.00 |    2.39 |    0.73 |   174.26 |    60 | 289,770 |     67 |\n",
                        "| **NEGmir~that_simple**     | simple     |     25,382.00 |    4.34 |    0.73 | 1,370.94 |   473 | 289,770 |    529 |\n",
                        "| **NEGmir~that_easy**       | easy       |     20,050.00 |    4.21 |    0.72 | 1,258.15 |   442 | 289,770 |    500 |\n",
                        "| **NEGmir~that_great**      | great      |      5,819.00 |    3.52 |    0.67 |   728.46 |   282 | 289,770 |    340 |\n",
                        "| **NEGmir~that_good**       | good       |     33,540.00 |    3.07 |    0.56 |   953.31 |   447 | 289,770 |    615 |\n",
                        "| **NEGmir~that_big**        | big        |      7,859.00 |    3.06 |    0.70 |   309.58 |   113 | 289,770 |    131 |\n",
                        "\n",
                        "\n",
                        "### 4. _before_\n",
                        "\n",
                        "No bigrams found in loaded `RBdirect` AM table.\n",
                        "No bigrams found in loaded `NEGmirror` AM table.\n",
                        "\n",
                        "### 5. _any_\n",
                        "\n",
                        "\n",
                        "#### Top 10 `RBdirect` \"any_*\" bigrams (sorted by `dP1`; `LRC > 1`)\n",
                        "\n",
                        "\n",
                        "|                          | `adj`     |   `adj_total` |   `LRC` |   `dP1` |     `G2` |   `f` |      `f1` |   `f2` |\n",
                        "|:-------------------------|:----------|--------------:|--------:|--------:|---------:|------:|----------:|-------:|\n",
                        "| **NEGany~any_happier**   | happier   |     19,501.00 |    4.65 |    0.53 | 3,488.76 |   830 | 3,226,213 |  1,472 |\n",
                        "| **NEGany~any_simpler**   | simpler   |     26,094.00 |    3.09 |    0.30 |   671.74 |   228 | 3,226,213 |    672 |\n",
                        "| **NEGany~any_clearer**   | clearer   |     13,369.00 |    3.21 |    0.30 | 1,051.22 |   357 | 3,226,213 |  1,053 |\n",
                        "| **NEGany~any_different** | different |    909,864.00 |    2.98 |    0.24 | 2,270.24 |   910 | 3,226,213 |  3,313 |\n",
                        "| **NEGany~any_younger**   | younger   |     29,805.00 |    2.37 |    0.19 |   544.17 |   256 | 3,226,213 |  1,121 |\n",
                        "| **NEGany~any_worse**     | worse     |    214,166.00 |    2.47 |    0.16 | 3,165.88 | 1,693 | 3,226,213 |  8,487 |\n",
                        "| **NEGany~any_bigger**    | bigger    |    130,470.00 |    2.27 |    0.17 |   688.06 |   357 | 3,226,213 |  1,735 |\n",
                        "| **NEGany~any_harder**    | harder    |     99,332.00 |    1.98 |    0.15 |   395.22 |   227 | 3,226,213 |  1,221 |\n",
                        "| **NEGany~any_safer**     | safer     |     26,779.00 |    1.73 |    0.12 |   346.68 |   235 | 3,226,213 |  1,471 |\n",
                        "| **NEGany~any_easier**    | easier    |    237,680.00 |    1.95 |    0.11 | 2,164.75 | 1,607 | 3,226,213 | 10,860 |\n",
                        "\n",
                        "\n",
                        "#### Top 4 `NEGmirror` \"any_*\" bigrams (sorted by `dP1`; `LRC > 1`)\n",
                        "\n",
                        "\n",
                        "|                       | `adj`   |   `adj_total` |   `LRC` |   `dP1` |     `G2` |   `f` |    `f1` |   `f2` |\n",
                        "|:----------------------|:--------|--------------:|--------:|--------:|---------:|------:|--------:|-------:|\n",
                        "| **NEGmir~any_better** | better  |     14,076.00 |    4.44 |    0.75 | 1,148.18 |   381 | 289,770 |    416 |\n",
                        "| **NEGmir~any_easier** | easier  |      2,409.00 |    2.42 |    0.75 |   181.98 |    61 | 289,770 |     67 |\n",
                        "| **NEGmir~any_worse**  | worse   |      8,490.00 |    2.87 |    0.72 |   248.63 |    88 | 289,770 |    100 |\n",
                        "| **NEGmir~any_closer** | closer  |        986.00 |    2.21 |    0.68 |   149.62 |    56 | 289,770 |     66 |\n",
                        "\n",
                        "\n",
                        "### 6. _ever_\n",
                        "\n",
                        "\n",
                        "#### Top 5 `RBdirect` \"ever_*\" bigrams (sorted by `dP1`; `LRC > 1`)\n",
                        "\n",
                        "\n",
                        "|                         | `adj`   |   `adj_total` |   `LRC` |   `dP1` |     `G2` |   `f` |      `f1` |   `f2` |\n",
                        "|:------------------------|:--------|--------------:|--------:|--------:|---------:|------:|----------:|-------:|\n",
                        "| **NEGany~ever_simple**  | simple  |    427,167.00 |    5.54 |    0.77 | 1,142.04 |   212 | 3,226,213 |    262 |\n",
                        "| **NEGany~ever_easy**    | easy    |    771,307.00 |    5.06 |    0.63 | 2,030.58 |   430 | 3,226,213 |    641 |\n",
                        "| **NEGany~ever_good**    | good    |  2,037,285.00 |    3.76 |    0.40 | 1,178.00 |   332 | 3,226,213 |    756 |\n",
                        "| **NEGany~ever_perfect** | perfect |    164,519.00 |    3.48 |    0.37 |   736.05 |   217 | 3,226,213 |    527 |\n",
                        "| **NEGany~ever_able**    | able    |    428,268.00 |    1.81 |    0.13 |   363.95 |   234 | 3,226,213 |  1,398 |\n",
                        "\n",
                        "\n",
                        "#### Top 6 `NEGmirror` \"ever_*\" bigrams (sorted by `dP1`; `LRC > 1`)\n",
                        "\n",
                        "\n",
                        "|                         | `adj`   |   `adj_total` |   `LRC` |   `dP1` |     `G2` |   `f` |    `f1` |   `f2` |\n",
                        "|:------------------------|:--------|--------------:|--------:|--------:|---------:|------:|--------:|-------:|\n",
                        "| **NEGmir~ever_easy**    | easy    |     20,050.00 |    3.21 |    0.83 | 1,311.83 |   367 | 289,770 |    368 |\n",
                        "| **NEGmir~ever_perfect** | perfect |      3,708.00 |    2.38 |    0.83 |   735.10 |   207 | 289,770 |    208 |\n",
                        "| **NEGmir~ever_good**    | good    |     33,540.00 |    4.72 |    0.82 | 1,034.95 |   298 | 289,770 |    302 |\n",
                        "| **NEGmir~ever_wrong**   | wrong   |     20,866.00 |    2.56 |    0.82 |   349.21 |   102 | 289,770 |    104 |\n",
                        "| **NEGmir~ever_free**    | free    |      5,043.00 |    1.97 |    0.81 |   231.61 |    69 | 289,770 |     71 |\n",
                        "| **NEGmir~ever_able**    | able    |      6,448.00 |    3.66 |    0.79 |   437.65 |   136 | 289,770 |    143 |\n",
                        "\n",
                        "\n",
                        "### 7. _yet_\n",
                        "\n",
                        "\n",
                        "#### Top 10 `RBdirect` \"yet_*\" bigrams (sorted by `dP1`; `LRC > 1`)\n",
                        "\n",
                        "\n",
                        "|                          | `adj`     |   `adj_total` |   `LRC` |   `dP1` |      `G2` |    `f` |      `f1` |   `f2` |\n",
                        "|:-------------------------|:----------|--------------:|--------:|--------:|----------:|-------:|----------:|-------:|\n",
                        "| **NEGany~yet_clear**     | clear     |    491,108.00 |   10.26 |    0.95 | 67,924.56 | 10,553 | 3,226,213 | 10,693 |\n",
                        "| **NEGany~yet_eligible**  | eligible  |     49,578.00 |    7.72 |    0.94 |  2,929.15 |    459 | 3,226,213 |    468 |\n",
                        "| **NEGany~yet_official**  | official  |      9,778.00 |    7.33 |    0.94 |  2,236.98 |    353 | 3,226,213 |    362 |\n",
                        "| **NEGany~yet_ready**     | ready     |    240,297.00 |    9.23 |    0.93 | 48,012.06 |  7,611 | 3,226,213 |  7,838 |\n",
                        "| **NEGany~yet_certain**   | certain   |    104,544.00 |    8.12 |    0.93 |  5,491.41 |    874 | 3,226,213 |    903 |\n",
                        "| **NEGany~yet_complete**  | complete  |    107,018.00 |    8.42 |    0.92 | 13,815.99 |  2,220 | 3,226,213 |  2,314 |\n",
                        "| **NEGany~yet_sure**      | sure      |    844,981.00 |    8.37 |    0.92 | 12,379.79 |  1,990 | 3,226,213 |  2,075 |\n",
                        "| **NEGany~yet_available** | available |    866,272.00 |    7.69 |    0.87 | 44,196.15 |  7,481 | 3,226,213 |  8,238 |\n",
                        "| **NEGany~yet_right**     | right     |    204,572.00 |    6.50 |    0.92 |  1,254.20 |    202 | 3,226,213 |    211 |\n",
                        "| **NEGany~yet_final**     | final     |      9,657.00 |    7.45 |    0.91 |  4,028.75 |    659 | 3,226,213 |    699 |\n",
                        "\n",
                        "No bigrams found in loaded `NEGmirror` AM table.\n",
                        "\n",
                        "### 8. _longer_\n",
                        "\n",
                        "\n",
                        "#### Top 5 `RBdirect` \"longer_*\" bigrams (sorted by `dP1`; `LRC > 1`)\n",
                        "\n",
                        "\n",
                        "|                          | `adj`     |   `adj_total` |   `LRC` |   `dP1` |   `G2` |    `f` |       `f1` |   `f2` |\n",
                        "|:-------------------------|:----------|--------------:|--------:|--------:|-------:|-------:|-----------:|-------:|\n",
                        "| **COM~longer_lasting**   | lasting   |     24,344.00 |    1.44 |    0.04 | 244.09 |  3,860 | 83,102,035 |  3,866 |\n",
                        "| **COM~longer_enough**    | enough    |    453,790.00 |    1.41 |    0.03 | 216.98 |  3,952 | 83,102,035 |  3,964 |\n",
                        "| **COM~longer_able**      | able      |    428,268.00 |    2.28 |    0.03 | 623.67 | 11,677 | 83,102,035 | 11,716 |\n",
                        "| **COM~longer_available** | available |    866,272.00 |    2.45 |    0.03 | 974.55 | 18,865 | 83,102,035 | 18,935 |\n",
                        "| **COM~longer_necessary** | necessary |    187,396.00 |    1.27 |    0.03 | 220.07 |  5,365 | 83,102,035 |  5,399 |\n",
                        "\n",
                        "No bigrams found in loaded `NEGmirror` AM table.\n",
                        "\n",
                        "### 9. _immediately_\n",
                        "\n",
                        "\n",
                        "#### Top 5 `RBdirect` \"immediately_*\" bigrams (sorted by `dP1`; `LRC > 1`)\n",
                        "\n",
                        "\n",
                        "|                                  | `adj`     |   `adj_total` |   `LRC` |   `dP1` |       `G2` |    `f` |      `f1` |   `f2` |\n",
                        "|:---------------------------------|:----------|--------------:|--------:|--------:|-----------:|-------:|----------:|-------:|\n",
                        "| **NEGany~immediately_possible**  | possible  |    364,265.00 |    7.68 |    0.90 |   6,269.26 |  1,027 | 3,226,213 |  1,091 |\n",
                        "| **NEGany~immediately_clear**     | clear     |    491,108.00 |    8.32 |    0.90 | 153,302.22 | 25,276 | 3,226,213 | 27,066 |\n",
                        "| **NEGany~immediately_available** | available |    866,272.00 |    5.77 |    0.66 | 102,962.94 | 21,297 | 3,226,213 | 30,725 |\n",
                        "| **NEGany~immediately_able**      | able      |    428,268.00 |    4.87 |    0.58 |   2,851.84 |    639 | 3,226,213 |  1,036 |\n",
                        "| **NEGany~immediately_obvious**   | obvious   |    193,498.00 |    4.59 |    0.49 |   9,043.23 |  2,258 | 3,226,213 |  4,305 |\n",
                        "\n",
                        "\n",
                        "#### Top 1 `NEGmirror` \"immediately_*\" bigrams (sorted by `dP1`; `LRC > 1`)\n",
                        "\n",
                        "\n",
                        "|                                  | `adj`     |   `adj_total` |   `LRC` |   `dP1` |   `G2` |   `f` |    `f1` |   `f2` |\n",
                        "|:---------------------------------|:----------|--------------:|--------:|--------:|-------:|------:|--------:|-------:|\n",
                        "| **NEGmir~immediately_available** | available |     12,636.00 |    1.94 |    0.43 | 254.47 |   162 | 289,770 |    274 |\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "def show_adv_bigrams(sample_size, C,\n",
                "                     bigram_dfs,\n",
                "                     selector: str = 'dP1',\n",
                "                     column_list: list = None) -> dict:\n",
                "    def _force_ints(_df):\n",
                "        count_cols = _df.filter(regex=r'total$|^[fN]').columns\n",
                "        _df.loc[:, count_cols] = _df.loc[:,count_cols].apply(\n",
                "            pd.to_numeric, downcast='unsigned')\n",
                "        return _df\n",
                "    bigram_k = max(sample_size + 2, 10)\n",
                "    print(\n",
                "        f'## Top {bigram_k} \"most negative\" bigrams corresponding to top {K} adverbs\\n')\n",
                "    print(timestamp_today())\n",
                "    patterns = list(bigram_dfs.keys())\n",
                "    top_adverbs = C.index\n",
                "    bigram_samples = dict.fromkeys(top_adverbs)\n",
                "    bigrams = []\n",
                "    adj = []\n",
                "    for rank, adv in enumerate(top_adverbs, start=1):\n",
                "        print(f'\\n### {rank}. _{adv}_\\n')\n",
                "        adv_top = None\n",
                "        bigram_samples[adv] = dict.fromkeys(patterns + ['both', 'adj'])\n",
                "        adj_for_adv = []\n",
                "        for pat, bdf in bigram_dfs.items():\n",
                "            # avoid KeyError while maintaining intended order\n",
                "            bdf = adjust_assoc_columns(\n",
                "                bdf[[c for c in FOCUS+['adj', 'adj_total', 'adv', 'adv_total']\n",
                "                     if c in bdf.columns]\n",
                "                    ])\n",
                "            # > Force significant & positive association according to LRC\n",
                "            bdf = bdf.loc[bdf.LRC >= 1, :]\n",
                "\n",
                "            bdf = _force_ints(bdf.loc[bdf.adv == adv, :])\n",
                "            top_by_metric = [bdf.nlargest(bigram_k *2, m)\n",
                "                 for m in\n",
                "                 ['dP1', 'LRC']\n",
                "                 #  [selector, list({'LRC', 'dP1'} - {selector}[0]])\n",
                "            ]\n",
                "            half_k = bigram_k//2\n",
                "            adv_pat_bigrams = pd.concat(\n",
                "                [top_bigrams.head(half_k) for top_bigrams in top_by_metric]\n",
                "            ).drop_duplicates()\n",
                "            if len(bdf) >= bigram_k:\n",
                "                x=0\n",
                "                while len(adv_pat_bigrams) < bigram_k: \n",
                "                    x += 1\n",
                "                    next_ix = half_k + x\n",
                "                    adv_pat_bigrams = pd.concat((adv_pat_bigrams, \n",
                "                                                top_by_metric[0].iloc[[next_ix], :], \n",
                "                                                top_by_metric[1].iloc[[next_ix], :])\n",
                "                                                ).drop_duplicates()\n",
                "                adv_pat_bigrams = adv_pat_bigrams.head(bigram_k)\n",
                "\n",
                "            if adv_pat_bigrams.empty:\n",
                "                print(f'No bigrams found in loaded `{pat}` AM table.')\n",
                "            else:\n",
                "                print(\n",
                "                    f'\\n#### Top {len(adv_pat_bigrams)} `{pat}` \"{adv}_*\" bigrams (sorted by `{selector}`; `LRC > 1`)\\n')\n",
                "                column_list = column_list or bdf.columns\n",
                "                nb_show_table(adv_pat_bigrams[column_list], n_dec=2)\n",
                "\n",
                "            adj_for_adv.extend(adv_pat_bigrams.adj.drop_duplicates().to_list())\n",
                "\n",
                "            bigram_samples[adv][pat] = adv_pat_bigrams\n",
                "\n",
                "            adv_top = adv_pat_bigrams if adv_top is None else pd.concat(\n",
                "                [adv_top, adv_pat_bigrams])\n",
                "\n",
                "        bigram_samples[adv]['adj'] = set(adj_for_adv)\n",
                "        bigrams.extend(adv_top.l2.drop_duplicates().to_list())\n",
                "        adj.extend(adj_for_adv)\n",
                "        bigram_samples[adv]['both'] = adv_top\n",
                "    bigram_samples['bigrams'] = set(bigrams)\n",
                "    bigram_samples['adj'] = set(adj)\n",
                "    return bigram_samples, bigram_k\n",
                "\n",
                "\n",
                "samples_dict, bigram_k = show_adv_bigrams(\n",
                "    K, C, bigram_dfs,\n",
                "    column_list=[\n",
                "        'adj', 'adj_total',\n",
                "        *pd.Series(main_cols_ordered).str.replace(\n",
                "            r'mean_|_SET|_MIR', '', regex=True)\n",
                "        .drop_duplicates().to_list(),\n",
                "        # 't', 'MI'\n",
                "    ]\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Top 10 \"most negative\" bigrams corresponding to top 5 adverbs\n",
                "\n",
                "2024-05-23\n",
                "\n",
                "### 1. _necessarily_\n",
                "\n",
                "\n",
                "#### Top 10 `RBdirect` \"necessarily_*\" bigrams (sorted by `dP1`; `LRC > 1`)\n",
                "\n",
                "\n",
                "|                                       | `adj`          |   `adj_total` |   `LRC` |   `dP1` |      `G2` |   `f` |      `f1` |   `f2` |\n",
                "|:--------------------------------------|:---------------|--------------:|--------:|--------:|----------:|------:|----------:|-------:|\n",
                "| **NEGany~necessarily_sure**           | sure           |    844,981.00 |    5.91 |    0.95 |  1,436.68 |   222 | 3,226,213 |    224 |\n",
                "| **NEGany~necessarily_surprising**     | surprising     |    150,067.00 |    7.22 |    0.93 |  2,150.86 |   343 | 3,226,213 |    355 |\n",
                "| **NEGany~necessarily_indicative**     | indicative     |     12,760.00 |    8.37 |    0.93 |  8,811.69 | 1,406 | 3,226,213 |  1,456 |\n",
                "| **NEGany~necessarily_representative** | representative |     25,187.00 |    7.31 |    0.91 |  3,044.27 |   496 | 3,226,213 |    524 |\n",
                "| **NEGany~necessarily_available**      | available      |    866,272.00 |    6.36 |    0.89 |  1,280.24 |   213 | 3,226,213 |    230 |\n",
                "| **NEGany~necessarily_easy**           | easy           |    771,307.00 |    7.26 |    0.88 |  5,448.34 |   914 | 3,226,213 |    996 |\n",
                "| **NEGany~necessarily_true**           | true           |    348,994.00 |    6.89 |    0.82 | 18,199.76 | 3,238 | 3,226,213 |  3,786 |\n",
                "| **NEGany~necessarily_illegal**        | illegal        |     44,028.00 |    6.48 |    0.87 |  1,659.90 |   280 | 3,226,213 |    307 |\n",
                "| **NEGany~necessarily_related**        | related        |    137,661.00 |    6.74 |    0.84 |  4,271.76 |   742 | 3,226,213 |    842 |\n",
                "| **NEGany~necessarily_interested**     | interested     |    364,497.00 |    6.77 |    0.87 |  2,500.26 |   422 | 3,226,213 |    463 |\n",
                "\n",
                "\n",
                "#### Top 3 `NEGmirror` \"necessarily_*\" bigrams (sorted by `dP1`; `LRC > 1`)\n",
                "\n",
                "\n",
                "|                              | `adj`   |   `adj_total` |   `LRC` |   `dP1` |   `G2` |   `f` |    `f1` |   `f2` |\n",
                "|:-----------------------------|:--------|--------------:|--------:|--------:|-------:|------:|--------:|-------:|\n",
                "| **NEGmir~necessarily_wrong** | wrong   |     20,866.00 |    4.27 |    0.81 | 708.98 |   209 | 289,770 |    214 |\n",
                "| **NEGmir~necessarily_bad**   | bad     |     10,783.00 |    2.02 |    0.76 | 153.43 |    50 | 289,770 |     54 |\n",
                "| **NEGmir~necessarily_true**  | true    |      7,402.00 |    2.18 |    0.75 | 159.07 |    53 | 289,770 |     58 |\n",
                "\n",
                "\n",
                "### 2. _exactly_\n",
                "\n",
                "\n",
                "#### Top 10 `RBdirect` \"exactly_*\" bigrams (sorted by `dP1`; `LRC > 1`)\n",
                "\n",
                "\n",
                "|                               | `adj`      |   `adj_total` |   `LRC` |   `dP1` |      `G2` |   `f` |      `f1` |   `f2` |\n",
                "|:------------------------------|:-----------|--------------:|--------:|--------:|----------:|------:|----------:|-------:|\n",
                "| **NEGany~exactly_surprising** | surprising |    150,067.00 |    7.34 |    0.96 |  2,863.35 |   441 | 3,226,213 |    444 |\n",
                "| **NEGany~exactly_cheap**      | cheap      |     83,765.00 |    8.28 |    0.95 |  4,443.27 |   693 | 3,226,213 |    704 |\n",
                "| **NEGany~exactly_subtle**     | subtle     |     56,845.00 |    6.92 |    0.94 |  1,671.02 |   264 | 3,226,213 |    271 |\n",
                "| **NEGany~exactly_fun**        | fun        |    224,457.00 |    6.67 |    0.94 |  1,423.92 |   225 | 3,226,213 |    231 |\n",
                "| **NEGany~exactly_conducive**  | conducive  |     16,405.00 |    6.56 |    0.93 |  1,313.09 |   208 | 3,226,213 |    214 |\n",
                "| **NEGany~exactly_sure**       | sure       |    844,981.00 |    8.63 |    0.92 | 54,750.58 | 8,860 | 3,226,213 |  9,301 |\n",
                "| **NEGany~exactly_new**        | new        |    321,311.00 |    8.54 |    0.93 |  8,697.93 | 1,378 | 3,226,213 |  1,418 |\n",
                "| **NEGany~exactly_easy**       | easy       |    771,307.00 |    8.37 |    0.93 |  6,747.64 | 1,069 | 3,226,213 |  1,100 |\n",
                "| **NEGany~exactly_clear**      | clear      |    491,108.00 |    8.30 |    0.92 | 10,937.16 | 1,759 | 3,226,213 |  1,835 |\n",
                "| **NEGany~exactly_happy**      | happy      |    528,511.00 |    7.16 |    0.90 |  2,694.69 |   441 | 3,226,213 |    468 |\n",
                "\n",
                "No bigrams found in loaded `NEGmirror` AM table.\n",
                "\n",
                "### 3. _that_\n",
                "\n",
                "\n",
                "#### Top 10 `RBdirect` \"that_*\" bigrams (sorted by `dP1`; `LRC > 1`)\n",
                "\n",
                "\n",
                "|                             | `adj`       |   `adj_total` |   `LRC` |   `dP1` |      `G2` |   `f` |      `f1` |   `f2` |\n",
                "|:----------------------------|:------------|--------------:|--------:|--------:|----------:|------:|----------:|-------:|\n",
                "| **NEGany~that_uncommon**    | uncommon    |     61,767.00 |    8.39 |    0.94 |  5,136.91 |   804 | 3,226,213 |    819 |\n",
                "| **NEGany~that_fond**        | fond        |     39,809.00 |    7.27 |    0.94 |  2,127.94 |   334 | 3,226,213 |    341 |\n",
                "| **NEGany~that_surprising**  | surprising  |    150,067.00 |    8.14 |    0.92 |  7,115.30 | 1,141 | 3,226,213 |  1,187 |\n",
                "| **NEGany~that_common**      | common      |    556,435.00 |    8.12 |    0.92 |  7,564.08 | 1,216 | 3,226,213 |  1,268 |\n",
                "| **NEGany~that_dissimilar**  | dissimilar  |      8,816.00 |    7.00 |    0.92 |  1,904.15 |   307 | 3,226,213 |    321 |\n",
                "| **NEGany~that_hard**        | hard        |    430,990.00 |    7.96 |    0.88 | 59,642.82 | 9,966 | 3,226,213 | 10,818 |\n",
                "| **NEGany~that_complicated** | complicated |    180,071.00 |    7.95 |    0.91 |  7,450.89 | 1,208 | 3,226,213 |  1,270 |\n",
                "| **NEGany~that_impressed**   | impressed   |    113,281.00 |    7.57 |    0.91 |  4,207.58 |   684 | 3,226,213 |    721 |\n",
                "| **NEGany~that_noticeable**  | noticeable  |     40,372.00 |    6.78 |    0.91 |  1,632.07 |   265 | 3,226,213 |    279 |\n",
                "| **NEGany~that_exciting**    | exciting    |    236,396.00 |    7.48 |    0.90 |  4,892.83 |   805 | 3,226,213 |    859 |\n",
                "\n",
                "\n",
                "#### Top 10 `NEGmirror` \"that_*\" bigrams (sorted by `dP1`; `LRC > 1`)\n",
                "\n",
                "\n",
                "|                            | `adj`      |   `adj_total` |   `LRC` |   `dP1` |     `G2` |   `f` |    `f1` |   `f2` |\n",
                "|:---------------------------|:-----------|--------------:|--------:|--------:|---------:|------:|--------:|-------:|\n",
                "| **NEGmir~that_popular**    | popular    |      5,787.00 |    2.50 |    0.76 |   200.44 |    65 | 289,770 |     70 |\n",
                "| **NEGmir~that_interested** | interested |      9,258.00 |    2.42 |    0.76 |   190.06 |    62 | 289,770 |     67 |\n",
                "| **NEGmir~that_difficult**  | difficult  |     16,043.00 |    2.15 |    0.75 |   155.64 |    52 | 289,770 |     57 |\n",
                "| **NEGmir~that_hard**       | hard       |      7,311.00 |    2.31 |    0.74 |   168.31 |    57 | 289,770 |     63 |\n",
                "| **NEGmir~that_close**      | close      |     13,962.00 |    2.39 |    0.73 |   174.26 |    60 | 289,770 |     67 |\n",
                "| **NEGmir~that_simple**     | simple     |     25,382.00 |    4.34 |    0.73 | 1,370.94 |   473 | 289,770 |    529 |\n",
                "| **NEGmir~that_easy**       | easy       |     20,050.00 |    4.21 |    0.72 | 1,258.15 |   442 | 289,770 |    500 |\n",
                "| **NEGmir~that_great**      | great      |      5,819.00 |    3.52 |    0.67 |   728.46 |   282 | 289,770 |    340 |\n",
                "| **NEGmir~that_good**       | good       |     33,540.00 |    3.07 |    0.56 |   953.31 |   447 | 289,770 |    615 |\n",
                "| **NEGmir~that_big**        | big        |      7,859.00 |    3.06 |    0.70 |   309.58 |   113 | 289,770 |    131 |\n",
                "\n",
                "\n",
                "### 4. _before_\n",
                "\n",
                "No bigrams found in loaded `RBdirect` AM table.\n",
                "No bigrams found in loaded `NEGmirror` AM table.\n",
                "\n",
                "### 5. _any_\n",
                "\n",
                "\n",
                "#### Top 10 `RBdirect` \"any_*\" bigrams (sorted by `dP1`; `LRC > 1`)\n",
                "\n",
                "\n",
                "|                          | `adj`     |   `adj_total` |   `LRC` |   `dP1` |     `G2` |   `f` |      `f1` |   `f2` |\n",
                "|:-------------------------|:----------|--------------:|--------:|--------:|---------:|------:|----------:|-------:|\n",
                "| **NEGany~any_happier**   | happier   |     19,501.00 |    4.65 |    0.53 | 3,488.76 |   830 | 3,226,213 |  1,472 |\n",
                "| **NEGany~any_simpler**   | simpler   |     26,094.00 |    3.09 |    0.30 |   671.74 |   228 | 3,226,213 |    672 |\n",
                "| **NEGany~any_clearer**   | clearer   |     13,369.00 |    3.21 |    0.30 | 1,051.22 |   357 | 3,226,213 |  1,053 |\n",
                "| **NEGany~any_different** | different |    909,864.00 |    2.98 |    0.24 | 2,270.24 |   910 | 3,226,213 |  3,313 |\n",
                "| **NEGany~any_younger**   | younger   |     29,805.00 |    2.37 |    0.19 |   544.17 |   256 | 3,226,213 |  1,121 |\n",
                "| **NEGany~any_worse**     | worse     |    214,166.00 |    2.47 |    0.16 | 3,165.88 | 1,693 | 3,226,213 |  8,487 |\n",
                "| **NEGany~any_bigger**    | bigger    |    130,470.00 |    2.27 |    0.17 |   688.06 |   357 | 3,226,213 |  1,735 |\n",
                "| **NEGany~any_harder**    | harder    |     99,332.00 |    1.98 |    0.15 |   395.22 |   227 | 3,226,213 |  1,221 |\n",
                "| **NEGany~any_safer**     | safer     |     26,779.00 |    1.73 |    0.12 |   346.68 |   235 | 3,226,213 |  1,471 |\n",
                "| **NEGany~any_easier**    | easier    |    237,680.00 |    1.95 |    0.11 | 2,164.75 | 1,607 | 3,226,213 | 10,860 |\n",
                "\n",
                "\n",
                "#### Top 4 `NEGmirror` \"any_*\" bigrams (sorted by `dP1`; `LRC > 1`)\n",
                "\n",
                "\n",
                "|                       | `adj`   |   `adj_total` |   `LRC` |   `dP1` |     `G2` |   `f` |    `f1` |   `f2` |\n",
                "|:----------------------|:--------|--------------:|--------:|--------:|---------:|------:|--------:|-------:|\n",
                "| **NEGmir~any_better** | better  |     14,076.00 |    4.44 |    0.75 | 1,148.18 |   381 | 289,770 |    416 |\n",
                "| **NEGmir~any_easier** | easier  |      2,409.00 |    2.42 |    0.75 |   181.98 |    61 | 289,770 |     67 |\n",
                "| **NEGmir~any_worse**  | worse   |      8,490.00 |    2.87 |    0.72 |   248.63 |    88 | 289,770 |    100 |\n",
                "| **NEGmir~any_closer** | closer  |        986.00 |    2.21 |    0.68 |   149.62 |    56 | 289,770 |     66 |\n",
                "\n",
                "\n",
                "### 6. _ever_\n",
                "\n",
                "\n",
                "#### Top 5 `RBdirect` \"ever_*\" bigrams (sorted by `dP1`; `LRC > 1`)\n",
                "\n",
                "\n",
                "|                         | `adj`   |   `adj_total` |   `LRC` |   `dP1` |     `G2` |   `f` |      `f1` |   `f2` |\n",
                "|:------------------------|:--------|--------------:|--------:|--------:|---------:|------:|----------:|-------:|\n",
                "| **NEGany~ever_simple**  | simple  |    427,167.00 |    5.54 |    0.77 | 1,142.04 |   212 | 3,226,213 |    262 |\n",
                "| **NEGany~ever_easy**    | easy    |    771,307.00 |    5.06 |    0.63 | 2,030.58 |   430 | 3,226,213 |    641 |\n",
                "| **NEGany~ever_good**    | good    |  2,037,285.00 |    3.76 |    0.40 | 1,178.00 |   332 | 3,226,213 |    756 |\n",
                "| **NEGany~ever_perfect** | perfect |    164,519.00 |    3.48 |    0.37 |   736.05 |   217 | 3,226,213 |    527 |\n",
                "| **NEGany~ever_able**    | able    |    428,268.00 |    1.81 |    0.13 |   363.95 |   234 | 3,226,213 |  1,398 |\n",
                "\n",
                "\n",
                "#### Top 6 `NEGmirror` \"ever_*\" bigrams (sorted by `dP1`; `LRC > 1`)\n",
                "\n",
                "\n",
                "|                         | `adj`   |   `adj_total` |   `LRC` |   `dP1` |     `G2` |   `f` |    `f1` |   `f2` |\n",
                "|:------------------------|:--------|--------------:|--------:|--------:|---------:|------:|--------:|-------:|\n",
                "| **NEGmir~ever_easy**    | easy    |     20,050.00 |    3.21 |    0.83 | 1,311.83 |   367 | 289,770 |    368 |\n",
                "| **NEGmir~ever_perfect** | perfect |      3,708.00 |    2.38 |    0.83 |   735.10 |   207 | 289,770 |    208 |\n",
                "| **NEGmir~ever_good**    | good    |     33,540.00 |    4.72 |    0.82 | 1,034.95 |   298 | 289,770 |    302 |\n",
                "| **NEGmir~ever_wrong**   | wrong   |     20,866.00 |    2.56 |    0.82 |   349.21 |   102 | 289,770 |    104 |\n",
                "| **NEGmir~ever_free**    | free    |      5,043.00 |    1.97 |    0.81 |   231.61 |    69 | 289,770 |     71 |\n",
                "| **NEGmir~ever_able**    | able    |      6,448.00 |    3.66 |    0.79 |   437.65 |   136 | 289,770 |    143 |\n",
                "\n",
                "\n",
                "### 7. _yet_\n",
                "\n",
                "\n",
                "#### Top 10 `RBdirect` \"yet_*\" bigrams (sorted by `dP1`; `LRC > 1`)\n",
                "\n",
                "\n",
                "|                          | `adj`     |   `adj_total` |   `LRC` |   `dP1` |      `G2` |    `f` |      `f1` |   `f2` |\n",
                "|:-------------------------|:----------|--------------:|--------:|--------:|----------:|-------:|----------:|-------:|\n",
                "| **NEGany~yet_clear**     | clear     |    491,108.00 |   10.26 |    0.95 | 67,924.56 | 10,553 | 3,226,213 | 10,693 |\n",
                "| **NEGany~yet_eligible**  | eligible  |     49,578.00 |    7.72 |    0.94 |  2,929.15 |    459 | 3,226,213 |    468 |\n",
                "| **NEGany~yet_official**  | official  |      9,778.00 |    7.33 |    0.94 |  2,236.98 |    353 | 3,226,213 |    362 |\n",
                "| **NEGany~yet_ready**     | ready     |    240,297.00 |    9.23 |    0.93 | 48,012.06 |  7,611 | 3,226,213 |  7,838 |\n",
                "| **NEGany~yet_certain**   | certain   |    104,544.00 |    8.12 |    0.93 |  5,491.41 |    874 | 3,226,213 |    903 |\n",
                "| **NEGany~yet_complete**  | complete  |    107,018.00 |    8.42 |    0.92 | 13,815.99 |  2,220 | 3,226,213 |  2,314 |\n",
                "| **NEGany~yet_sure**      | sure      |    844,981.00 |    8.37 |    0.92 | 12,379.79 |  1,990 | 3,226,213 |  2,075 |\n",
                "| **NEGany~yet_available** | available |    866,272.00 |    7.69 |    0.87 | 44,196.15 |  7,481 | 3,226,213 |  8,238 |\n",
                "| **NEGany~yet_right**     | right     |    204,572.00 |    6.50 |    0.92 |  1,254.20 |    202 | 3,226,213 |    211 |\n",
                "| **NEGany~yet_final**     | final     |      9,657.00 |    7.45 |    0.91 |  4,028.75 |    659 | 3,226,213 |    699 |\n",
                "\n",
                "No bigrams found in loaded `NEGmirror` AM table.\n",
                "\n",
                "### 8. _longer_\n",
                "\n",
                "\n",
                "#### Top 5 `RBdirect` \"longer_*\" bigrams (sorted by `dP1`; `LRC > 1`)\n",
                "\n",
                "\n",
                "|                          | `adj`     |   `adj_total` |   `LRC` |   `dP1` |   `G2` |    `f` |       `f1` |   `f2` |\n",
                "|:-------------------------|:----------|--------------:|--------:|--------:|-------:|-------:|-----------:|-------:|\n",
                "| **COM~longer_lasting**   | lasting   |     24,344.00 |    1.44 |    0.04 | 244.09 |  3,860 | 83,102,035 |  3,866 |\n",
                "| **COM~longer_enough**    | enough    |    453,790.00 |    1.41 |    0.03 | 216.98 |  3,952 | 83,102,035 |  3,964 |\n",
                "| **COM~longer_able**      | able      |    428,268.00 |    2.28 |    0.03 | 623.67 | 11,677 | 83,102,035 | 11,716 |\n",
                "| **COM~longer_available** | available |    866,272.00 |    2.45 |    0.03 | 974.55 | 18,865 | 83,102,035 | 18,935 |\n",
                "| **COM~longer_necessary** | necessary |    187,396.00 |    1.27 |    0.03 | 220.07 |  5,365 | 83,102,035 |  5,399 |\n",
                "\n",
                "No bigrams found in loaded `NEGmirror` AM table.\n",
                "\n",
                "### 9. _immediately_\n",
                "\n",
                "\n",
                "#### Top 5 `RBdirect` \"immediately_*\" bigrams (sorted by `dP1`; `LRC > 1`)\n",
                "\n",
                "\n",
                "|                                  | `adj`     |   `adj_total` |   `LRC` |   `dP1` |       `G2` |    `f` |      `f1` |   `f2` |\n",
                "|:---------------------------------|:----------|--------------:|--------:|--------:|-----------:|-------:|----------:|-------:|\n",
                "| **NEGany~immediately_possible**  | possible  |    364,265.00 |    7.68 |    0.90 |   6,269.26 |  1,027 | 3,226,213 |  1,091 |\n",
                "| **NEGany~immediately_clear**     | clear     |    491,108.00 |    8.32 |    0.90 | 153,302.22 | 25,276 | 3,226,213 | 27,066 |\n",
                "| **NEGany~immediately_available** | available |    866,272.00 |    5.77 |    0.66 | 102,962.94 | 21,297 | 3,226,213 | 30,725 |\n",
                "| **NEGany~immediately_able**      | able      |    428,268.00 |    4.87 |    0.58 |   2,851.84 |    639 | 3,226,213 |  1,036 |\n",
                "| **NEGany~immediately_obvious**   | obvious   |    193,498.00 |    4.59 |    0.49 |   9,043.23 |  2,258 | 3,226,213 |  4,305 |\n",
                "\n",
                "\n",
                "#### Top 1 `NEGmirror` \"immediately_*\" bigrams (sorted by `dP1`; `LRC > 1`)\n",
                "\n",
                "\n",
                "|                                  | `adj`     |   `adj_total` |   `LRC` |   `dP1` |   `G2` |   `f` |    `f1` |   `f2` |\n",
                "|:---------------------------------|:----------|--------------:|--------:|--------:|-------:|------:|--------:|-------:|\n",
                "| **NEGmir~immediately_available** | available |     12,636.00 |    1.94 |    0.43 | 254.47 |   162 | 289,770 |    274 |\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 99,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>l1</th>\n",
                            "      <th>l2</th>\n",
                            "      <th>f</th>\n",
                            "      <th>E11</th>\n",
                            "      <th>am_log_likelihood</th>\n",
                            "      <th>am_odds_ratio_disc</th>\n",
                            "      <th>...</th>\n",
                            "      <th>f1_sqrt</th>\n",
                            "      <th>f2_sqrt</th>\n",
                            "      <th>adv</th>\n",
                            "      <th>adj</th>\n",
                            "      <th>adv_total</th>\n",
                            "      <th>adj_total</th>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>key</th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>0 rows  49 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "Empty DataFrame\n",
                            "Columns: [l1, l2, f, E11, am_log_likelihood, am_odds_ratio_disc, am_p1_given2, am_p2_given1, am_p1_given2_simple, am_p2_given1_simple, f1, f2, N, Fyy(O11), Fyn(O12), Fny(O21), Fnn(O22), Fy_(R1), Fn_(R2), F_y(C1), F_n(C2), E12, E21, E22, t_score, dice, liddell, mutual_information, deltaP_min, deltaP_max, deltaP_max_abs, deltaP_product, unexpected_f, unexpected_ratio, expected_sqrt, unexpected_abs_sqrt, conservative_log_ratio, conservative_log_ratio_001, conservative_log_ratio_01, conservative_log_ratio_05, conservative_log_ratio_nc, conservative_log_ratio_dv, f_sqrt, f1_sqrt, f2_sqrt, adv, adj, adv_total, adj_total]\n",
                            "Index: []\n",
                            "\n",
                            "[0 rows x 49 columns]"
                        ]
                    },
                    "execution_count": 99,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "bigram_dfs['RBdirect'].filter(like='~before_', axis=0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 100,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "1. _necessarily_ (12 unique)\n",
                        "   1. _representative_\n",
                        "   1. _surprising_\n",
                        "   1. _wrong_\n",
                        "   1. _bad_\n",
                        "   1. _available_\n",
                        "   1. _related_\n",
                        "   1. _illegal_\n",
                        "   1. _indicative_\n",
                        "   1. _true_\n",
                        "   1. _sure_\n",
                        "   1. _easy_\n",
                        "   1. _interested_\n",
                        "\n",
                        "1. _exactly_ (10 unique)\n",
                        "   1. _clear_\n",
                        "   1. _subtle_\n",
                        "   1. _surprising_\n",
                        "   1. _fun_\n",
                        "   1. _new_\n",
                        "   1. _conducive_\n",
                        "   1. _cheap_\n",
                        "   1. _sure_\n",
                        "   1. _happy_\n",
                        "   1. _easy_\n",
                        "\n",
                        "1. _that_ (19 unique)\n",
                        "   1. _hard_\n",
                        "   1. _good_\n",
                        "   1. _dissimilar_\n",
                        "   1. _simple_\n",
                        "   1. _noticeable_\n",
                        "   1. _close_\n",
                        "   1. _exciting_\n",
                        "   1. _surprising_\n",
                        "   1. _great_\n",
                        "   1. _difficult_\n",
                        "   1. _easy_\n",
                        "   1. _big_\n",
                        "   1. _common_\n",
                        "   1. _uncommon_\n",
                        "   1. _popular_\n",
                        "   1. _fond_\n",
                        "   1. _impressed_\n",
                        "   1. _complicated_\n",
                        "   1. _interested_\n",
                        "\n",
                        "1. _before_ (0 unique)\n",
                        "\n",
                        "\n",
                        "1. _any_ (12 unique)\n",
                        "   1. _simpler_\n",
                        "   1. _worse_\n",
                        "   1. _better_\n",
                        "   1. _easier_\n",
                        "   1. _younger_\n",
                        "   1. _harder_\n",
                        "   1. _happier_\n",
                        "   1. _safer_\n",
                        "   1. _clearer_\n",
                        "   1. _bigger_\n",
                        "   1. _closer_\n",
                        "   1. _different_\n",
                        "\n",
                        "1. _ever_ (7 unique)\n",
                        "   1. _simple_\n",
                        "   1. _perfect_\n",
                        "   1. _good_\n",
                        "   1. _wrong_\n",
                        "   1. _able_\n",
                        "   1. _easy_\n",
                        "   1. _free_\n",
                        "\n",
                        "1. _yet_ (10 unique)\n",
                        "   1. _clear_\n",
                        "   1. _certain_\n",
                        "   1. _available_\n",
                        "   1. _right_\n",
                        "   1. _eligible_\n",
                        "   1. _final_\n",
                        "   1. _complete_\n",
                        "   1. _sure_\n",
                        "   1. _official_\n",
                        "   1. _ready_\n",
                        "\n",
                        "1. _longer_ (5 unique)\n",
                        "   1. _lasting_\n",
                        "   1. _available_\n",
                        "   1. _able_\n",
                        "   1. _enough_\n",
                        "   1. _necessary_\n",
                        "\n",
                        "1. _immediately_ (5 unique)\n",
                        "   1. _clear_\n",
                        "   1. _obvious_\n",
                        "   1. _available_\n",
                        "   1. _able_\n",
                        "   1. _possible_\n",
                        "\n",
                        "1. _ALL bigrams_ (80 unique)\n",
                        "   1. _longer able_\n",
                        "   1. _exactly subtle_\n",
                        "   1. _that big_\n",
                        "   1. _that impressed_\n",
                        "   1. _yet certain_\n",
                        "   1. _necessarily easy_\n",
                        "   1. _that hard_\n",
                        "   1. _yet official_\n",
                        "   1. _yet clear_\n",
                        "   1. _that popular_\n",
                        "   1. _that uncommon_\n",
                        "   1. _that complicated_\n",
                        "   1. _immediately obvious_\n",
                        "   1. _yet ready_\n",
                        "   1. _ever wrong_\n",
                        "   1. _necessarily surprising_\n",
                        "   1. _that surprising_\n",
                        "   1. _yet eligible_\n",
                        "   1. _that exciting_\n",
                        "   1. _any safer_\n",
                        "   1. _that great_\n",
                        "   1. _necessarily bad_\n",
                        "   1. _necessarily available_\n",
                        "   1. _any closer_\n",
                        "   1. _yet right_\n",
                        "   1. _yet complete_\n",
                        "   1. _longer necessary_\n",
                        "   1. _ever able_\n",
                        "   1. _that close_\n",
                        "   1. _exactly conducive_\n",
                        "   1. _exactly easy_\n",
                        "   1. _ever free_\n",
                        "   1. _immediately available_\n",
                        "   1. _that easy_\n",
                        "   1. _necessarily sure_\n",
                        "   1. _necessarily representative_\n",
                        "   1. _exactly happy_\n",
                        "   1. _ever perfect_\n",
                        "   1. _that interested_\n",
                        "   1. _necessarily illegal_\n",
                        "   1. _that fond_\n",
                        "   1. _immediately able_\n",
                        "   1. _any better_\n",
                        "   1. _that common_\n",
                        "   1. _yet sure_\n",
                        "   1. _any simpler_\n",
                        "   1. _ever good_\n",
                        "   1. _exactly new_\n",
                        "   1. _longer lasting_\n",
                        "   1. _yet available_\n",
                        "   1. _necessarily true_\n",
                        "   1. _exactly cheap_\n",
                        "   1. _that dissimilar_\n",
                        "   1. _exactly sure_\n",
                        "   1. _exactly surprising_\n",
                        "   1. _any bigger_\n",
                        "   1. _necessarily indicative_\n",
                        "   1. _that difficult_\n",
                        "   1. _exactly clear_\n",
                        "   1. _any younger_\n",
                        "   1. _exactly fun_\n",
                        "   1. _yet final_\n",
                        "   1. _ever easy_\n",
                        "   1. _that noticeable_\n",
                        "   1. _immediately possible_\n",
                        "   1. _necessarily related_\n",
                        "   1. _any different_\n",
                        "   1. _any happier_\n",
                        "   1. _any easier_\n",
                        "   1. _any harder_\n",
                        "   1. _ever simple_\n",
                        "   1. _necessarily wrong_\n",
                        "   1. _any clearer_\n",
                        "   1. _necessarily interested_\n",
                        "   1. _longer enough_\n",
                        "   1. _that simple_\n",
                        "   1. _any worse_\n",
                        "   1. _longer available_\n",
                        "   1. _that good_\n",
                        "   1. _immediately clear_\n",
                        "\n",
                        "1. _ALL adjectives_ (62 unique)\n",
                        "   1. _hard_\n",
                        "   1. _clear_\n",
                        "   1. _good_\n",
                        "   1. _better_\n",
                        "   1. _fun_\n",
                        "   1. _easier_\n",
                        "   1. _dissimilar_\n",
                        "   1. _right_\n",
                        "   1. _cheap_\n",
                        "   1. _happy_\n",
                        "   1. _enough_\n",
                        "   1. _simple_\n",
                        "   1. _obvious_\n",
                        "   1. _subtle_\n",
                        "   1. _available_\n",
                        "   1. _able_\n",
                        "   1. _noticeable_\n",
                        "   1. _conducive_\n",
                        "   1. _happier_\n",
                        "   1. _eligible_\n",
                        "   1. _sure_\n",
                        "   1. _close_\n",
                        "   1. _exciting_\n",
                        "   1. _ready_\n",
                        "   1. _closer_\n",
                        "   1. _simpler_\n",
                        "   1. _perfect_\n",
                        "   1. _representative_\n",
                        "   1. _surprising_\n",
                        "   1. _related_\n",
                        "   1. _great_\n",
                        "   1. _illegal_\n",
                        "   1. _new_\n",
                        "   1. _harder_\n",
                        "   1. _indicative_\n",
                        "   1. _true_\n",
                        "   1. _clearer_\n",
                        "   1. _difficult_\n",
                        "   1. _easy_\n",
                        "   1. _bigger_\n",
                        "   1. _free_\n",
                        "   1. _different_\n",
                        "   1. _official_\n",
                        "   1. _big_\n",
                        "   1. _necessary_\n",
                        "   1. _worse_\n",
                        "   1. _wrong_\n",
                        "   1. _bad_\n",
                        "   1. _certain_\n",
                        "   1. _lasting_\n",
                        "   1. _common_\n",
                        "   1. _uncommon_\n",
                        "   1. _younger_\n",
                        "   1. _final_\n",
                        "   1. _safer_\n",
                        "   1. _popular_\n",
                        "   1. _complete_\n",
                        "   1. _possible_\n",
                        "   1. _fond_\n",
                        "   1. _impressed_\n",
                        "   1. _complicated_\n",
                        "   1. _interested_\n"
                    ]
                }
            ],
            "source": [
                "for key, info in samples_dict.items():\n",
                "    if key in ('bigrams', 'adj'):\n",
                "        key = f'ALL {key.replace(\"adj\", \"adjectives\")}'\n",
                "    formatted_iter = [\n",
                "        f'_{a.replace(\"_\", \" \")}_' for a\n",
                "        in (info['adj'] if isinstance(info, dict)\n",
                "            else info)]\n",
                "    print_iter(formatted_iter,\n",
                "               header=f'1. _{key}_ ({len(formatted_iter)} unique)',\n",
                "               bullet='1.', indent=3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 101,
            "metadata": {},
            "outputs": [],
            "source": [
                "NEG_bigrams_sample = pd.concat(\n",
                "    (ad['both'] for ad in samples_dict.values() if isinstance(ad, dict))).sort_values('LRC', ascending=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 102,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "/share/compling/projects/sanpi/results/top_AM/Top5_NEG-ADV_top-10-bigrams.2024-05-23.csv\n",
                        "\n",
                        "|                                       |    `f` |   `dP1` |   `LRC` |       `G2` |        `N` |       `f1` |   `f2` |   `exp_f` |   `unexp_f` | `l1`       | `l2`                       | `adj`          |   `adj_total` | `adv`       |   `adv_total` |\n",
                        "|:--------------------------------------|-------:|--------:|--------:|-----------:|-----------:|-----------:|-------:|----------:|------------:|:-----------|:---------------------------|:---------------|--------------:|:------------|--------------:|\n",
                        "| **NEGany~yet_clear**                  | 10,553 |    0.95 |   10.26 |  67,924.56 | 86,330,752 |  3,226,213 | 10,693 |    399.60 |   10,153.40 | NEGATED    | yet_clear                  | clear          |    491,108.00 | yet         |    101,707.00 |\n",
                        "| **NEGany~yet_ready**                  |  7,611 |    0.93 |    9.23 |  48,012.06 | 86,330,752 |  3,226,213 |  7,838 |    292.91 |    7,318.09 | NEGATED    | yet_ready                  | ready          |    240,297.00 | yet         |    101,707.00 |\n",
                        "| **NEGany~exactly_sure**               |  8,860 |    0.92 |    8.63 |  54,750.58 | 86,330,752 |  3,226,213 |  9,301 |    347.58 |    8,512.42 | NEGATED    | exactly_sure               | sure           |    844,981.00 | exactly     |     61,599.00 |\n",
                        "| **NEGany~exactly_new**                |  1,378 |    0.93 |    8.54 |   8,697.93 | 86,330,752 |  3,226,213 |  1,418 |     52.99 |    1,325.01 | NEGATED    | exactly_new                | new            |    321,311.00 | exactly     |     61,599.00 |\n",
                        "| **NEGany~yet_complete**               |  2,220 |    0.92 |    8.42 |  13,815.99 | 86,330,752 |  3,226,213 |  2,314 |     86.48 |    2,133.52 | NEGATED    | yet_complete               | complete       |    107,018.00 | yet         |    101,707.00 |\n",
                        "| **NEGany~that_uncommon**              |    804 |    0.94 |    8.39 |   5,136.91 | 86,330,752 |  3,226,213 |    819 |     30.61 |      773.39 | NEGATED    | that_uncommon              | uncommon       |     61,767.00 | that        |    250,392.00 |\n",
                        "| **NEGany~necessarily_indicative**     |  1,406 |    0.93 |    8.37 |   8,811.69 | 86,330,752 |  3,226,213 |  1,456 |     54.41 |    1,351.59 | NEGATED    | necessarily_indicative     | indicative     |     12,760.00 | necessarily |     56,694.00 |\n",
                        "| **NEGany~yet_sure**                   |  1,990 |    0.92 |    8.37 |  12,379.79 | 86,330,752 |  3,226,213 |  2,075 |     77.54 |    1,912.46 | NEGATED    | yet_sure                   | sure           |    844,981.00 | yet         |    101,707.00 |\n",
                        "| **NEGany~exactly_easy**               |  1,069 |    0.93 |    8.37 |   6,747.64 | 86,330,752 |  3,226,213 |  1,100 |     41.11 |    1,027.89 | NEGATED    | exactly_easy               | easy           |    771,307.00 | exactly     |     61,599.00 |\n",
                        "| **NEGany~immediately_clear**          | 25,276 |    0.90 |    8.32 | 153,302.22 | 86,330,752 |  3,226,213 | 27,066 |  1,011.47 |   24,264.53 | NEGATED    | immediately_clear          | clear          |    491,108.00 | immediately |    103,177.00 |\n",
                        "| **NEGany~exactly_clear**              |  1,759 |    0.92 |    8.30 |  10,937.16 | 86,330,752 |  3,226,213 |  1,835 |     68.57 |    1,690.43 | NEGATED    | exactly_clear              | clear          |    491,108.00 | exactly     |     61,599.00 |\n",
                        "| **NEGany~exactly_cheap**              |    693 |    0.95 |    8.28 |   4,443.27 | 86,330,752 |  3,226,213 |    704 |     26.31 |      666.69 | NEGATED    | exactly_cheap              | cheap          |     83,765.00 | exactly     |     61,599.00 |\n",
                        "| **NEGany~that_surprising**            |  1,141 |    0.92 |    8.14 |   7,115.30 | 86,330,752 |  3,226,213 |  1,187 |     44.36 |    1,096.64 | NEGATED    | that_surprising            | surprising     |    150,067.00 | that        |    250,392.00 |\n",
                        "| **NEGany~that_common**                |  1,216 |    0.92 |    8.12 |   7,564.08 | 86,330,752 |  3,226,213 |  1,268 |     47.39 |    1,168.61 | NEGATED    | that_common                | common         |    556,435.00 | that        |    250,392.00 |\n",
                        "| **NEGany~yet_certain**                |    874 |    0.93 |    8.12 |   5,491.41 | 86,330,752 |  3,226,213 |    903 |     33.75 |      840.25 | NEGATED    | yet_certain                | certain        |    104,544.00 | yet         |    101,707.00 |\n",
                        "| **NEGany~that_hard**                  |  9,966 |    0.88 |    7.96 |  59,642.82 | 86,330,752 |  3,226,213 | 10,818 |    404.27 |    9,561.73 | NEGATED    | that_hard                  | hard           |    430,990.00 | that        |    250,392.00 |\n",
                        "| **NEGany~that_complicated**           |  1,208 |    0.91 |    7.95 |   7,450.89 | 86,330,752 |  3,226,213 |  1,270 |     47.46 |    1,160.54 | NEGATED    | that_complicated           | complicated    |    180,071.00 | that        |    250,392.00 |\n",
                        "| **NEGany~yet_eligible**               |    459 |    0.94 |    7.72 |   2,929.15 | 86,330,752 |  3,226,213 |    468 |     17.49 |      441.51 | NEGATED    | yet_eligible               | eligible       |     49,578.00 | yet         |    101,707.00 |\n",
                        "| **NEGany~yet_available**              |  7,481 |    0.87 |    7.69 |  44,196.15 | 86,330,752 |  3,226,213 |  8,238 |    307.86 |    7,173.14 | NEGATED    | yet_available              | available      |    866,272.00 | yet         |    101,707.00 |\n",
                        "| **NEGany~immediately_possible**       |  1,027 |    0.90 |    7.68 |   6,269.26 | 86,330,752 |  3,226,213 |  1,091 |     40.77 |      986.23 | NEGATED    | immediately_possible       | possible       |    364,265.00 | immediately |    103,177.00 |\n",
                        "| **NEGany~that_impressed**             |    684 |    0.91 |    7.57 |   4,207.58 | 86,330,752 |  3,226,213 |    721 |     26.94 |      657.06 | NEGATED    | that_impressed             | impressed      |    113,281.00 | that        |    250,392.00 |\n",
                        "| **NEGany~that_exciting**              |    805 |    0.90 |    7.48 |   4,892.83 | 86,330,752 |  3,226,213 |    859 |     32.10 |      772.90 | NEGATED    | that_exciting              | exciting       |    236,396.00 | that        |    250,392.00 |\n",
                        "| **NEGany~yet_final**                  |    659 |    0.91 |    7.45 |   4,028.75 | 86,330,752 |  3,226,213 |    699 |     26.12 |      632.88 | NEGATED    | yet_final                  | final          |      9,657.00 | yet         |    101,707.00 |\n",
                        "| **NEGany~exactly_surprising**         |    441 |    0.96 |    7.34 |   2,863.35 | 86,330,752 |  3,226,213 |    444 |     16.59 |      424.41 | NEGATED    | exactly_surprising         | surprising     |    150,067.00 | exactly     |     61,599.00 |\n",
                        "| **NEGany~yet_official**               |    353 |    0.94 |    7.33 |   2,236.98 | 86,330,752 |  3,226,213 |    362 |     13.53 |      339.47 | NEGATED    | yet_official               | official       |      9,778.00 | yet         |    101,707.00 |\n",
                        "| **NEGany~necessarily_representative** |    496 |    0.91 |    7.31 |   3,044.27 | 86,330,752 |  3,226,213 |    524 |     19.58 |      476.42 | NEGATED    | necessarily_representative | representative |     25,187.00 | necessarily |     56,694.00 |\n",
                        "| **NEGany~that_fond**                  |    334 |    0.94 |    7.27 |   2,127.94 | 86,330,752 |  3,226,213 |    341 |     12.74 |      321.26 | NEGATED    | that_fond                  | fond           |     39,809.00 | that        |    250,392.00 |\n",
                        "| **NEGany~necessarily_easy**           |    914 |    0.88 |    7.26 |   5,448.34 | 86,330,752 |  3,226,213 |    996 |     37.22 |      876.78 | NEGATED    | necessarily_easy           | easy           |    771,307.00 | necessarily |     56,694.00 |\n",
                        "| **NEGany~necessarily_surprising**     |    343 |    0.93 |    7.22 |   2,150.86 | 86,330,752 |  3,226,213 |    355 |     13.27 |      329.73 | NEGATED    | necessarily_surprising     | surprising     |    150,067.00 | necessarily |     56,694.00 |\n",
                        "| **NEGany~exactly_happy**              |    441 |    0.90 |    7.16 |   2,694.69 | 86,330,752 |  3,226,213 |    468 |     17.49 |      423.51 | NEGATED    | exactly_happy              | happy          |    528,511.00 | exactly     |     61,599.00 |\n",
                        "| **NEGany~that_dissimilar**            |    307 |    0.92 |    7.00 |   1,904.15 | 86,330,752 |  3,226,213 |    321 |     12.00 |      295.00 | NEGATED    | that_dissimilar            | dissimilar     |      8,816.00 | that        |    250,392.00 |\n",
                        "| **NEGany~exactly_subtle**             |    264 |    0.94 |    6.92 |   1,671.02 | 86,330,752 |  3,226,213 |    271 |     10.13 |      253.87 | NEGATED    | exactly_subtle             | subtle         |     56,845.00 | exactly     |     61,599.00 |\n",
                        "| **NEGany~necessarily_true**           |  3,238 |    0.82 |    6.89 |  18,199.76 | 86,330,752 |  3,226,213 |  3,786 |    141.48 |    3,096.52 | NEGATED    | necessarily_true           | true           |    348,994.00 | necessarily |     56,694.00 |\n",
                        "| **NEGany~that_noticeable**            |    265 |    0.91 |    6.78 |   1,632.07 | 86,330,752 |  3,226,213 |    279 |     10.43 |      254.57 | NEGATED    | that_noticeable            | noticeable     |     40,372.00 | that        |    250,392.00 |\n",
                        "| **NEGany~necessarily_interested**     |    422 |    0.87 |    6.77 |   2,500.26 | 86,330,752 |  3,226,213 |    463 |     17.30 |      404.70 | NEGATED    | necessarily_interested     | interested     |    364,497.00 | necessarily |     56,694.00 |\n",
                        "| **NEGany~necessarily_related**        |    742 |    0.84 |    6.74 |   4,271.76 | 86,330,752 |  3,226,213 |    842 |     31.47 |      710.53 | NEGATED    | necessarily_related        | related        |    137,661.00 | necessarily |     56,694.00 |\n",
                        "| **NEGany~exactly_fun**                |    225 |    0.94 |    6.67 |   1,423.92 | 86,330,752 |  3,226,213 |    231 |      8.63 |      216.37 | NEGATED    | exactly_fun                | fun            |    224,457.00 | exactly     |     61,599.00 |\n",
                        "| **NEGany~exactly_conducive**          |    208 |    0.93 |    6.56 |   1,313.09 | 86,330,752 |  3,226,213 |    214 |      8.00 |      200.00 | NEGATED    | exactly_conducive          | conducive      |     16,405.00 | exactly     |     61,599.00 |\n",
                        "| **NEGany~yet_right**                  |    202 |    0.92 |    6.50 |   1,254.20 | 86,330,752 |  3,226,213 |    211 |      7.89 |      194.11 | NEGATED    | yet_right                  | right          |    204,572.00 | yet         |    101,707.00 |\n",
                        "| **NEGany~necessarily_illegal**        |    280 |    0.87 |    6.48 |   1,659.90 | 86,330,752 |  3,226,213 |    307 |     11.47 |      268.53 | NEGATED    | necessarily_illegal        | illegal        |     44,028.00 | necessarily |     56,694.00 |\n",
                        "| **NEGany~necessarily_available**      |    213 |    0.89 |    6.36 |   1,280.24 | 86,330,752 |  3,226,213 |    230 |      8.60 |      204.40 | NEGATED    | necessarily_available      | available      |    866,272.00 | necessarily |     56,694.00 |\n",
                        "| **NEGany~necessarily_sure**           |    222 |    0.95 |    5.91 |   1,436.68 | 86,330,752 |  3,226,213 |    224 |      8.37 |      213.63 | NEGATED    | necessarily_sure           | sure           |    844,981.00 | necessarily |     56,694.00 |\n",
                        "| **NEGany~immediately_available**      | 21,297 |    0.66 |    5.77 | 102,962.94 | 86,330,752 |  3,226,213 | 30,725 |  1,148.20 |   20,148.80 | NEGATED    | immediately_available      | available      |    866,272.00 | immediately |    103,177.00 |\n",
                        "| **NEGany~ever_simple**                |    212 |    0.77 |    5.54 |   1,142.04 | 86,330,752 |  3,226,213 |    262 |      9.79 |      202.21 | NEGATED    | ever_simple                | simple         |    427,167.00 | ever        |    124,592.00 |\n",
                        "| **NEGany~ever_easy**                  |    430 |    0.63 |    5.06 |   2,030.58 | 86,330,752 |  3,226,213 |    641 |     23.95 |      406.05 | NEGATED    | ever_easy                  | easy           |    771,307.00 | ever        |    124,592.00 |\n",
                        "| **NEGany~immediately_able**           |    639 |    0.58 |    4.87 |   2,851.84 | 86,330,752 |  3,226,213 |  1,036 |     38.72 |      600.28 | NEGATED    | immediately_able           | able           |    428,268.00 | immediately |    103,177.00 |\n",
                        "| **NEGmir~ever_good**                  |    298 |    0.82 |    4.72 |   1,034.95 |  1,761,853 |    289,770 |    302 |     49.67 |      248.33 | NEGMIR     | ever_good                  | good           |     33,540.00 | ever        |      5,027.00 |\n",
                        "| **NEGany~any_happier**                |    830 |    0.53 |    4.65 |   3,488.76 | 86,330,752 |  3,226,213 |  1,472 |     55.01 |      774.99 | NEGATED    | any_happier                | happier        |     19,501.00 | any         |     94,152.00 |\n",
                        "| **NEGany~immediately_obvious**        |  2,258 |    0.49 |    4.59 |   9,043.23 | 86,330,752 |  3,226,213 |  4,305 |    160.88 |    2,097.12 | NEGATED    | immediately_obvious        | obvious        |    193,498.00 | immediately |    103,177.00 |\n",
                        "| **NEGmir~any_better**                 |    381 |    0.75 |    4.44 |   1,148.18 |  1,761,853 |    289,770 |    416 |     68.42 |      312.58 | NEGMIR     | any_better                 | better         |     14,076.00 | any         |      1,178.00 |\n",
                        "| **NEGmir~that_simple**                |    473 |    0.73 |    4.34 |   1,370.94 |  1,761,853 |    289,770 |    529 |     87.00 |      386.00 | NEGMIR     | that_simple                | simple         |     25,382.00 | that        |      5,488.00 |\n",
                        "| **NEGmir~necessarily_wrong**          |    209 |    0.81 |    4.27 |     708.98 |  1,761,853 |    289,770 |    214 |     35.20 |      173.80 | NEGMIR     | necessarily_wrong          | wrong          |     20,866.00 | necessarily |      1,100.00 |\n",
                        "| **NEGmir~that_easy**                  |    442 |    0.72 |    4.21 |   1,258.15 |  1,761,853 |    289,770 |    500 |     82.23 |      359.77 | NEGMIR     | that_easy                  | easy           |     20,050.00 | that        |      5,488.00 |\n",
                        "| **NEGany~ever_good**                  |    332 |    0.40 |    3.76 |   1,178.00 | 86,330,752 |  3,226,213 |    756 |     28.25 |      303.75 | NEGATED    | ever_good                  | good           |  2,037,285.00 | ever        |    124,592.00 |\n",
                        "| **NEGmir~ever_able**                  |    136 |    0.79 |    3.66 |     437.65 |  1,761,853 |    289,770 |    143 |     23.52 |      112.48 | NEGMIR     | ever_able                  | able           |      6,448.00 | ever        |      5,027.00 |\n",
                        "| **NEGmir~that_great**                 |    282 |    0.67 |    3.52 |     728.46 |  1,761,853 |    289,770 |    340 |     55.92 |      226.08 | NEGMIR     | that_great                 | great          |      5,819.00 | that        |      5,488.00 |\n",
                        "| **NEGany~ever_perfect**               |    217 |    0.37 |    3.48 |     736.05 | 86,330,752 |  3,226,213 |    527 |     19.69 |      197.31 | NEGATED    | ever_perfect               | perfect        |    164,519.00 | ever        |    124,592.00 |\n",
                        "| **NEGany~any_clearer**                |    357 |    0.30 |    3.21 |   1,051.22 | 86,330,752 |  3,226,213 |  1,053 |     39.35 |      317.65 | NEGATED    | any_clearer                | clearer        |     13,369.00 | any         |     94,152.00 |\n",
                        "| **NEGmir~ever_easy**                  |    367 |    0.83 |    3.21 |   1,311.83 |  1,761,853 |    289,770 |    368 |     60.52 |      306.48 | NEGMIR     | ever_easy                  | easy           |     20,050.00 | ever        |      5,027.00 |\n",
                        "| **NEGany~any_simpler**                |    228 |    0.30 |    3.09 |     671.74 | 86,330,752 |  3,226,213 |    672 |     25.11 |      202.89 | NEGATED    | any_simpler                | simpler        |     26,094.00 | any         |     94,152.00 |\n",
                        "| **NEGmir~that_good**                  |    447 |    0.56 |    3.07 |     953.31 |  1,761,853 |    289,770 |    615 |    101.15 |      345.85 | NEGMIR     | that_good                  | good           |     33,540.00 | that        |      5,488.00 |\n",
                        "| **NEGmir~that_big**                   |    113 |    0.70 |    3.06 |     309.58 |  1,761,853 |    289,770 |    131 |     21.55 |       91.45 | NEGMIR     | that_big                   | big            |      7,859.00 | that        |      5,488.00 |\n",
                        "| **NEGany~any_different**              |    910 |    0.24 |    2.98 |   2,270.24 | 86,330,752 |  3,226,213 |  3,313 |    123.81 |      786.19 | NEGATED    | any_different              | different      |    909,864.00 | any         |     94,152.00 |\n",
                        "| **NEGmir~any_worse**                  |     88 |    0.72 |    2.87 |     248.63 |  1,761,853 |    289,770 |    100 |     16.45 |       71.55 | NEGMIR     | any_worse                  | worse          |      8,490.00 | any         |      1,178.00 |\n",
                        "| **NEGmir~ever_wrong**                 |    102 |    0.82 |    2.56 |     349.21 |  1,761,853 |    289,770 |    104 |     17.10 |       84.90 | NEGMIR     | ever_wrong                 | wrong          |     20,866.00 | ever        |      5,027.00 |\n",
                        "| **NEGmir~that_popular**               |     65 |    0.76 |    2.50 |     200.44 |  1,761,853 |    289,770 |     70 |     11.51 |       53.49 | NEGMIR     | that_popular               | popular        |      5,787.00 | that        |      5,488.00 |\n",
                        "| **NEGany~any_worse**                  |  1,693 |    0.16 |    2.47 |   3,165.88 | 86,330,752 |  3,226,213 |  8,487 |    317.16 |    1,375.84 | NEGATED    | any_worse                  | worse          |    214,166.00 | any         |     94,152.00 |\n",
                        "| **COM~longer_available**              | 18,865 |    0.03 |    2.45 |     974.55 | 86,330,752 | 83,102,035 | 18,935 | 18,226.84 |      638.16 | COMPLEMENT | longer_available           | available      |    866,272.00 | longer      |    157,984.00 |\n",
                        "| **NEGmir~that_interested**            |     62 |    0.76 |    2.42 |     190.06 |  1,761,853 |    289,770 |     67 |     11.02 |       50.98 | NEGMIR     | that_interested            | interested     |      9,258.00 | that        |      5,488.00 |\n",
                        "| **NEGmir~any_easier**                 |     61 |    0.75 |    2.42 |     181.98 |  1,761,853 |    289,770 |     67 |     11.02 |       49.98 | NEGMIR     | any_easier                 | easier         |      2,409.00 | any         |      1,178.00 |\n",
                        "| **NEGmir~that_close**                 |     60 |    0.73 |    2.39 |     174.26 |  1,761,853 |    289,770 |     67 |     11.02 |       48.98 | NEGMIR     | that_close                 | close          |     13,962.00 | that        |      5,488.00 |\n",
                        "| **NEGmir~ever_perfect**               |    207 |    0.83 |    2.38 |     735.10 |  1,761,853 |    289,770 |    208 |     34.21 |      172.79 | NEGMIR     | ever_perfect               | perfect        |      3,708.00 | ever        |      5,027.00 |\n",
                        "| **NEGany~any_younger**                |    256 |    0.19 |    2.37 |     544.17 | 86,330,752 |  3,226,213 |  1,121 |     41.89 |      214.11 | NEGATED    | any_younger                | younger        |     29,805.00 | any         |     94,152.00 |\n",
                        "| **NEGmir~that_hard**                  |     57 |    0.74 |    2.31 |     168.31 |  1,761,853 |    289,770 |     63 |     10.36 |       46.64 | NEGMIR     | that_hard                  | hard           |      7,311.00 | that        |      5,488.00 |\n",
                        "| **COM~longer_able**                   | 11,677 |    0.03 |    2.28 |     623.67 | 86,330,752 | 83,102,035 | 11,716 | 11,277.83 |      399.17 | COMPLEMENT | longer_able                | able           |    428,268.00 | longer      |    157,984.00 |\n",
                        "| **NEGany~any_bigger**                 |    357 |    0.17 |    2.27 |     688.06 | 86,330,752 |  3,226,213 |  1,735 |     64.84 |      292.16 | NEGATED    | any_bigger                 | bigger         |    130,470.00 | any         |     94,152.00 |\n",
                        "| **NEGmir~any_closer**                 |     56 |    0.68 |    2.21 |     149.62 |  1,761,853 |    289,770 |     66 |     10.85 |       45.15 | NEGMIR     | any_closer                 | closer         |        986.00 | any         |      1,178.00 |\n",
                        "| **NEGmir~necessarily_true**           |     53 |    0.75 |    2.18 |     159.07 |  1,761,853 |    289,770 |     58 |      9.54 |       43.46 | NEGMIR     | necessarily_true           | true           |      7,402.00 | necessarily |      1,100.00 |\n",
                        "| **NEGmir~that_difficult**             |     52 |    0.75 |    2.15 |     155.64 |  1,761,853 |    289,770 |     57 |      9.37 |       42.63 | NEGMIR     | that_difficult             | difficult      |     16,043.00 | that        |      5,488.00 |\n",
                        "| **NEGmir~necessarily_bad**            |     50 |    0.76 |    2.02 |     153.43 |  1,761,853 |    289,770 |     54 |      8.88 |       41.12 | NEGMIR     | necessarily_bad            | bad            |     10,783.00 | necessarily |      1,100.00 |\n",
                        "| **NEGany~any_harder**                 |    227 |    0.15 |    1.98 |     395.22 | 86,330,752 |  3,226,213 |  1,221 |     45.63 |      181.37 | NEGATED    | any_harder                 | harder         |     99,332.00 | any         |     94,152.00 |\n",
                        "| **NEGmir~ever_free**                  |     69 |    0.81 |    1.97 |     231.61 |  1,761,853 |    289,770 |     71 |     11.68 |       57.32 | NEGMIR     | ever_free                  | free           |      5,043.00 | ever        |      5,027.00 |\n",
                        "| **NEGany~any_easier**                 |  1,607 |    0.11 |    1.95 |   2,164.75 | 86,330,752 |  3,226,213 | 10,860 |    405.84 |    1,201.16 | NEGATED    | any_easier                 | easier         |    237,680.00 | any         |     94,152.00 |\n",
                        "| **NEGmir~immediately_available**      |    162 |    0.43 |    1.94 |     254.47 |  1,761,853 |    289,770 |    274 |     45.06 |      116.94 | NEGMIR     | immediately_available      | available      |     12,636.00 | immediately |      1,193.00 |\n",
                        "| **NEGany~ever_able**                  |    234 |    0.13 |    1.81 |     363.95 | 86,330,752 |  3,226,213 |  1,398 |     52.24 |      181.76 | NEGATED    | ever_able                  | able           |    428,268.00 | ever        |    124,592.00 |\n",
                        "| **NEGany~any_safer**                  |    235 |    0.12 |    1.73 |     346.68 | 86,330,752 |  3,226,213 |  1,471 |     54.97 |      180.03 | NEGATED    | any_safer                  | safer          |     26,779.00 | any         |     94,152.00 |\n",
                        "| **COM~longer_lasting**                |  3,860 |    0.04 |    1.44 |     244.09 | 86,330,752 | 83,102,035 |  3,866 |  3,721.41 |      138.59 | COMPLEMENT | longer_lasting             | lasting        |     24,344.00 | longer      |    157,984.00 |\n",
                        "| **COM~longer_enough**                 |  3,952 |    0.03 |    1.41 |     216.98 | 86,330,752 | 83,102,035 |  3,964 |  3,815.75 |      136.25 | COMPLEMENT | longer_enough              | enough         |    453,790.00 | longer      |    157,984.00 |\n",
                        "| **COM~longer_necessary**              |  5,365 |    0.03 |    1.27 |     220.07 | 86,330,752 | 83,102,035 |  5,399 |  5,197.08 |      167.92 | COMPLEMENT | longer_necessary           | necessary      |    187,396.00 | longer      |    157,984.00 |\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "top_NEGbigram_df_path = TOP_AM_DIR.joinpath(\n",
                "    f'Top{K}_NEG-ADV_top-{bigram_k}-bigrams.{timestamp_today()}.csv')\n",
                "print(top_NEGbigram_df_path)\n",
                "NEG_bigrams_sample.to_csv(top_NEGbigram_df_path)\n",
                "nb_show_table(NEG_bigrams_sample.sort_values('LRC', ascending=False), outpath= top_NEGbigram_df_path.with_suffix('.md'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 103,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "l1\n",
                            "NEGATED       60\n",
                            "NEGMIR        24\n",
                            "COMPLEMENT     5\n",
                            "Name: count, dtype: Int64"
                        ]
                    },
                    "execution_count": 103,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "NEG_bigrams_sample.l1.value_counts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 104,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "|                          |    `f` |   `dP1` |   `LRC` |   `G2` |        `N` |       `f1` |   `f2` |   `exp_f` |   `unexp_f` | `l1`       | `l2`             | `adj`     |   `adj_total` | `adv`   |   `adv_total` |\n",
                        "|:-------------------------|-------:|--------:|--------:|-------:|-----------:|-----------:|-------:|----------:|------------:|:-----------|:-----------------|:----------|--------------:|:--------|--------------:|\n",
                        "| **COM~longer_available** | 18,865 |    0.03 |    2.45 | 974.55 | 86,330,752 | 83,102,035 | 18,935 | 18,226.84 |      638.16 | COMPLEMENT | longer_available | available |    866,272.00 | longer  |    157,984.00 |\n",
                        "| **COM~longer_able**      | 11,677 |    0.03 |    2.28 | 623.67 | 86,330,752 | 83,102,035 | 11,716 | 11,277.83 |      399.17 | COMPLEMENT | longer_able      | able      |    428,268.00 | longer  |    157,984.00 |\n",
                        "| **COM~longer_lasting**   |  3,860 |    0.04 |    1.44 | 244.09 | 86,330,752 | 83,102,035 |  3,866 |  3,721.41 |      138.59 | COMPLEMENT | longer_lasting   | lasting   |     24,344.00 | longer  |    157,984.00 |\n",
                        "| **COM~longer_enough**    |  3,952 |    0.03 |    1.41 | 216.98 | 86,330,752 | 83,102,035 |  3,964 |  3,815.75 |      136.25 | COMPLEMENT | longer_enough    | enough    |    453,790.00 | longer  |    157,984.00 |\n",
                        "| **COM~longer_necessary** |  5,365 |    0.03 |    1.27 | 220.07 | 86,330,752 | 83,102,035 |  5,399 |  5,197.08 |      167.92 | COMPLEMENT | longer_necessary | necessary |    187,396.00 | longer  |    157,984.00 |\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "nb_show_table(NEG_bigrams_sample.filter(like='O', axis=0))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "dev-sanpi",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
