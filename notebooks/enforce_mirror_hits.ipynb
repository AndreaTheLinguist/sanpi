{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arh234/anaconda3/envs/dev-sanpi/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'POSmirror': PosixPath('/share/compling/data/sanpi/4_post-processed/POSmirror/trigger-bigrams_frq-thrMIN-7.35f.pkl.gz'),\n",
       " 'NEGmirror': PosixPath('/share/compling/data/sanpi/4_post-processed/NEGmirror/trigger-bigrams_frq-thrMIN-7.35f.pkl.gz')}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from source.utils import POST_PROC_DIR, print_iter\n",
    "from source.utils.sample import sample_pickle\n",
    "\n",
    "HIT_EX_COLS = ['WITH::^.[il].*lower', 'WITH::text', 'token_str']\n",
    "# sanpi/4_post-processed/POSmirror/trigger-bigrams_frq-thrMIN-7.35f.pkl.gz\n",
    "pkl_name = 'trigger-bigrams_frq-thrMIN-7.35f.pkl.gz'\n",
    "path_dict = {p: POST_PROC_DIR / p / pkl_name for  p in ('POSmirror','NEGmirror')}\n",
    "path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmir = pd.read_pickle(path_dict['NEGmirror'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmir = pd.read_pickle(path_dict['POSmirror'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_cat(df):\n",
    "    cat_cols = df.filter(regex=r'form|bigram|lemma|deprel|head').columns\n",
    "    df[cat_cols] = df[cat_cols].astype('category')\n",
    "    # df.info()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmir = str_to_cat(pmir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmir = str_to_cat(nmir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_col_widths(df):\n",
    "    cols = df.copy().reset_index().columns\n",
    "    width_dict = (\n",
    "        {c: None for c in cols}\n",
    "        | {c: 22 for c in cols[cols.str.contains('_id')]}\n",
    "        | {c: 45 for c in cols[cols.str.contains('text')]}\n",
    "        | {c: 30 for c in cols[cols.str.contains('forms')]}\n",
    "        | {c: 60 for c in cols[cols.str.contains('_str')]})\n",
    "    return list(width_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "POSmirror columns:\n",
      "▸ bigram_id\n",
      "▸ token_str\n",
      "▸ pattern\n",
      "▸ category\n",
      "▸ adv_form\n",
      "▸ adj_form\n",
      "▸ text_window\n",
      "▸ mir_deprel\n",
      "▸ mir_lemma\n",
      "▸ adv_lemma\n",
      "▸ adj_lemma\n",
      "▸ mir_form\n",
      "▸ mir_index\n",
      "▸ adv_index\n",
      "▸ adj_index\n",
      "▸ mir_form_lower\n",
      "▸ adv_form_lower\n",
      "▸ adj_form_lower\n",
      "▸ bigram_lower\n",
      "▸ all_forms_lower\n",
      "▸ prev_form_lower\n",
      "\n",
      "NEGmirror columns:\n",
      "▸ bigram_id\n",
      "▸ token_str\n",
      "▸ pattern\n",
      "▸ category\n",
      "▸ neg_form\n",
      "▸ adv_form\n",
      "▸ adj_form\n",
      "▸ text_window\n",
      "▸ neg_deprel\n",
      "▸ neg_lemma\n",
      "▸ adv_lemma\n",
      "▸ adj_lemma\n",
      "▸ neg_index\n",
      "▸ adv_index\n",
      "▸ adj_index\n",
      "▸ neg_form_lower\n",
      "▸ adv_form_lower\n",
      "▸ adj_form_lower\n",
      "▸ bigram_lower\n",
      "▸ all_forms_lower\n",
      "▸ prev_form_lower\n"
     ]
    }
   ],
   "source": [
    "print_iter(header = 'POSmirror columns:', iter_obj= pmir.columns.to_list())\n",
    "print_iter(header = 'NEGmirror columns:', iter_obj= nmir.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample(df: pd.DataFrame,\n",
    "                format: str = 'grid',\n",
    "                limit_cols: bool = True):\n",
    "    if limit_cols and format != 'pipe':\n",
    "        col_widths_list = set_col_widths(df)\n",
    "    else:\n",
    "        col_widths_list = [None] * len(df.columns)\n",
    "    print(df.to_markdown(\n",
    "        floatfmt=',.0f', intfmt=',',\n",
    "        maxcolwidths=col_widths_list, \n",
    "        tablefmt=format\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| pattern      |     count |\n",
      "|:-------------|----------:|\n",
      "| pos-mirror-R | 1,364,620 |\n",
      "| pos-mirror-L |   373,499 |\n"
     ]
    }
   ],
   "source": [
    "show_sample(pmir.pattern.value_counts().to_frame(), limit_cols=False, format='pipe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| pattern      |   count |\n",
      "|:-------------|--------:|\n",
      "| neg-mirror-R | 216,900 |\n",
      "| neg-mirror-L |  77,064 |\n"
     ]
    }
   ],
   "source": [
    "show_sample(nmir.pattern.value_counts().to_frame(), limit_cols=False, format='pipe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGNOT=r\" (n[o']t) \"\n",
    "def embolden(series,\n",
    "            bold_regex=None):\n",
    "    bold_regex = re.compile(bold_regex) if bold_regex else REGNOT\n",
    "    return series.apply(\n",
    "        lambda x: bold_regex.sub(r' __`\\1`__ ', x))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Sentences\n",
    "\n",
    "The following examples are all from the `POSmirror` data set which should not include any negative triggers. \n",
    "I believe the issue may be due to unexpected parses or cases where the negative trigger dependency is indirect or scopes over the identified positive trigger. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- *filtering rows...*\n",
      "  - regex parsing = True\n",
      "  - Filter expression `token_str==  (n[o']t)  .* exactly ` matched zero rows. Filter not applied.\n",
      "  - ✓ Applied filter: `adv_form_lower==^exactly$`\n",
      "  - ✓ Applied filter: `pattern==.*L$`\n",
      "\n",
      "### 6 random rows matching filter(s) from `input frame`\n",
      "\n",
      "| hit_id                                   | mir_form_lower   | bigram_lower      | text_window                                                             | token_str                                                                                                                                     |\n",
      "|:-----------------------------------------|:-----------------|:------------------|:------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| nyt_eng_19990108_0419_27:5-8-9           | someone          | exactly_simpatico | and he is not someone who was __`exactly`__ simpatico with the Gramm of | and he is not someone who was __`exactly`__ simpatico with the Gramm of old .                                                                 |\n",
      "| apw_eng_20070219_0931_10:22-24-25        | something        | exactly_alien     | of the dictum -- something not __`exactly`__ alien to him .             | Bellamy , who has a history of losing his temper , looks to be the first casualty of the dictum -- something not __`exactly`__ alien to him . |\n",
      "| pcc_eng_08_092.9577_x1488616_29:17-18-19 | something        | exactly_right     | I did n't have something __`exactly`__ right .                          | \" [ My clients ] needed a piece of art , and I did n't have something __`exactly`__ right .                                                   |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_715/2108415995.py:12: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  problems.loc[problems.token_str.str.contains(f'{REGNOT}.*{adv}')].assign(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- *filtering rows...*\n",
      "  - regex parsing = True\n",
      "  - Filter expression `token_str==  (n[o']t)  .* exactly ` matched zero rows. Filter not applied.\n",
      "  - ✓ Applied filter: `adv_form_lower==^exactly$`\n",
      "  - ✓ Applied filter: `pattern==.*R$`\n",
      "\n",
      "### 6 random rows matching filter(s) from `input frame`\n",
      "\n",
      "| hit_id                                   | mir_form_lower   | bigram_lower   | text_window                                               | token_str                                                                  |\n",
      "|:-----------------------------------------|:-----------------|:---------------|:----------------------------------------------------------|:---------------------------------------------------------------------------|\n",
      "| pcc_eng_23_043.3902_x0684965_07:10-14-15 | or               | exactly_right  | this is contradictory , or if it 's __`exactly`__ right . | I do n't know if this is contradictory , or if it 's __`exactly`__ right . |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_715/2108415995.py:12: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  problems.loc[problems.token_str.str.contains(f'{REGNOT}.*{adv}')].assign(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- *filtering rows...*\n",
      "  - regex parsing = True\n",
      "  - Filter expression `token_str==  (n[o']t)  .* ever ` matched zero rows. Filter not applied.\n",
      "  - ✓ Applied filter: `adv_form_lower==^ever$`\n",
      "  - ✓ Applied filter: `pattern==.*L$`\n",
      "\n",
      "### 6 random rows matching filter(s) from `input frame`\n",
      "\n",
      "| hit_id                                | mir_form_lower   | bigram_lower   | text_window                                                     | token_str                                                                                                                                                                                                                                         |\n",
      "|:--------------------------------------|:-----------------|:---------------|:----------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| pcc_eng_10_005.9191_x0079566_10:6-7-8 | something        | ever_related   | anyone hates AARP and something __`ever`__ related to it , then | If anyone hates AARP and something __`ever`__ related to it , then it 's good to hear that they wo n't __`ever`__ ever e-book an OAT journey , as a result of I would take one once more and I 'd hate to journey with somebody toting a grudge . |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_715/2108415995.py:12: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  problems.loc[problems.token_str.str.contains(f'{REGNOT}.*{adv}')].assign(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- *filtering rows...*\n",
      "  - regex parsing = True\n",
      "  - Filter expression `token_str==  (n[o']t)  .* ever ` matched zero rows. Filter not applied.\n",
      "  - ✓ Applied filter: `adv_form_lower==^ever$`\n",
      "  - ✓ Applied filter: `pattern==.*R$`\n",
      "\n",
      "### 6 random rows matching filter(s) from `input frame`\n",
      "\n",
      "| hit_id                                   | mir_form_lower   | bigram_lower   | text_window                                                          | token_str                                                                                                                                                                                             |\n",
      "|:-----------------------------------------|:-----------------|:---------------|:---------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| pcc_eng_05_066.5771_x1060893_86:31-33-34 | always           | ever_exclusive | for these films are always and __`ever`__ exclusive of one another . | The real \" elitism , \" it seems to me , is not nominating the Coens or dissing Sandra Bullock , but insisting that the audiences for these films are always and __`ever`__ exclusive of one another . |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_715/2108415995.py:12: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  problems.loc[problems.token_str.str.contains(f'{REGNOT}.*{adv}')].assign(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- *filtering rows...*\n",
      "  - regex parsing = True\n",
      "  - Filter expression `token_str==  (n[o']t)  .* necessarily ` matched zero rows. Filter not applied.\n",
      "  - ✓ Applied filter: `adv_form_lower==^necessarily$`\n",
      "  - ✓ Applied filter: `pattern==.*L$`\n",
      "\n",
      "### 6 random rows matching filter(s) from `input frame`\n",
      "\n",
      "| hit_id                                   | mir_form_lower   | bigram_lower          | text_window                                                             | token_str                                                                                                                                                                                                                                                                                                                                                         |\n",
      "|:-----------------------------------------|:-----------------|:----------------------|:------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| pcc_eng_24_001.5370_x0008698_18:5-6-7    | something        | necessarily_expensive | This need not be something __`necessarily`__ expensive .                | This need not be something __`necessarily`__ expensive .                                                                                                                                                                                                                                                                                                          |\n",
      "| pcc_eng_17_008.1276_x0115288_17:10-11-12 | something        | necessarily_vivid     | , it is not something __`necessarily`__ vivid and precise , but         | It is not a fantasy , it is not something __`necessarily`__ vivid and precise , but it functions as an anxious driver from within that forces attention and focus , that clamps onto your spinal column when you hear your child crying out in the night , makes you spin your head on a swivel when you hear an anonymous cry in the street ; is that my child ? |\n",
      "| pcc_eng_17_068.9505_x1097924_25:7-8-9    | something        | necessarily_wrong     | not saying there is something __`necessarily`__ wrong with well - liked | I am not saying there is something __`necessarily`__ wrong with well - liked taste , but I regard individuals like Bowie , and others who on their own produced a personal fashion , and artistic vision .                                                                                                                                                        |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_715/2108415995.py:12: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  problems.loc[problems.token_str.str.contains(f'{REGNOT}.*{adv}')].assign(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- *filtering rows...*\n",
      "  - regex parsing = True\n",
      "  - Filter expression `token_str==  (n[o']t)  .* necessarily ` matched zero rows. Filter not applied.\n",
      "  - ✓ Applied filter: `adv_form_lower==^necessarily$`\n",
      "  - ✓ Applied filter: `pattern==.*R$`\n",
      "\n",
      "### 6 random rows matching filter(s) from `input frame`\n",
      "\n",
      "| hit_id                                   | mir_form_lower   | bigram_lower         | text_window                                                         | token_str                                                                                                                                                                                                                                                                      |\n",
      "|:-----------------------------------------|:-----------------|:---------------------|:--------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| pcc_eng_26_003.8152_x0045348_28:33-34-35 | or               | necessarily_easy     | is n't obvious , or __`necessarily`__ easy to set up .              | It is possible to send SMS messages with Simon now , using the Email notifier and sending to your phone number at your wireless carrier , but that is n't obvious , or __`necessarily`__ easy to set up .                                                                      |\n",
      "| pcc_eng_17_106.3664_x1703438_25:7-8-9    | or               | necessarily_equal    | it was not better or __`necessarily`__ equal , but the differences  | No , it was not better or __`necessarily`__ equal , but the differences were negligible to all but the most experienced theatregoers ; if I had not known the production was non-Equity , I would not have been able to tell with any certainty , and I see a lot of theatre . |\n",
      "| pcc_eng_29_018.1427_x0276600_14:19-21-22 | or               | necessarily_pleasant | in fact particularly danceable or even __`necessarily`__ pleasant . | The mass suspension of disbelief , the readiness to like something that was not in fact particularly danceable or even __`necessarily`__ pleasant .                                                                                                                            |\n",
      "| pcc_eng_07_079.5738_x1269670_02:09-10-11 | or               | necessarily_safe     | it 's a wise or __`necessarily`__ safe thing to dress that          | I do n't think it 's a wise or __`necessarily`__ safe thing to dress that way and do what verifiedcorn said in his comment .                                                                                                                                                   |\n",
      "| pcc_eng_07_084.6026_x1350878_12:09-10-11 | or               | necessarily_true     | think it 's fair or __`necessarily`__ true to many I know           | I do n't even think it 's fair or __`necessarily`__ true to many I know to use the phrase \" right- wing \" to label these ideas , as it 's more like \" nut-wing \" to me and at any extreme edge along a political compass .                                                     |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_715/2108415995.py:12: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  problems.loc[problems.token_str.str.contains(f'{REGNOT}.*{adv}')].assign(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- *filtering rows...*\n",
      "  - regex parsing = True\n",
      "  - Filter expression `token_str==  (n[o']t)  .* yet ` matched zero rows. Filter not applied.\n",
      "  - ✓ Applied filter: `adv_form_lower==^yet$`\n",
      "  - ✓ Applied filter: `pattern==.*L$`\n",
      "\n",
      "### 6 random rows matching filter(s) from `input frame`\n",
      "\n",
      "| hit_id                                   | mir_form_lower   | bigram_lower   | text_window                                                              | token_str                                                                                      |\n",
      "|:-----------------------------------------|:-----------------|:---------------|:-------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------|\n",
      "| pcc_eng_03_097.9630_x1569987_08:07-10-11 | something        | yet_unknown    | not even begin until something ( still __`yet`__ unknown to us ) happens | Evolution can not even begin until something ( still __`yet`__ unknown to us ) happens first . |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_715/2108415995.py:12: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  problems.loc[problems.token_str.str.contains(f'{REGNOT}.*{adv}')].assign(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- *filtering rows...*\n",
      "  - regex parsing = True\n",
      "  - Filter expression `token_str==  (n[o']t)  .* yet ` matched zero rows. Filter not applied.\n",
      "  - ✓ Applied filter: `adv_form_lower==^yet$`\n",
      "  - ✓ Applied filter: `pattern==.*R$`\n",
      "\n",
      "### 6 random rows matching filter(s) from `input frame`\n",
      "\n",
      "| hit_id                                   | mir_form_lower   | bigram_lower     | text_window                                                           | token_str                                                                                                                                                                                      |\n",
      "|:-----------------------------------------|:-----------------|:-----------------|:----------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| pcc_eng_14_089.6457_x1432934_22:21-23-24 | or               | yet_undiscovered | authors too intimidated , or as __`yet`__ undiscovered , who have not | Seeing those rows makes me curious about what stories have not __`yet`__ been told , about authors too intimidated , or as __`yet`__ undiscovered , who have not written their greatest work . |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_715/2108415995.py:12: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  problems.loc[problems.token_str.str.contains(f'{REGNOT}.*{adv}')].assign(\n"
     ]
    }
   ],
   "source": [
    "for adv in ['exactly', 'ever', 'necessarily', 'yet']:\n",
    "    for pat_suff in ['L', 'R']:\n",
    "        problems = sample_pickle(\n",
    "            data=pmir, sample_size=6, regex=True, print_sample=False,\n",
    "            filters=[f'token_str== {REGNOT} .* {adv} ',\n",
    "                    f'adv_form_lower==^{adv}$', \n",
    "                    f'pattern==.*{pat_suff}$'],\n",
    "            columns=['mir_form_lower', 'bigram_lower', 'text_window', 'token_str'],\n",
    "            sort_by='all_forms_lower')\n",
    "\n",
    "        show_sample(\n",
    "            problems.loc[problems.token_str.str.contains(f'{REGNOT}.*{adv}')].assign(\n",
    "                token_str=embolden(problems.token_str, f' ({REGNOT}|{adv}) '),\n",
    "                text_window=embolden(problems.text_window, f' ({REGNOT}|{adv}) ')\n",
    "            ),\n",
    "            format='pipe', limit_cols=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This could be dealt with by modifying the patterns (i.e. the `WITHOUT` clauses specifically) and rerunning everything, but\n",
    "  1. There's no telling how long that would take \n",
    "  2. verifying its accuracy is difficult\n",
    "  3. even with 100% accurate patterns for *correct* parses, there is no way to prevent or really even predict all possible *mis*parses\n",
    "- So there is a better way: \n",
    "  \n",
    "  The preponderance of positive data provides a large margin for additional data exclusions without unbalancing the samples---in fact, \n",
    "  it actually brings `[POSMIR,f1]` _closer_ to the negative sample size, `[NEGMIR, f1]`.\n",
    "\n",
    "  Therefore, it is possible to simply drop anything with a likely negation preceding the bigram, \n",
    "  regardless of the polarity environment the particular syntactic configuration creates, and call it a day.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmir['adv_index'] = pd.to_numeric(pmir.index.to_series().str.split(':').str.get(-1).apply(lambda i: re.search(r'-(\\d+)-', i).group().strip('-')), downcast='unsigned')\n",
    "pmir['preceding_text'] = pmir.apply(lambda x: ' '.join(x.token_str.split()[:x.adv_index - 1]), axis='columns').astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----------------------------------------------+----------------+-------------------------------------------------------------+\n",
      "| hit_id                 | preceding_text                                | bigram_lower   | token_str                                                   |\n",
      "+========================+===============================================+================+=============================================================+\n",
      "| pcc_eng_24_020.1972_x0 | NG : Borrisokane wanted to release a new EP , | more_special   | NG : Borrisokane wanted to release a new EP , but rather    |\n",
      "| 310014_16:27-28-29     | but rather than just record something and put |                | than just record something and put it out , they wanted to  |\n",
      "|                        | it out , they wanted to make it something     |                | make it something more special and more involved with the   |\n",
      "|                        |                                               |                | Austin music community .                                    |\n",
      "+------------------------+-----------------------------------------------+----------------+-------------------------------------------------------------+\n",
      "| pcc_eng_09_092.1185_x1 | In fact , some of the album covers are        | quite_hideous  | In fact , some of the album covers are quite hideous .      |\n",
      "| 474215_06:04-10-11     |                                               |                |                                                             |\n",
      "+------------------------+-----------------------------------------------+----------------+-------------------------------------------------------------+\n",
      "| pcc_eng_00_081.5729_x1 | Lieryn Barnett sometimes is                   | so_depressed   | Lieryn Barnett sometimes is so depressed , all she wants to |\n",
      "| 302510_50:3-5-6        |                                               |                | do is sleep , she said .                                    |\n",
      "+------------------------+-----------------------------------------------+----------------+-------------------------------------------------------------+\n",
      "| pcc_eng_03_059.8105_x0 | Anyone , anywhere , anytime , no move is too  | too_small      | Anyone , anywhere , anytime , no move is too big or too     |\n",
      "| 952398_081:12-13-14    | big or                                        |                | small .                                                     |\n",
      "+------------------------+-----------------------------------------------+----------------+-------------------------------------------------------------+\n",
      "| pcc_eng_27_062.3314_x0 | Among these \" potential fallouts \" are        | unusually_high | Among these \" potential fallouts \" are additional stress on |\n",
      "| 991364_11:15-16-17     | additional stress on the dog ; suppressed or  |                | the dog ; suppressed or unusually high levels of aggression |\n",
      "|                        |                                               |                | ; and stunted emotional growth or complete emotional shut-  |\n",
      "|                        |                                               |                | down .                                                      |\n",
      "+------------------------+-----------------------------------------------+----------------+-------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "show_sample(pmir[['preceding_text', 'bigram_lower', 'token_str']].sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| hit_id                                   | preceding_text                                                                                                                                                           | bigram_lower    | token_str                                                                                                                                                                                                                                                                                                                                                   |\n",
      "|:-----------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| pcc_eng_11_065.5198_x1044154_33:27-28-29 | It 's as if the Beckers decided they were happy enough with their Wickenden Street , crepe-stuffed lifestyle until Saturday night reared its head and demanded something | more_indigenous | It 's as if the Beckers decided they were happy enough with their Wickenden Street , crepe-stuffed lifestyle until Saturday night reared its head and demanded something more indigenous and perhaps even a little dirtier .                                                                                                                                |\n",
      "| pcc_eng_06_069.4303_x1107189_83:11-12-13 | The data taken for granted in other countries are unavailable or                                                                                                         | simply_unknown  | The data taken for granted in other countries are unavailable or simply unknown here .                                                                                                                                                                                                                                                                      |\n",
      "| pcc_eng_07_008.4428_x0120530_06:09-14-15 | Thankfully , there ARE answers to burnout and some of them are really                                                                                                    | quite_simple    | Thankfully , there ARE answers to burnout and some of them are really quite simple .                                                                                                                                                                                                                                                                        |\n",
      "| pcc_eng_09_060.9402_x0969792_19:21-26-27 | There are some powerful poems about the civil war , during which he worked as a nurse , but then some of it is really                                                    | quite_small     | There are some powerful poems about the civil war , during which he worked as a nurse , but then some of it is really quite small too .                                                                                                                                                                                                                     |\n",
      "| pcc_eng_06_036.9081_x0580700_04:13-14-15 | Safe Routes to School 's influence on a community can vary from something                                                                                                | as_discrete     | Safe Routes to School 's influence on a community can vary from something as discrete as funding the construction of a missing block of sidewalk , to something as complex as developing a wide- ranging walk to school program in schools across an entire school district , with volunteer walking teams , encouragement events , incentives , and more . |\n"
     ]
    }
   ],
   "source": [
    "show_sample(pmir[['preceding_text', 'bigram_lower', 'token_str']].sample(5), format='pipe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_715/3396796712.py:1: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  pmir['after_neg'] = pmir.preceding_text.str.lower().str.contains(r\"\\b(no|n[o']t|no(body| one|thing|where)|(rare|scarce|bare|hard)ly|seldom|without|never)\\b\", regex=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----------------------------------------------+-----------------+--------------------------------------------------------------+\n",
      "| hit_id                 | preceding_text                                | bigram_lower    | token_str                                                    |\n",
      "+========================+===============================================+=================+==============================================================+\n",
      "| pcc_eng_19_018.1666_x0 | Naturalness , to physicists , means no ( or   | very_little     | Naturalness , to physicists , means no ( or very little )    |\n",
      "| 276969_22:09-10-11     |                                               |                 | fine tuning .                                                |\n",
      "+------------------------+-----------------------------------------------+-----------------+--------------------------------------------------------------+\n",
      "| pcc_eng_14_075.7211_x1 | I still love the genre , but I ca n't read or | very_domestic   | I still love the genre , but I ca n't read or watch anything |\n",
      "| 208178_056:20-21-22    | watch anything that involves kids or even     |                 | that involves kids or even something very domestic ( think   |\n",
      "|                        | something                                     |                 | Funny Games ) .                                              |\n",
      "+------------------------+-----------------------------------------------+-----------------+--------------------------------------------------------------+\n",
      "| pcc_eng_23_064.1540_x1 | I 'd never had my Bars done before , I 've    | very_new        | I 'd never had my Bars done before , I 've just worked with  |\n",
      "| 020375_6:29-30-31      | just worked with generating questions ,       |                 | generating questions , energy balls , statements and         |\n",
      "|                        | energy balls , statements and clearing energy |                 | clearing energy , so it was all very new to me .             |\n",
      "|                        | , so it was all                               |                 |                                                              |\n",
      "+------------------------+-----------------------------------------------+-----------------+--------------------------------------------------------------+\n",
      "| pcc_eng_28_088.4912_x1 | Although each family will tackle this subject | even_guilty     | Although each family will tackle this subject in the way     |\n",
      "| 415491_29:49-50-51     | in the way that they feel will work best for  |                 | that they feel will work best for them , parents may still   |\n",
      "|                        | them , parents may still need to help their   |                 | need to help their other children to express their feelings  |\n",
      "|                        | other children to express their feelings in   |                 | in the knowledge that it is n't wrong to feel embarrassed ,  |\n",
      "|                        | the knowledge that it is n't wrong to feel    |                 | awkward , resentful , or even guilty towards their sister /  |\n",
      "|                        | embarrassed , awkward , resentful , or        |                 | brother .                                                    |\n",
      "+------------------------+-----------------------------------------------+-----------------+--------------------------------------------------------------+\n",
      "| pcc_eng_11_035.0781_x0 | Not sure exactly what you 're looking for ,   | not_sure        | Not sure exactly what you 're looking for , or not sure      |\n",
      "| 551592_25:10-11-12     | or                                            |                 | where to start ?                                             |\n",
      "+------------------------+-----------------------------------------------+-----------------+--------------------------------------------------------------+\n",
      "| pcc_eng_26_059.4311_x0 | Many stellar ideas may not make it to market  | more_successful | Many stellar ideas may not make it to market - the clinical  |\n",
      "| 944790_13:26-28-29     | - the clinical trial process has far more     |                 | trial process has far more failures than successes , and     |\n",
      "|                        | failures than successes , and low-tech        |                 | low-tech solutions may sometimes be more successful than     |\n",
      "|                        | solutions may sometimes be                    |                 | intellectually satisfying high - tech approaches .           |\n",
      "+------------------------+-----------------------------------------------+-----------------+--------------------------------------------------------------+\n",
      "| pcc_eng_25_085.0830_x1 | \" It was n't until after we had the pilings   | n't_right       | \" It was n't until after we had the pilings and foundation   |\n",
      "| 360803_28:19-21-22     | and foundation in place that we realized that |                 | in place that we realized that something was n't right , \"   |\n",
      "|                        | something was                                 |                 | said Aaron Payment of the Sault Ste.                         |\n",
      "+------------------------+-----------------------------------------------+-----------------+--------------------------------------------------------------+\n",
      "| pcc_eng_00_007.6970_x0 | Working 9 - 5 is our way to make a living ,   | that_lucky      | Working 9 - 5 is our way to make a living , no matter how    |\n",
      "| 108142_02:34-38-39     | no matter how much we try to fight it sitting |                 | much we try to fight it sitting and watching Netflix all day |\n",
      "|                        | and watching Netflix all day is not our job , |                 | is not our job , not all of us are that lucky !              |\n",
      "|                        | not all of us are                             |                 |                                                              |\n",
      "+------------------------+-----------------------------------------------+-----------------+--------------------------------------------------------------+\n",
      "| pcc_eng_14_080.5913_x1 | Here 's a new Kickstarter form a team nobody  | pretty_excited  | Here 's a new Kickstarter form a team nobody seems to have   |\n",
      "| 286992_02:19-20-21     | seems to have heard of , but we 're all       |                 | heard of , but we 're all pretty excited anyway because Son  |\n",
      "|                        |                                               |                 | of Nor looks awesome .                                       |\n",
      "+------------------------+-----------------------------------------------+-----------------+--------------------------------------------------------------+\n",
      "| pcc_eng_24_001.4966_x0 | The first stories mentioned pictures , but no | even_naked      | The first stories mentioned pictures , but no one seemed to  |\n",
      "| 008008_049:19-24-25    | one seemed to know how many Father Ron had    |                 | know how many Father Ron had taken or whether the children   |\n",
      "|                        | taken or whether the children were            |                 | were even naked .                                            |\n",
      "+------------------------+-----------------------------------------------+-----------------+--------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "pmir['after_neg'] = pmir.preceding_text.str.lower().str.contains(r\"\\b(no|n[o']t|no(body| one|thing|where)|(rare|scarce|bare|hard)ly|seldom|without|never)\\b\", regex=True)\n",
    "show_sample(pmir.loc[pmir.after_neg, ['preceding_text', 'bigram_lower', 'token_str']].sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| hit_id                                    | preceding_text                                                                                                                                                                                          | bigram_lower    | token_str                                                                                                                                                                                                                                                     |\n",
      "|:------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| pcc_eng_07_052.3021_x0829311_35:24-26-27  | Their designs - furniture particularly - may often have been popular and occasionally ( though not all that often ) cheap ; but some were                                                               | very_expensive  | Their designs - furniture particularly - may often have been popular and occasionally ( though not all that often ) cheap ; but some were very expensive indeed , and were certainly intended to last .                                                       |\n",
      "| pcc_eng_13_033.0963_x0518938_11:18-29-30  | As such , I do n't know if it 's the removal of the brand from WWII or whether the drama and execution of the game is just                                                                              | that_good       | As such , I do n't know if it 's the removal of the brand from WWII or whether the drama and execution of the game is just that good , but ...                                                                                                                |\n",
      "| pcc_eng_00_047.5699_x0752643_21:15-16-17  | \" I __`never`__ sensed that he thought he was more important , smarter , or                                                                                                                             | more_powerful   | \" I never sensed that he thought he was more important , smarter , or more powerful than me , although he was all those things , \" Martin Hollis , who has worked on many Nintendo titles , said .                                                            |\n",
      "| pcc_eng_07_079.1272_x1262350_05:26-27-28  | For the Palestinians , this means submitting extensive plans for JWC approval - and usually not receiving it - every time they want to do something                                                     | as_simple       | For the Palestinians , this means submitting extensive plans for JWC approval - and usually not receiving it - every time they want to do something as simple as rehabilitating a village spring , according to Attili .                                      |\n",
      "| pcc_eng_22_091.9347_x1469504_105:26-28-29 | There are , of course , __`no`__ actual strategic advantages to watching the opposing team practice - both teams know each other inside out , both are                                                  | fully_aware     | There are , of course , no actual strategic advantages to watching the opposing team practice - both teams know each other inside out , both are fully aware of the other 's game plan and their key strategies .                                             |\n",
      "| pcc_eng_11_078.3098_x1251547_10:36-42-43  | Many in the activist community see MI Legalize as a last ditch way to salvage the progress made last season by the campaign in the event the MPP does not do a campaign in MI or if the MPP language is | too_unpalatable | Many in the activist community see MI Legalize as a last ditch way to salvage the progress made last season by the campaign in the event the MPP does not do a campaign in MI or if the MPP language is too unpalatable for those in the activist community . |\n"
     ]
    }
   ],
   "source": [
    "some_neg_ex = pmir.loc[pmir.after_neg, ['preceding_text', 'bigram_lower', 'token_str']].sample(6)\n",
    "show_sample(some_neg_ex.assign(\n",
    "    preceding_text=embolden(some_neg_ex.preceding_text, \n",
    "                            f' ({REGNOT}|nobody|nothing|never|none|no) ')\n",
    "    ), format='pipe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* $1,487,458$ tokens in `POSmirror` hits not preceded by negation\n",
      "  > - I.e. what would remain if _all_ potential contaminants were excluded\n",
      "  > - _250,661_ potential exclusions\n",
      "* $293,964$ tokens in `NEGmirror` hits\n",
      "* Remaining Sample Size Discrepancy: $1,193,494$\n"
     ]
    }
   ],
   "source": [
    "print(f'* ${pmir.after_neg.value_counts()[False]:,}$ tokens in `POSmirror` hits not preceded by negation')\n",
    "print('  > - I.e. what would remain if _all_ potential contaminants were excluded')\n",
    "print(f'  > - _{pmir.after_neg.value_counts()[True]:,}_ potential exclusions')\n",
    "print(f'* ${len(nmir):,}$ tokens in `NEGmirror` hits')\n",
    "print(f'* Remaining Sample Size Discrepancy: ${pmir.after_neg.value_counts()[False] - len(nmir):,}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Negation Removals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### For 868+ frequency filtered ad* forms \n",
    "  \n",
    "  _Without considering any upper case_\n",
    "  * ~~__1,457,913__ tokens in `POSmirror` hits not preceded by negation~~\n",
    "      * ~~I.e. what would remain if _all_ potential contaminants were excluded~~\n",
    "      * ~~_217,588_ potential exclusions~~\n",
    "  ---\n",
    "  _Without considering fully upper case triggers_\n",
    "  * ~~__1,460,126__ tokens in `POSmirror` hits not preceded by negation~~\n",
    "  * ~~I.e. what would remain if _all_ potential contaminants were excluded~~\n",
    "  * ~~_215,375_ potential exclusions~~\n",
    "  ---\n",
    "  _Normalized for case first, but not catching negation at very end of preceding text (no whitespace following)_\n",
    "  * ~~**1,459,568** tokens in `POSmirror` hits not preceded by negation~~\n",
    "  > - ~~I.e. what would remain if _all_ potential contaminants were excluded~~\n",
    "  > - ~~_215,933_ potential exclusions~~\n",
    "  * ~~Updated difference in hit subtotals: **1,174,133**~~\n",
    "  * $285,435$ tokens in `NEGmirror` hits\n",
    "  ---\n",
    "  **_Fixed to catch even `preceding_text` final negative triggers_**\n",
    "  * ~~**1,455,547** tokens in `POSmirror` hits not preceded by negation~~\n",
    "  > - ~~I.e. what would remain if _all_ potential contaminants were excluded~~\n",
    "  > - ~~_219,954_ potential exclusions~~\n",
    "  * $285,435$ tokens in `NEGmirror` hits\n",
    "  * ~~Remaining Sample Size Discrepancy: **1,170,112**~~\n",
    "  ---\n",
    "  **Strengthened even furthre to catch negative adverbs and \"without\" and triggers at the _beginning_ of the `preceding_text`**\n",
    "  * $1,434,420$ tokens in `POSmirror` hits not preceded by negation\n",
    "  > - I.e. what would remain if _all_ potential contaminants were excluded\n",
    "  > - _241,081_ potential exclusions\n",
    "  * $285,435$ tokens in `NEGmirror` hits\n",
    "  * Remaining Sample Size Discrepancy: $1,148,985$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### For 7+ frequency filtered ad\\* forms\n",
    "\n",
    "  * $1,487,458$ tokens in `POSmirror` hits not preceded by negation\n",
    "    > - I.e. what would remain if _all_ potential contaminants were excluded\n",
    "    > - _250,661_ potential exclusions\n",
    "  * $293,964$ tokens in `NEGmirror` hits\n",
    "  * Remaining Sample Size Discrepancy: $1,193,494$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1487458 entries, apw_eng_19941111_0004_1:14-15-16 to pcc_eng_26_108.10246_x1747457_06:6-8-9\n",
      "Data columns (total 22 columns):\n",
      " #   Column           Non-Null Count    Dtype   \n",
      "---  ------           --------------    -----   \n",
      " 0   bigram_id        1487458 non-null  category\n",
      " 1   token_str        1487458 non-null  string  \n",
      " 2   pattern          1487458 non-null  category\n",
      " 3   category         1487458 non-null  category\n",
      " 4   adv_form         1487458 non-null  category\n",
      " 5   adj_form         1487458 non-null  category\n",
      " 6   text_window      1487458 non-null  string  \n",
      " 7   mir_deprel       1487458 non-null  category\n",
      " 8   mir_lemma        1487458 non-null  category\n",
      " 9   adv_lemma        1487458 non-null  category\n",
      " 10  adj_lemma        1487458 non-null  category\n",
      " 11  mir_form         1487458 non-null  category\n",
      " 12  mir_index        1487458 non-null  UInt16  \n",
      " 13  adv_index        1487458 non-null  uint8   \n",
      " 14  adj_index        1487458 non-null  UInt16  \n",
      " 15  mir_form_lower   1487458 non-null  category\n",
      " 16  adv_form_lower   1487458 non-null  category\n",
      " 17  adj_form_lower   1487458 non-null  category\n",
      " 18  bigram_lower     1487458 non-null  category\n",
      " 19  all_forms_lower  1487458 non-null  category\n",
      " 20  prev_form_lower  1487458 non-null  category\n",
      " 21  preceding_text   1487458 non-null  string  \n",
      "dtypes: UInt16(2), category(16), string(3), uint8(1)\n",
      "memory usage: 1.1 GB\n"
     ]
    }
   ],
   "source": [
    "enforced_pos= pmir.loc[~pmir.after_neg, :'preceding_text']\n",
    "enforced_pos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- *filtering rows...*\n",
      "  - regex parsing = False\n",
      "  - ✓ Applied filter: `adv_form_lower==exactly`\n",
      "\n",
      "### 10 random rows matching filter(s) from `input frame`\n",
      "\n",
      "+------------------------+------------------------------+--------------------------------------------------------------+\n",
      "| hit_id                 | all_forms_lower              | token_str                                                    |\n",
      "+========================+==============================+==============================================================+\n",
      "| pcc_eng_01_007.5031_x0 | everything_exactly_right     | Everything from the frieze boards on the exterior to the     |\n",
      "| 105039_16:01-17-18     |                              | window trim on the interior is __`exactly`__ right for the   |\n",
      "|                        |                              | space .                                                      |\n",
      "+------------------------+------------------------------+--------------------------------------------------------------+\n",
      "| pcc_eng_06_077.3579_x1 | everyone_exactly_alike       | I grew up in an environment where there were very few people |\n",
      "| 234906_19:20-22-23     |                              | to be intolerant of , because nearly everyone was            |\n",
      "|                        |                              | __`exactly`__ alike .                                        |\n",
      "+------------------------+------------------------------+--------------------------------------------------------------+\n",
      "| pcc_eng_08_054.6917_x0 | everyone_exactly_right       | And everyone which is really wonderful is __`exactly`__      |\n",
      "| 869513_62:2-8-9        |                              | right for their roles .                                      |\n",
      "+------------------------+------------------------------+--------------------------------------------------------------+\n",
      "| pcc_eng_08_094.1834_x1 | everything_exactly_right     | This was one of those peak \" vacation moments \" when         |\n",
      "| 508489_019:12-14-15    |                              | everything was __`exactly`__ right : perfect air , no bugs , |\n",
      "|                        |                              | great scenery , the sound of the water falling , nobody else |\n",
      "|                        |                              | around , and no schedule .                                   |\n",
      "+------------------------+------------------------------+--------------------------------------------------------------+\n",
      "| pcc_eng_10_016.2174_x0 | everything_exactly_different | \" Everything is __`exactly`__ different now , \" I told my    |\n",
      "| 245725_013:2-4-5       |                              | father .                                                     |\n",
      "+------------------------+------------------------------+--------------------------------------------------------------+\n",
      "| pcc_eng_12_044.6593_x0 | or_exactly_enough            | The cabbage that accompanied a Muscovy duck breast was       |\n",
      "| 705786_21:19-20-21     |                              | braised with too much cinnamon , some thought , or           |\n",
      "|                        |                              | __`exactly`__ enough , thought others .                      |\n",
      "+------------------------+------------------------------+--------------------------------------------------------------+\n",
      "| pcc_eng_16_014.2506_x0 | or_exactly_correct           | Do you think that the estimation will be an over - or under- |\n",
      "| 214645_03:15-20-21     |                              | estimate , or will it be essentially __`exactly`__ correct ? |\n",
      "+------------------------+------------------------------+--------------------------------------------------------------+\n",
      "| pcc_eng_22_051.1450_x0 | something_exactly_right      | When I hear that something is \" __`exactly`__ right , \" I    |\n",
      "| 810130_11:5-8-9        |                              | expect mathematical precision .                              |\n",
      "+------------------------+------------------------------+--------------------------------------------------------------+\n",
      "| pcc_eng_28_005.0500_x0 | both_exactly_perfect         | We 're heading to the same place , we 're taking different   |\n",
      "| 065442_17:18-19-20     |                              | routes , but we 're both __`exactly`__ perfect the way we    |\n",
      "|                        |                              | are .                                                        |\n",
      "+------------------------+------------------------------+--------------------------------------------------------------+\n",
      "| pcc_eng_28_061.2836_x0 | all_exactly_right            | That is all __`exactly`__ right .                            |\n",
      "| 975191_15:3-4-5        |                              |                                                              |\n",
      "+------------------------+------------------------------+--------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "adv = 'exactly'\n",
    "new_exactly_ex = sample_pickle(\n",
    "    data=enforced_pos,\n",
    "    print_sample=False, sample_size=10,\n",
    "    columns=['all_forms_lower', 'token_str'],\n",
    "    filters=[f'adv_form_lower=={adv}'],\n",
    ")\n",
    "\n",
    "show_sample(new_exactly_ex.assign(token_str=embolden(new_exactly_ex.token_str, r' (exactly) ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- *filtering rows...*\n",
      "  - regex parsing = False\n",
      "  - ✓ Applied filter: `adv_form_lower==exactly`\n",
      "  - ✓ Applied filter: `pattern==pos-mirror-R`\n",
      "\n",
      "### 8 random rows matching filter(s) from `input frame`\n",
      "\n",
      "| hit_id                                    | all_forms_lower             | text_window                                                                                                                 | token_str                                                                                                                                                                                                                                                                                                  |\n",
      "|:------------------------------------------|:----------------------------|:----------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| pcc_eng_07_002.9468_x0031350_128:19-20-21 | or_exactly_equal            | or less than n or __`exactly`__ equal to n .                                                                                | The total value of all pips in a spell must be greater than n or less than n or __`exactly`__ equal to n .                                                                                                                                                                                                 |\n",
      "| pcc_eng_10_096.0405_x1536500_662:13-14-15 | all_exactly_identical       | , and they were all __`exactly`__ identical .                                                                               | The doors were evenly spaced from one another , and they were all __`exactly`__ identical .                                                                                                                                                                                                                |\n",
      "| pcc_eng_02_067.8072_x1080644_16:45-49-50  | everything_exactly_relevant | such a way that everything they said was __`exactly`__ relevant to what I had                                               | Once , a wand I was working on for a friend fell from a table during a ritual invocation ; on another occasion , after a particularly intense invocation , I heard a person talking on their cell phone in such a way that everything they said was __`exactly`__ relevant to what I had asked for .       |\n",
      "| pcc_eng_22_095.2471_x1523059_018:2-5-6    | both_exactly_right          | But both cannot be __`exactly`__ right when they 're both                                                                   | But both cannot be __`exactly`__ right when they 're both responsible for a team folding in the final two weeks and losing as many games as it won .                                                                                                                                                       |\n",
      "| pcc_eng_07_106.5163_x1705439_100:5-8-9    | sometimes_exactly_right     | And , indeed , sometimes that 's __`exactly`__ right !                                                                      | And , indeed , sometimes that 's __`exactly`__ right !                                                                                                                                                                                                                                                     |\n",
      "| pcc_eng_00_065.7777_x1047192_457:4-6-7    | everything_exactly_right    | In theory , everything is __`exactly`__ right : the lips ,                                                                  | In theory , everything is __`exactly`__ right : the lips , the Peter Lorre eyes ( as a lover said , centuries ago ) , the dimpled temples , the short hair , slightly grey and thinning , the way I like to wear it : the skinny , unremarkable body , in reasonable shape , with its tuft of chest hair . |\n",
      "| pcc_eng_26_085.0062_x1358518_20:07-09-10  | everything_exactly_right    | mm is enough if everything is __`exactly`__ right .                                                                         | Sure 7 mm is enough if everything is __`exactly`__ right .                                                                                                                                                                                                                                                 |\n",
      "| pcc_eng_01_007.5031_x0105039_16:01-17-18  | everything_exactly_right    | Everything from the frieze boards on the exterior to the window trim on the interior is __`exactly`__ right for the space . | Everything from the frieze boards on the exterior to the window trim on the interior is __`exactly`__ right for the space .                                                                                                                                                                                |\n",
      "\n",
      "- *filtering rows...*\n",
      "  - regex parsing = False\n",
      "  - ✓ Applied filter: `adv_form_lower==exactly`\n",
      "  - ✓ Applied filter: `pattern==pos-mirror-L`\n",
      "\n",
      "### 8 random rows matching filter(s) from `input frame`\n",
      "\n",
      "| hit_id                                    | all_forms_lower            | text_window                                                                   | token_str                                                                                                                                                                   |\n",
      "|:------------------------------------------|:---------------------------|:------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| pcc_eng_01_028.2684_x0440942_22:23-24-25  | everyone_exactly_alike     | keys or surfaces , everyone __`exactly`__ alike .                             | All we have is typewriting : a series of gestures that are always the same - taps on keys or surfaces , everyone __`exactly`__ alike .                                      |\n",
      "| pcc_eng_05_069.4747_x1107978_086:1-2-3    | everybody_exactly_alike    | Everybody __`exactly`__ alike . \"                                             | Everybody __`exactly`__ alike . \"                                                                                                                                           |\n",
      "| pcc_eng_06_038.9890_x0614425_107:3-6-7    | all_exactly_alike          | They are all of them __`exactly`__ alike , and there is                       | They are all of them __`exactly`__ alike , and there is not one of them can be eaten .                                                                                      |\n",
      "| pcc_eng_02_048.1298_x0762484_04:1-2-3     | everybody_exactly_alike    | Everybody __`exactly`__ alike . \"                                             | Everybody __`exactly`__ alike . \"                                                                                                                                           |\n",
      "| pcc_eng_04_104.1453_x1666254_08:20-21-22  | something_exactly_opposite | say that somebody said something __`exactly`__ opposite to what they actually | misrepresentation is the kind of thing you and Goerzen do where you outright lie and say that somebody said something __`exactly`__ opposite to what they actually said . > |\n",
      "| pcc_eng_15_106.5980_x1707092_015:16-17-18 | something_exactly_related  | , you offered them something __`exactly`__ related to the post they           | What if , instead of pointing visitors to a semi-related resource , you offered them something __`exactly`__ related to the post they just read ?                           |\n",
      "| pcc_eng_11_064.7133_x1031125_24:1-2-3     | everything_exactly_same    | Everything __`exactly`__ same , minimum two hundred                           | Everything __`exactly`__ same , minimum two hundred ninety people dead .                                                                                                    |\n",
      "| pcc_eng_08_106.0266_x1700594_12:1-2-3     | everything_exactly_same    | Everything __`exactly`__ same , minimum 290 people                            | Everything __`exactly`__ same , minimum 290 people dead .                                                                                                                   |\n"
     ]
    }
   ],
   "source": [
    "for pat_suff in ['R', 'L']:\n",
    "    new_exactly_ex = sample_pickle(\n",
    "        data=enforced_pos, sample_size=8,\n",
    "        print_sample=False, sort_by='adj_form_lower',\n",
    "        columns=['all_forms_lower', 'text_window', 'token_str'],\n",
    "        filters=[f'adv_form_lower=={adv}', \n",
    "                f'pattern==pos-mirror-{pat_suff}'],\n",
    "    )\n",
    "\n",
    "    show_sample(new_exactly_ex.assign(\n",
    "        text_window=embolden(new_exactly_ex.text_window, f' ({adv}) '),\n",
    "        token_str=embolden(new_exactly_ex.token_str, f' ({adv}) ')\n",
    "    ), format='pipe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Duplicated `text_window`+`all_forms_lower`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "enforced_pos['utt_len']= pd.to_numeric(enforced_pos.token_str.apply(lambda x: int(len(x.split()))), downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Potental Removals (no `utt_len` filter applied)\n",
      "▸ token_str:   15,359\n",
      "▸ text_window: 36,745\n",
      "▸ both:        14,827\n"
     ]
    }
   ],
   "source": [
    "dups_token_str = enforced_pos.loc[enforced_pos.duplicated(subset=['token_str', 'all_forms_lower']), ['all_forms_lower', 'token_str','text_window', 'utt_len']]\n",
    "dups_text_window = enforced_pos.loc[enforced_pos.duplicated(subset=['text_window', 'all_forms_lower']), ['all_forms_lower', 'token_str', 'text_window','utt_len']]\n",
    "dups_both = enforced_pos.loc[enforced_pos.duplicated(subset=['text_window', 'token_str', 'all_forms_lower']), ['all_forms_lower', 'token_str','text_window', 'utt_len']]\n",
    "# show_sample(dups.loc[dups.utt_len>=80, :].sort_values(['utt_len', 'token_str']).head(6))\n",
    "print_iter([f'token_str:   {len(dups_token_str):,}', \n",
    "            f'text_window: {len(dups_text_window):,}',\n",
    "            f'both:        {len(dups_both):,}'], header='Potental Removals (no `utt_len` filter applied)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`text_window` duplicates when restricted to 20+ tokens in `token_str`: 16,479\n"
     ]
    }
   ],
   "source": [
    "print(f'`text_window` duplicates when restricted to 20+ tokens in `token_str`: {len(dups_text_window.loc[dups_text_window.utt_len>=20, :]):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These duplicates are retained since it's too messy to separate the clearly carbon copy utterances from plausible genuine production. \n",
    "\n",
    "Highly Suspicious\n",
    "\n",
    "|     | text_window                                               | \\#tokens in sentence | \\#duplications |\n",
    "|----:|:----------------------------------------------------------|---------------------:|---------------:|\n",
    "|   7 | _Everything you see here is absolutely FREE to watch ._   |                   10 |             60 |\n",
    "|  17 | _All of Swedenborg 's works are well worth reading ._     |                   10 |             43 |\n",
    "|  60 | _2 fig Something quintessentially Canadian ._             |                    6 |             20 |\n",
    "|  65 | _Everybody is Super Heady in our sandbox ._               |                    8 |             19 |\n",
    "| 119 | _Because sometimes , 140 characters just is n't enough ._ |                   10 |             13 |\n",
    "| 143 | _\" Or maybe stupid , \" Ebenezar countered_                |                    9 |             11 |\n",
    "| 188 | _Because Sometimes 140 Characters Just Is n't Enough_     |                    8 |              9 |\n",
    "| 283 | _There 's something very wrong with our pterosaurs ._     |                    9 |              7 |\n",
    "| 290 | _The plaid decoration is all very good ._                 |                    8 |              7 |\n",
    "| 482 | _wrap up something as special as she is [...]_            |                    9 |              5 |\n",
    "\n",
    "Plausible Production\n",
    "\n",
    "|    | text_window                                    | \\#tokens in sentence | \\#duplications |\n",
    "|---:|:-----------------------------------------------|---------------------:|---------------:|\n",
    "|  2 | _Something was n't right ._                    |                    5 |            118 |\n",
    "|  3 | _But I 'm sure everything will be just fine ._ |                   10 |            102 |\n",
    "|  8 | _It 's all very confusing ._                   |                    6 |             56 |\n",
    "|  6 | _We should all be so lucky ._                  |                    7 |             69 |\n",
    "| 10 | _It 's all very exciting ._                    |                    6 |             54 |\n",
    "| 19 | _Something is definitely wrong ._              |                    5 |             41 |\n",
    "| 20 | _Looking for something more specific ?_        |                    6 |             40 |\n",
    "| 25 | _Both are equally important ._                 |                    5 |             33 |\n",
    "| 31 | _My cup is always half full ._                 |                    7 |             30 |\n",
    "| 39 | _If only it were all so simple !_              |                    9 |             24 |\n",
    "| 48 | _Everything is not awesome ._                  |                    5 |             23 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_window</th>\n",
       "      <th>utt_len</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Some of your changes are now live .</td>\n",
       "      <td>8</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And now for something completely different .</td>\n",
       "      <td>7</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Something was n't right .</td>\n",
       "      <td>5</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>But I 'm sure everything will be just fine .</td>\n",
       "      <td>10</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>And now for something completely different ...</td>\n",
       "      <td>7</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7953</th>\n",
       "      <td>\" And now for something completely different . \"</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7950</th>\n",
       "      <td>\" All of us at Whataburger are so happy to get...</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7949</th>\n",
       "      <td>\" All along I have been completely consistent ...</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8954</th>\n",
       "      <td>\" Abusers are often very adept at identifying ...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3030</th>\n",
       "      <td>\" ... something truly special . \"</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11104 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_window  utt_len  count\n",
       "0                   Some of your changes are now live .        8    384\n",
       "1          And now for something completely different .        7    122\n",
       "2                             Something was n't right .        5    118\n",
       "3          But I 'm sure everything will be just fine .       10    102\n",
       "4        And now for something completely different ...        7     75\n",
       "...                                                 ...      ...    ...\n",
       "7953   \" And now for something completely different . \"       17      1\n",
       "7950  \" All of us at Whataburger are so happy to get...       16      1\n",
       "7949  \" All along I have been completely consistent ...       18      1\n",
       "8954  \" Abusers are often very adept at identifying ...       10      1\n",
       "3030                  \" ... something truly special . \"        7      1\n",
       "\n",
       "[11104 rows x 3 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dups_text_window.loc[(dups_text_window.utt_len < 20), :].value_counts(['text_window', 'utt_len']).to_frame().reset_index().sort_values(['count','text_window', ], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weed_windows(df):\n",
    "    return pd.concat(\n",
    "        [df.loc[df.utt_len < 20, :],\n",
    "         df.loc[df.utt_len >= 20, :].drop_duplicates(\n",
    "            subset=['text_window', 'all_forms_lower'])]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1487458 entries, apw_eng_19941111_0004_1:14-15-16 to pcc_eng_26_108.10246_x1747457_06:6-8-9\n",
      "Data columns (total 23 columns):\n",
      " #   Column           Non-Null Count    Dtype   \n",
      "---  ------           --------------    -----   \n",
      " 0   bigram_id        1487458 non-null  category\n",
      " 1   token_str        1487458 non-null  string  \n",
      " 2   pattern          1487458 non-null  category\n",
      " 3   category         1487458 non-null  category\n",
      " 4   adv_form         1487458 non-null  category\n",
      " 5   adj_form         1487458 non-null  category\n",
      " 6   text_window      1487458 non-null  string  \n",
      " 7   mir_deprel       1487458 non-null  category\n",
      " 8   mir_lemma        1487458 non-null  category\n",
      " 9   adv_lemma        1487458 non-null  category\n",
      " 10  adj_lemma        1487458 non-null  category\n",
      " 11  mir_form         1487458 non-null  category\n",
      " 12  mir_index        1487458 non-null  UInt16  \n",
      " 13  adv_index        1487458 non-null  uint8   \n",
      " 14  adj_index        1487458 non-null  UInt16  \n",
      " 15  mir_form_lower   1487458 non-null  category\n",
      " 16  adv_form_lower   1487458 non-null  category\n",
      " 17  adj_form_lower   1487458 non-null  category\n",
      " 18  bigram_lower     1487458 non-null  category\n",
      " 19  all_forms_lower  1487458 non-null  category\n",
      " 20  prev_form_lower  1487458 non-null  category\n",
      " 21  preceding_text   1487458 non-null  string  \n",
      " 22  utt_len          1487458 non-null  int16   \n",
      "dtypes: UInt16(2), category(16), int16(1), string(3), uint8(1)\n",
      "memory usage: 1.1 GB\n"
     ]
    }
   ],
   "source": [
    "enforced_pos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,472,077 hits remaining in `POSmirror` set after additional filtering\n",
      "(15,381 hits removed as duplicates.)\n"
     ]
    }
   ],
   "source": [
    "new_pmir = weed_windows(enforced_pos)\n",
    "print(f'{len(new_pmir):,} hits remaining in `POSmirror` set after additional filtering', \n",
    "      f'({len(enforced_pos) - len(new_pmir):,} hits removed as duplicates.)', \n",
    "      sep='\\n')\n",
    "# show_sample(new_pmir.sample(6)[['all_forms_lower', 'text_window']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1472077 entries, apw_eng_19941111_0090_14:09-12-13 to pcc_eng_26_108.10246_x1747457_06:6-8-9\n",
      "Data columns (total 23 columns):\n",
      " #   Column           Non-Null Count    Dtype   \n",
      "---  ------           --------------    -----   \n",
      " 0   bigram_id        1472077 non-null  category\n",
      " 1   token_str        1472077 non-null  string  \n",
      " 2   pattern          1472077 non-null  category\n",
      " 3   category         1472077 non-null  category\n",
      " 4   adv_form         1472077 non-null  category\n",
      " 5   adj_form         1472077 non-null  category\n",
      " 6   text_window      1472077 non-null  string  \n",
      " 7   mir_deprel       1472077 non-null  category\n",
      " 8   mir_lemma        1472077 non-null  category\n",
      " 9   adv_lemma        1472077 non-null  category\n",
      " 10  adj_lemma        1472077 non-null  category\n",
      " 11  mir_form         1472077 non-null  category\n",
      " 12  mir_index        1472077 non-null  UInt16  \n",
      " 13  adv_index        1472077 non-null  uint8   \n",
      " 14  adj_index        1472077 non-null  UInt16  \n",
      " 15  mir_form_lower   1472077 non-null  category\n",
      " 16  adv_form_lower   1472077 non-null  category\n",
      " 17  adj_form_lower   1472077 non-null  category\n",
      " 18  bigram_lower     1472077 non-null  category\n",
      " 19  all_forms_lower  1472077 non-null  category\n",
      " 20  prev_form_lower  1472077 non-null  category\n",
      " 21  preceding_text   1472077 non-null  string  \n",
      " 22  utt_len          1472077 non-null  int16   \n",
      "dtypes: UInt16(2), category(16), int16(1), string(3), uint8(1)\n",
      "memory usage: 1.1 GB\n"
     ]
    }
   ],
   "source": [
    "new_pmir.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add `trigger_lower` column to `POSmirror` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bigram_id', 'token_str', 'pattern', 'category', 'adv_form', 'adj_form',\n",
       "       'text_window', 'mir_deprel', 'mir_lemma', 'adv_lemma', 'adj_lemma',\n",
       "       'mir_form', 'mir_index', 'adv_index', 'adj_index', 'mir_form_lower',\n",
       "       'adv_form_lower', 'adj_form_lower', 'bigram_lower', 'all_forms_lower',\n",
       "       'trigger_lower'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pmir = new_pmir.loc[:, :'all_forms_lower']\n",
    "new_pmir['trigger_lower'] = new_pmir['mir_form_lower'].astype('category')\n",
    "new_pmir.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated `POSmirror` hits dataframe saved as:\\ \n",
      "  `/share/compling/data/sanpi/4_post-processed/POSmirror/LimitedPOS-trigger-bigrams_frq-thrMIN-7.35f.pkl.gz`\n"
     ]
    }
   ],
   "source": [
    "new_path = path_dict['POSmirror'].with_name('LimitedPOS-'+path_dict['POSmirror'].name)\n",
    "\n",
    "if not new_path.is_file():\n",
    "    \n",
    "    new_pmir.loc[:, ].to_pickle(new_path)\n",
    "    print(f'Updated `POSmirror` hits dataframe saved as:\\ \\n  `{new_path}`')\n",
    "else: \n",
    "    print(f'Updated `POSmirror` hits dataframe already exists:\\ \\n  `{new_path}`')\n",
    "    print('\\n```shell')\n",
    "    !ls -ho {new_path}\n",
    "    print('```')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Duplication from `NEGmirror` as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 293964 entries, pcc_eng_11_001.0326_x0000513_088:14-15-16 to pcc_eng_10_108.10108_x1747378_18:7-8-9\n",
      "Data columns (total 21 columns):\n",
      " #   Column           Non-Null Count   Dtype   \n",
      "---  ------           --------------   -----   \n",
      " 0   bigram_id        293964 non-null  category\n",
      " 1   token_str        293964 non-null  string  \n",
      " 2   pattern          293964 non-null  category\n",
      " 3   category         293964 non-null  category\n",
      " 4   neg_form         293964 non-null  category\n",
      " 5   adv_form         293964 non-null  category\n",
      " 6   adj_form         293964 non-null  category\n",
      " 7   text_window      293964 non-null  string  \n",
      " 8   neg_deprel       293964 non-null  category\n",
      " 9   neg_lemma        293964 non-null  category\n",
      " 10  adv_lemma        293964 non-null  category\n",
      " 11  adj_lemma        293964 non-null  category\n",
      " 12  neg_index        293964 non-null  UInt16  \n",
      " 13  adv_index        293964 non-null  UInt16  \n",
      " 14  adj_index        293964 non-null  UInt16  \n",
      " 15  neg_form_lower   293964 non-null  category\n",
      " 16  adv_form_lower   293964 non-null  category\n",
      " 17  adj_form_lower   293964 non-null  category\n",
      " 18  bigram_lower     293964 non-null  category\n",
      " 19  all_forms_lower  293964 non-null  category\n",
      " 20  prev_form_lower  293964 non-null  category\n",
      "dtypes: UInt16(3), category(16), string(2)\n",
      "memory usage: 169.5 MB\n"
     ]
    }
   ],
   "source": [
    "nmir.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----------------+-----------------------------+---------------------------------------------+\n",
      "| hit_id                 | trigger_lower   | all_forms_lower             | text_window                                 |\n",
      "+========================+=================+=============================+=============================================+\n",
      "| pcc_eng_24_084.7054_x1 | never           | never_more_robust           | all American cities have never been more    |\n",
      "| 353971_6:15-17-18      |                 |                             | robust , more vibrant and                   |\n",
      "+------------------------+-----------------+-----------------------------+---------------------------------------------+\n",
      "| pcc_eng_28_004.8344_x0 | none            | none_particularly_patriotic | None of us have been particularly patriotic |\n",
      "| 061988_30:1-6-7        |                 |                             | up until now ,                              |\n",
      "+------------------------+-----------------+-----------------------------+---------------------------------------------+\n",
      "| pcc_eng_03_033.4509_x0 | never           | never_truly_great           | two decades in , never once truly great .   |\n",
      "| 525617_17:11-13-14     |                 |                             |                                             |\n",
      "+------------------------+-----------------+-----------------------------+---------------------------------------------+\n",
      "| pcc_eng_06_060.8769_x0 | nothing         | nothing_as_easy             | Nothing is as easy as it looks .            |\n",
      "| 968868_14:1-3-4        |                 |                             |                                             |\n",
      "+------------------------+-----------------+-----------------------------+---------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "nmir['utt_len']= nmir.token_str.apply(lambda x: len(x.split()))\n",
    "new_nmir = weed_windows(nmir)\n",
    "new_nmir = new_nmir.loc[:, :'all_forms_lower']\n",
    "new_nmir['trigger_lower'] = new_nmir.neg_form_lower.astype('category')\n",
    "show_sample(new_nmir.sample(4)[['trigger_lower', 'all_forms_lower', 'text_window']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* 293,964 original hits in `NEGmirror` (`NEGmirror/trigger-bigrams_frq-thrMIN-7.35f.pkl.gz`)\n",
      "* 289,776 hits remaining in `NEGmirror` set after additional filtering of duplicate hits\n",
      "  (4,188 hits removed as duplicates.)\n"
     ]
    }
   ],
   "source": [
    "print(f'\\n* {len(nmir):,} original hits in `NEGmirror` (`{path_dict[\"NEGmirror\"].relative_to(POST_PROC_DIR)}`)')\n",
    "print(f'* {len(new_nmir):,} hits remaining in `NEGmirror` set after additional filtering of duplicate hits')\n",
    "print(f'  ({len(nmir) - len(new_nmir):,} hits removed as duplicates.)', \n",
    "      sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated `NEGmirror` hits dataframe saved as:\\ \n",
      "  `/share/compling/data/sanpi/4_post-processed/NEGmirror/LimitedNEG-trigger-bigrams_frq-thrMIN-7.35f.pkl.gz`\n"
     ]
    }
   ],
   "source": [
    "new_path = path_dict['NEGmirror'].with_name('LimitedNEG-'+path_dict['NEGmirror'].name)\n",
    "if not new_path.is_file():\n",
    "    \n",
    "    new_nmir.to_pickle(new_path)\n",
    "    print(f'Updated `NEGmirror` hits dataframe saved as:\\ \\n  `{new_path}`')\n",
    "else: \n",
    "    print(f'Updated `NEGmirror` hits dataframe already exists:\\ \\n  `{new_path}`')\n",
    "    print('\\n```shell')\n",
    "    !ls -ho {new_path}\n",
    "    print('```')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After Removing Additional Duplication\n",
    "\n",
    "* $1,472,077$ hits remaining in `POSmirror` set after additional filtering\\\n",
    "  (15,381 hits removed as duplicates.)\n",
    "\n",
    "* $289,776$ hits remaining in `NEGmirror` set after additional filtering of duplicate hits\\\n",
    "  (4,188 hits removed as duplicates.)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-sanpi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
